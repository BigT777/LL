{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEYWORDS\n",
    "conjugate verbs\n",
    "pluralize singular nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_forms.word_forms import get_word_forms\n",
    "\n",
    "import json  \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': {'good', 'goodness', 'goodnesses', 'goods'},\n",
       " 'a': {'good'},\n",
       " 'v': set(),\n",
       " 'r': {'good', 'well'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_forms(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_word_forms in module word_forms.word_forms:\n",
      "\n",
      "get_word_forms(word)\n",
      "    args\n",
      "        word : a word e.g \"love\"\n",
      "    \n",
      "    returns the related word forms corresponding to the input word. the output\n",
      "    is a dictionary with four keys \"n\" (noun), \"a\" (adjective), \"v\" (verb)\n",
      "    and \"r\" (adverb). The value for each key is a python Set containing\n",
      "    related word forms with that part of speech.\n",
      "    \n",
      "    e.g. {'a': {'lovable', 'loveable'},\n",
      "          'n': {'love', 'lover', 'lovers', 'loves'},\n",
      "          'r': set(),\n",
      "          'v': {'love', 'loved', 'loves', 'loving'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(get_word_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unigramms_unique.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amplification',\n",
       " 'recriminations',\n",
       " 'intensification',\n",
       " 'indemnification',\n",
       " 'classification',\n",
       " 'mortification',\n",
       " 'quantification',\n",
       " 'simplification',\n",
       " 'qualifications',\n",
       " 'magnification',\n",
       " 'gratification',\n",
       " 'reunification',\n",
       " 'reciprocation',\n",
       " 'specialization',\n",
       " 'clarifications',\n",
       " 'stratification',\n",
       " 'qualification',\n",
       " 'justifications',\n",
       " 'objectification',\n",
       " 'sophistication',\n",
       " 'personification',\n",
       " 'rectification',\n",
       " 'fortifications',\n",
       " 'certification',\n",
       " 'clarification',\n",
       " 'justification',\n",
       " 'recrimination',\n",
       " 'diversification',\n",
       " 'notifications',\n",
       " 'desertification',\n",
       " 'simplifications',\n",
       " 'fortification',\n",
       " 'ramifications',\n",
       " 'identification',\n",
       " 'precipitation']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_mixed_words = {}\n",
    "for el in data:\n",
    "    dct_mixed_words[el['word']] = el['simlar_words']\n",
    "dct_mixed_words['specifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abdE'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "regex.sub('', 'ab3d*E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cossack\n",
      "('cossack', 'NN')\n",
      "wordforms_dict {'n': set(), 'a': set(), 'v': set(), 'r': set()}\n",
      "wordform_set set()\n",
      "\n",
      "NOT_ENOUGH_WORDS_AND_NOT_ENOUGH_MIXED_WORDS cossack\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_variants_from_dict(dct):\n",
    "    wordforms_list = []\n",
    "    for wordform_type in dct.keys():\n",
    "        for wordform in dct[wordform_type]:\n",
    "            print(\"wordform\", wordform)\n",
    "            if len(wordform.split()) == 1:\n",
    "                wordforms_list.append(wordform)\n",
    "    return set(wordforms_list)\n",
    "def get_wordforms(word):\n",
    "    MINIMAL_WORDFORMS_REQ = 6\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    clean_word = regex.sub('', word)\n",
    "    print(clean_word)\n",
    "    pos_tagged_ngramm = nltk.pos_tag([clean_word])\n",
    "    for word_el in pos_tagged_ngramm:\n",
    "        print(word_el)\n",
    "        pos = get_wordnet_pos(word_el[1])\n",
    "        if pos:\n",
    "            lemma = lemmatizer.lemmatize(word_el[0], pos =pos)\n",
    "        else:\n",
    "            lemma = word_el[0]\n",
    "        break\n",
    "    if clean_word ==  lemma:\n",
    "        wordforms_dict = get_word_forms(clean_word)\n",
    "        print(\"wordforms_dict\", wordforms_dict)\n",
    "        wordform_set = extract_variants_from_dict(wordforms_dict)\n",
    "        print(\"wordform_set\", wordform_set)\n",
    "    else:\n",
    "        wordforms_dict = get_word_forms(clean_word)\n",
    "        wordform_set = extract_variants_from_dict(wordforms_dict)\n",
    "        \n",
    "        wordforms_lemma_dict = get_word_forms(lemma)\n",
    "        wordform_set_from_lemma = extract_variants_from_dict(wordforms_lemma_dict)\n",
    "        wordform_set = wordform_set.union(wordform_set_from_lemma)\n",
    "\n",
    "        \n",
    "    if len(wordform_set) < MINIMAL_WORDFORMS_REQ:\n",
    "        if lemma in dct_mixed_words:\n",
    "            more_words_number = MINIMAL_WORDFORMS_REQ - len(wordform_set)\n",
    "            add_words_list = dct_mixed_words[lemma][:more_words_number + 1]\n",
    "            print(\"additional words\", add_words_list)\n",
    "            add_words_list = set(add_words_list)\n",
    "            wordform_set = wordform_set.union(add_words_list)\n",
    "        else:\n",
    "            print(\"\\nNOT_ENOUGH_WORDS_AND_NOT_ENOUGH_MIXED_WORDS\",word)\n",
    "    return wordform_set\n",
    "get_wordforms(\"cossack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'machined',\n",
       " 'machineries',\n",
       " 'machinery',\n",
       " 'machines',\n",
       " 'machining',\n",
       " 'machinist',\n",
       " 'machinists'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_variants_from_dict(dct, original_word):\n",
    "    wordforms_list = []\n",
    "    for wordform_type in dct.keys():\n",
    "        for wordform in dct[wordform_type]:\n",
    "            #print(wordform.split()[0] == original_word)\n",
    "            if len(wordform.split()) == 1 and wordform.split()[0] != original_word:\n",
    "                #print(wordform)\n",
    "                wordforms_list.append(wordform)\n",
    "    return set(wordforms_list)\n",
    "\n",
    "def get_wordforms(word):\n",
    "    MINIMAL_WORDFORMS_REQ = 6\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    clean_word = regex.sub('', word)\n",
    "    #print(clean_word)\n",
    "    pos_tagged_ngramm = nltk.pos_tag([clean_word])\n",
    "    for word_el in pos_tagged_ngramm:\n",
    "        #print(word_el)\n",
    "        pos = get_wordnet_pos(word_el[1])\n",
    "        if pos:\n",
    "            lemma = lemmatizer.lemmatize(word_el[0], pos =pos)\n",
    "        else:\n",
    "            lemma = word_el[0]\n",
    "        break\n",
    "    if clean_word ==  lemma:\n",
    "        wordforms_dict = get_word_forms(clean_word)\n",
    "        wordform_set = extract_variants_from_dict(wordforms_dict, clean_word)\n",
    "    else:\n",
    "        wordforms_dict = get_word_forms(clean_word)\n",
    "        wordform_set = extract_variants_from_dict(wordforms_dict, clean_word)\n",
    "        \n",
    "        wordforms_lemma_dict = get_word_forms(lemma)\n",
    "        wordform_set_from_lemma = extract_variants_from_dict(wordforms_lemma_dict, clean_word)\n",
    "        wordform_set = wordform_set.union(wordform_set_from_lemma)\n",
    "\n",
    "    if len(wordform_set) < MINIMAL_WORDFORMS_REQ:\n",
    "        if lemma in dct_mixed_words:\n",
    "            more_words_number = MINIMAL_WORDFORMS_REQ - len(wordform_set)\n",
    "            add_words_list = dct_mixed_words[lemma][:more_words_number + 1]\n",
    "            print(\"additional words\", add_words_list)\n",
    "            add_words_list = set(add_words_list)\n",
    "            wordform_set = wordform_set.union(add_words_list)\n",
    "        else:\n",
    "            print(\"NOT_ENOUGH_WORDS_AND_NOT_ENOUGH_MIXED_WORDS\",word)\n",
    "    return wordform_set\n",
    "get_wordforms(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
