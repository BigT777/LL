{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "full_punctuation = punctuation + \"–\" + \",\" + \"»\" + \"«\" + \"…\" +'’'\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2_path = \"/Users/nigula/input/ngramms_tfidf/w2_.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['275', 'a', 'a\\n']\n"
     ]
    }
   ],
   "source": [
    "stopwords\n",
    "numbers something with uncruation\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bigr(path):\n",
    "    filtereb_ngramm = []\n",
    "    with open (path, \"r\",encoding='utf-8', errors='ignore') as f:\n",
    "        index = 0 \n",
    "        for line in f.readlines():\n",
    "            #print(line)\n",
    "            spl_line =line.split(\"\\t\") \n",
    "            skip = False\n",
    "            clean_word = ''\n",
    "            for word_ind in range(1, len(spl_line)):\n",
    "                #print(spl_line[word_ind])\n",
    "                if spl_line[word_ind] in stopWords:\n",
    "                    skip = True\n",
    "                    #print(\"FILTERED\",line)\n",
    "                    break\n",
    "                clean_word += spl_line[word_ind] + ' '\n",
    "            if skip == False:\n",
    "                clean_word = clean_word.strip()\n",
    "                filtereb_ngramm.append(clean_word)\n",
    "                #print(clean_word) \n",
    "            index += 1\n",
    "        \n",
    "            #if index > 20000:break\n",
    "    return filtereb_ngramm\n",
    "        \n",
    "bigramm_list_from_tfidf = filter_bigr(w2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ngr(path):\n",
    "    filtereb_ngramm = []\n",
    "    with open (path, \"r\",encoding='utf-8', errors='ignore') as f:\n",
    "        index = 0 \n",
    "        for line in f.readlines():\n",
    "            #print(line)\n",
    "            spl_line =line.split(\"\\t\") \n",
    "            stop_words_count = 0\n",
    "            clean_word = ''\n",
    "            for word_ind in range(1, len(spl_line)):\n",
    "                #print(spl_line[word_ind])\n",
    "                if spl_line[word_ind] in stopWords:\n",
    "                    stop_words_count += 1\n",
    "                    \n",
    "                clean_word += spl_line[word_ind] + ' '\n",
    "            if stop_words_count <= 1:\n",
    "                clean_word = clean_word.strip()\n",
    "                filtereb_ngramm.append(clean_word)\n",
    "                #print(clean_word) \n",
    "            index += 1\n",
    "        \n",
    "            #if index > 20000:break\n",
    "    return filtereb_ngramm\n",
    "w3_path = \"/Users/nigula/input/ngramms_tfidf/w3_.txt\"\n",
    "trigramms_list_from_tfidf = filter_ngr(w3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "w3_path = \"/Users/nigula/input/ngramms_tfidf/w4_.txt\"\n",
    "qgramms_list_from_tfidf = filter_ngr(w3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291784"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qgramms_list_from_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "colloc_qgr = []\n",
    "with open(\"colloc_qgr.txt\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        colloc_qgr.append(line[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_overall_qgramm = []\n",
    "all_trigramms = [colloc_qgr, qgramms_list_from_tfidf]\n",
    "for bigr_list in all_trigramms:\n",
    "    for bigr in bigr_list:\n",
    "        stop_words = 0\n",
    "        for word in bigr.split():\n",
    "            if word in stopWords:\n",
    "                stop_words += 1\n",
    "        if stop_words <= 1:\n",
    "            filtered_overall_qgramm.append(bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442106"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_overall_qgramm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"big_qgramms_list.json\", \"w\") as f:\n",
    "    json.dump(filtered_overall_qgramm, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766236"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigramms_list_from_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b.a degree',\n",
       " 'a b.a in',\n",
       " 'a b.s in',\n",
       " 'a ba in',\n",
       " 'a babble of',\n",
       " 'a babe in',\n",
       " 'a baby and',\n",
       " 'a baby as',\n",
       " 'a baby at',\n",
       " 'a baby before']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramms_list_from_tfidf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "colloc_trigr = []\n",
    "with open(\"colloc_trigr.txt\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        colloc_trigr.append(line[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1934801"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(colloc_trigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_overall_trigramm = []\n",
    "all_trigramms = [colloc_trigr, trigramms_list_from_tfidf]\n",
    "for bigr_list in all_trigramms:\n",
    "    for bigr in bigr_list:\n",
    "        stop_words = 0\n",
    "        for word in bigr.split():\n",
    "            if word in stopWords:\n",
    "                stop_words += 1\n",
    "        if stop_words <= 1:\n",
    "            filtered_overall_bigramm.append(bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2322194"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_overall_trigramm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great deal more',\n",
       " 'the post office',\n",
       " 'needless to say',\n",
       " 'far better than',\n",
       " 'every single one',\n",
       " 'change my mind',\n",
       " 'stood in front',\n",
       " 'a faint smile',\n",
       " 'sorry to interrupt',\n",
       " 'about twenty minute']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_overall_trigramm[1100:1110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"big_trigramms_list.json\", \"w\") as f:\n",
    "    json.dump(filtered_overall_trigramm, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "colloc_bigramm = []\n",
    "with open(\"colloc_bigr.txt\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        #print(line)\n",
    "        colloc_bigramm.append(line[:-1])\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'NN'), ('go', 'VB'), ('on', 'IN'), ('world', 'NN')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"hello\",\"go\",\"on\",\"world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_overall_bigramm = []\n",
    "all_bigramms = [colloc_bigramm, bigramm_list_from_tfidf]\n",
    "for bigr_list in all_bigramms:\n",
    "    for bigr in bigr_list:\n",
    "        skip = False\n",
    "        for word in bigr.split():\n",
    "            if word in stopWords:\n",
    "                skip = True\n",
    "        if skip == False:\n",
    "            filtered_overall_bigramm.append(bigr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674037"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigramm_list_from_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2896229"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_overall_bigramm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"big_bigramms_list.json\", \"w\") as f:\n",
    "    json.dump(filtered_overall_bigramm, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['middle class',\n",
       " 'good good',\n",
       " 'yeah yeah',\n",
       " 'right good',\n",
       " 'blah blah',\n",
       " 'stainless steel',\n",
       " 'e mail',\n",
       " 'oh oh',\n",
       " 'door open',\n",
       " 'black leather',\n",
       " 'raw material',\n",
       " 'big fat',\n",
       " 'right right',\n",
       " 'middle east',\n",
       " 'movie star',\n",
       " 'snow white',\n",
       " 'feel good',\n",
       " 'month old',\n",
       " 'sorry sorry',\n",
       " 'heavy metal',\n",
       " 'door close',\n",
       " 'ten minute',\n",
       " 'big deal',\n",
       " 'coffee table',\n",
       " 'bright yellow',\n",
       " 'day today',\n",
       " 'right next',\n",
       " 'uh uh',\n",
       " 'bedside table',\n",
       " 'nobody else',\n",
       " 'feel guilty',\n",
       " 'breakfast table',\n",
       " 'turn right',\n",
       " 'year old',\n",
       " 'somebody else',\n",
       " 'black hair',\n",
       " 'blood pressure',\n",
       " 'step closer',\n",
       " 'door swung',\n",
       " 'rock star',\n",
       " 'mouth open',\n",
       " 'small white',\n",
       " 'bang bang',\n",
       " 'wild animal',\n",
       " 'good night',\n",
       " 'great great',\n",
       " 'old man',\n",
       " 'middle age',\n",
       " 'blood vessel',\n",
       " 'run run',\n",
       " 'bright light',\n",
       " 'big enough',\n",
       " 'morning light',\n",
       " 'good old',\n",
       " 'lot better',\n",
       " 'sound good',\n",
       " 'small dark',\n",
       " 'l l',\n",
       " 'right let',\n",
       " 'big big',\n",
       " 'anyone else',\n",
       " 'mm mm',\n",
       " 'anybody else',\n",
       " 'blue sky',\n",
       " 'cash flow',\n",
       " 'thick black',\n",
       " 'dark brown',\n",
       " 'air condition',\n",
       " 'get ready',\n",
       " 'poor little',\n",
       " 'feel safe',\n",
       " 'black box',\n",
       " 'mouth full',\n",
       " 'blue light',\n",
       " 'big black',\n",
       " 'feel right',\n",
       " 'blond hair',\n",
       " 'hey hey',\n",
       " 'mmm mmm',\n",
       " 'shoulder length',\n",
       " 'cold blood',\n",
       " 'feel free',\n",
       " 'tiny little',\n",
       " 'great big',\n",
       " 'people feel',\n",
       " 'oh yeah',\n",
       " 'wind blow',\n",
       " 'everybody else',\n",
       " 'dining table',\n",
       " 'white marble',\n",
       " 'south east',\n",
       " 'lot easier',\n",
       " 'round table',\n",
       " 'damn good',\n",
       " 'black man',\n",
       " 'window open',\n",
       " 'blind man',\n",
       " 'man get',\n",
       " 'role model',\n",
       " 'cold cold',\n",
       " 'prime minister',\n",
       " 'civil war',\n",
       " 'minute later',\n",
       " 'blonde hair',\n",
       " 'turn around',\n",
       " 'dim light',\n",
       " 'god damn',\n",
       " 'junior high',\n",
       " 'one else',\n",
       " 'dinner table',\n",
       " 'fine fine',\n",
       " 'light flash',\n",
       " 'foot wide',\n",
       " 'get lost',\n",
       " 'deep blue',\n",
       " 'let loose',\n",
       " 'black magic',\n",
       " 'big old',\n",
       " 'long dark',\n",
       " 'good right',\n",
       " 'people leave',\n",
       " 'tall dark',\n",
       " 'feel cold',\n",
       " 'sci fi',\n",
       " 'quarter past',\n",
       " 'parking lot',\n",
       " 'high school',\n",
       " 'interest rate',\n",
       " 'brand new',\n",
       " 'saturday night',\n",
       " 'eye contact',\n",
       " 'good news',\n",
       " 'dead body',\n",
       " 'ex wife',\n",
       " 'cute little',\n",
       " 'dear old',\n",
       " 'bag full',\n",
       " 'feel sure',\n",
       " 'dear little',\n",
       " 'funny little']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_overall_bigramm[0:140]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
