{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import psycopg2\n",
    "import math\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_translate(text, from_lang, to_lang):\n",
    "    url_y = \"http://192.168.122.13:31436/GetTranslate\"\n",
    "    h_y = {\"apiVersion\": \"1.0.0\", \"text\": text, \"langPair\": {\"source\": from_lang, \"target\": to_lang}}\n",
    "    r = requests.post(url = url_y, json=h_y)\n",
    "    data = r.json()\n",
    "    return data['translate']\n",
    "y_translate(\"привет уеба\", \"ru\", \"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434c5c72bad34ef28abd2f3937d356f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56075), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nigula/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-bf551a7a4abf>\", line 23, in <module>\n",
      "    total_json, unhandled_json, unhandled_words = check_unhandled_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru\")\n",
      "  File \"<ipython-input-3-bf551a7a4abf>\", line 8, in check_unhandled_lookup\n",
      "    f = open(os.path.join(directory,file), \"r\", encoding='utf-8')\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nigula/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nigula/Library/Python/3.7/lib/python/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/nigula/Library/Python/3.7/lib/python/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/nigula/Library/Python/3.7/lib/python/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "def check_unhandled_lookup(directory):\n",
    "    total_files = 0\n",
    "    unhandled_lookup = 0\n",
    "    unhandled_words = []\n",
    "    for file in tqdm(os.listdir(directory)):\n",
    "        if \"DS_Store\" not in file:\n",
    "            try:\n",
    "                f = open(os.path.join(directory,file), \"r\", encoding='utf-8')\n",
    "            except:\n",
    "                f = open(os.path.join(directory,file), \"r\")\n",
    "            try:\n",
    "                data = json.load(f, encoding = 'utf-8')\n",
    "            except:\n",
    "                print(file)\n",
    "                data = json.load(f)\n",
    "            #print(len(data['def']), data['def'])\n",
    "            if len(data['def']) == 0:\n",
    "                unhandled_lookup += 1\n",
    "                word = file.split(\".\")[0]\n",
    "                unhandled_words.append(word)\n",
    "            total_files +=1\n",
    "    return total_files, unhandled_lookup, unhandled_words\n",
    "total_json, unhandled_json, unhandled_words = check_unhandled_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_from_yandex_lookup(directory, print_output = False):\n",
    "    word = []\n",
    "    local_word = []\n",
    "    pos_list = []\n",
    "    examples = []\n",
    "    examples_local = []\n",
    "    words_from_not_handled_count = 0 \n",
    "    empty = 0\n",
    "    for file in tqdm(os.listdir(directory)):\n",
    "        if print_output == True: print(file)\n",
    "        current_word = file.split(\".\")[0]\n",
    "        \n",
    "        if \"DS_Store\" not in file:\n",
    "            try:\n",
    "                f = open(os.path.join(directory,file), \"r\", encoding='utf-8')\n",
    "            except:\n",
    "                f = open(os.path.join(directory,file), \"r\")\n",
    "            try:\n",
    "                data = json.load(f, encoding = 'utf-8')\n",
    "            except:\n",
    "                data = json.load(f)\n",
    "            if \"def\" in data:\n",
    "                for definition in data['def']:\n",
    "                    word_current =  definition['text']\n",
    "                    if 'pos' in definition:\n",
    "                        global_pos = definition['pos']\n",
    "                    else:\n",
    "                        global_pos = 'no_pos_available'\n",
    "                    for translation in definition['tr']: \n",
    "                        if 'pos' in translation:\n",
    "                            pos = translation['pos']\n",
    "                        else:\n",
    "                            pos = global_pos\n",
    "                        pos_list.append(pos)\n",
    "                        word.append(word_current)\n",
    "                        local_word.append(translation['text'])\n",
    "                        ex_en = []\n",
    "                        ex_rus = []\n",
    "                        if 'ex' in translation:\n",
    "                            for exmpl in translation['ex']:\n",
    "                                #print(exmpl)\n",
    "                                ex_en.append(exmpl['text'])\n",
    "                                ex_rus.append(exmpl['tr'][0]['text'])\n",
    "                        examples.append(ex_en)\n",
    "                        examples_local.append(ex_rus)\n",
    "                if len(data['def']) == 0:\n",
    "                    empty += 1\n",
    "            words_from_not_handled_count += 1\n",
    "    print(\"empty json\", empty)\n",
    "    print(\"non_handled_basic_language__words_added_to_dataframe\", words_from_not_handled_count)\n",
    "    data = pd.DataFrame(list(zip(word,local_word,pos_list, examples, examples_local)),columns =['word', 'local_word', 'pos', 'examples','local_examples'])\n",
    "    return  data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb74642bd664a5095f6e58e9f436e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45262), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty json 26409\n",
      "non_handled_basic_language__words_added_to_dataframe 45262\n"
     ]
    }
   ],
   "source": [
    "yandex_lookup_fr_en = parse_from_yandex_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_fr_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0421d985286e4c189f189bbfce33a419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9245), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty json 4904\n",
      "non_handled_basic_language__words_added_to_dataframe 9245\n"
     ]
    }
   ],
   "source": [
    "yandex_lookup_fr_en_2 = parse_from_yandex_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_fr_en_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sagittaire</td>\n",
       "      <td>archer</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sagittaire</td>\n",
       "      <td>Sagittarian</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zorn</td>\n",
       "      <td>Zorn</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guantanamo</td>\n",
       "      <td>Guantanamo</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guantánamo</td>\n",
       "      <td>Guantanamo</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word   local_word   pos\n",
       "0  Sagittaire       archer  noun\n",
       "1  Sagittaire  Sagittarian  noun\n",
       "2        Zorn         Zorn  noun\n",
       "3  Guantanamo   Guantanamo  noun\n",
       "4  Guantánamo   Guantanamo  noun"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fr_en = pd.concat([yandex_lookup_fr_en, yandex_lookup_fr_en_2])\n",
    "del df_fr_en['examples']\n",
    "del df_fr_en['local_examples']\n",
    "\n",
    "df_fr_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9272"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(yandex_lookup_fr_en_2['word'])) + 4904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32250 entries, 0 to 5961\n",
      "Data columns (total 5 columns):\n",
      "word              32250 non-null object\n",
      "local_word        32250 non-null object\n",
      "pos               32250 non-null object\n",
      "examples          32250 non-null object\n",
      "local_examples    32250 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_fr_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr_en = df_fr_en.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21750"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_fr_en['word'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29946 entries, 0 to 5961\n",
      "Data columns (total 3 columns):\n",
      "word          29946 non-null object\n",
      "local_word    29946 non-null object\n",
      "pos           29946 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 935.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_fr_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr_en.to_csv(\"/Users/nigula/LL/adjust_unigr_dict/lookup results/yandex_lookup_fr_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Боевой ru_fr (на момент начала парсинга все слов собраны)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef820efe1ac143758afd8aea59a0940c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=68545), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "non_handled_basic_language__words_added_to_dataframe 68545\n"
     ]
    }
   ],
   "source": [
    "yandex_lookup_ru_fr = parse_from_yandex_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_ru_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yandex_lookup_ru_fr.to_csv(\"/Users/nigula/LL/adjust_unigr_dict/lookup results/yandex_lookup_ru_fr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Боевой en_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46014"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_handled_in_triplet_eng_word_csv = pd.read_csv(\"/Users/nigula/LL/adjust_unigr_dict/reverse_connected_dicts/cross_barbos/not_handled_in_triplet_eng_word.csv\")\n",
    "not_handled_in_triplet_eng_word_set= set(not_handled_in_triplet_eng_word_csv['words_no_handled'])\n",
    "len(not_handled_in_triplet_eng_word_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1a8566e20b41e7b51732241bba4fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56075), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "basic_words_added_to_dataframe 46012\n"
     ]
    }
   ],
   "source": [
    "yandex_lookup_en_ru = parse_from_yandex_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru\", \n",
    "                                              not_handled_words=not_handled_in_triplet_eng_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91843"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yandex_lookup_en_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "yandex_lookup_en_ru.to_csv(\"/Users/nigula/LL/adjust_unigr_dict/lookup results/yandex_lookup_en_ru_non_handled_friday.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yandex_lookup_fr_en= parse_from_yandex_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_fr_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tomber</td>\n",
       "      <td>fall</td>\n",
       "      <td>verb</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomber</td>\n",
       "      <td>fell</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tomber</td>\n",
       "      <td>fall down</td>\n",
       "      <td>verb</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pénétrer</td>\n",
       "      <td>penetrate</td>\n",
       "      <td>verb</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complet</td>\n",
       "      <td>full</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word local_word   pos examples local_examples\n",
       "0    tomber       fall  verb       []             []\n",
       "1    tomber       fell  noun       []             []\n",
       "2    tomber  fall down  verb       []             []\n",
       "3  pénétrer  penetrate  verb       []             []\n",
       "4   complet       full  noun       []             []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yandex_lookup_fr_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yandex_lookup_fr_ru= parse_from_yandex_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_fr_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tomber</td>\n",
       "      <td>упасть</td>\n",
       "      <td>verb</td>\n",
       "      <td>[branches tombées, tomber à terre, tomber vict...</td>\n",
       "      <td>[упавшие ветви, падать на землю, пасть жертвам...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomber</td>\n",
       "      <td>попасть</td>\n",
       "      <td>verb</td>\n",
       "      <td>[tomber en disgrâce]</td>\n",
       "      <td>[попадать в немилость]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tomber</td>\n",
       "      <td>опускать</td>\n",
       "      <td>verb</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomber</td>\n",
       "      <td>опадать</td>\n",
       "      <td>verb</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tomber</td>\n",
       "      <td>положить</td>\n",
       "      <td>verb</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word local_word   pos                                           examples  \\\n",
       "0  tomber     упасть  verb  [branches tombées, tomber à terre, tomber vict...   \n",
       "1  tomber    попасть  verb                               [tomber en disgrâce]   \n",
       "2  tomber   опускать  verb                                                 []   \n",
       "3  tomber    опадать  verb                                                 []   \n",
       "4  tomber   положить  verb                                                 []   \n",
       "\n",
       "                                      local_examples  \n",
       "0  [упавшие ветви, падать на землю, пасть жертвам...  \n",
       "1                             [попадать в немилость]  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yandex_lookup_fr_ru.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yandex_lookup_fr_ru.to_csv(\"/Users/nigula/LL/adjust_unigr_dict/lookup results/yandex_lookup_fr_ru.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yandex_lookup_fr_en.to_csv(\"yandex_lookup_fr_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youngling</td>\n",
       "      <td>детеныш</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youngling</td>\n",
       "      <td>юнец</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asperity</td>\n",
       "      <td>лишения</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asperity</td>\n",
       "      <td>шероховатость</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asperity</td>\n",
       "      <td>резкость</td>\n",
       "      <td>noun</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word     local_word   pos examples local_examples\n",
       "0  youngling        детеныш  noun       []             []\n",
       "1  youngling           юнец  noun       []             []\n",
       "2   asperity        лишения  noun       []             []\n",
       "3   asperity  шероховатость  noun       []             []\n",
       "4   asperity       резкость  noun       []             []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yandex_lookup_en_ru_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_forms(word):\n",
    "    req = \"\"\"SELECT DISTINCT\n",
    "    content_words.word_id,content_words.word_lemma, content_words.word_value\n",
    "    FROM content_words\n",
    "    WHERE content_words.word_value !~ ('\\W') AND\n",
    "    (array_length(regexp_split_to_array(content_words.word_value, '[ ''-]'), 1) = 1) \n",
    "    and word_lemma != 0 and word_hash = calc_hash(' \"\"\" + word + \"\"\"')\"\"\"\n",
    "    cursor.execute(req)\n",
    "    req_res = cursor.fetchone()\n",
    "    if not req_res:\n",
    "        print(word, \" is not in db\")\n",
    "        return []\n",
    "    else:\n",
    "        #print(a[0])\n",
    "        word_id = req_res[0]\n",
    "    word_forms_request = \"\"\"SELECT DISTINCT \n",
    "    content_words.word_value\n",
    "    FROM content_words\n",
    "    where word_lemma = \"\"\" + str(word_id) + \"\"\"  and word_lemma != word_id \"\"\"\n",
    "    cursor.execute(word_forms_request)\n",
    "    word_forms = []\n",
    "    for word in cursor:\n",
    "        #print(word[0])\n",
    "        word_forms.append(word[0])\n",
    "    return word_forms\n",
    "get_word_forms(\"book\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(path, word, local_word,examples,examples_local):\n",
    "    try:\n",
    "        with open(path, \"r\") as f: \n",
    "            data = json.load(f)\n",
    "            for definition in data['def']:\n",
    "                word_current =  definition['text']\n",
    "                for translation in definition['tr']: \n",
    "                    word.append(word_current)\n",
    "                    local_word.append(translation['text'])\n",
    "                    ex_en = []\n",
    "                    ex_rus = []\n",
    "                    if 'ex' in translation:\n",
    "                        for exmpl in translation['ex']:\n",
    "                            #print(exmpl)\n",
    "                            ex_en.append(exmpl['text'])\n",
    "                            ex_rus.append(exmpl['tr'][0]['text'])\n",
    "                    examples.append(ex_en)\n",
    "                    examples_local.append(ex_rus)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_from_yandex_lookup_vs_wordforms(directory):\n",
    "    word = []\n",
    "    local_word = []\n",
    "    examples = []\n",
    "    examples_local = []\n",
    "    words = pd.read_csv(\"test_words.csv\", header = None)\n",
    "    for word_i in words[0].items():\n",
    "        print (word_i[1])\n",
    "        file = word_i[1] + \".json\"\n",
    "        parse_json(os.path.join(directory,file),word, local_word,examples,examples_local)\n",
    "        wordforms = get_word_forms(word_i[1].lower())\n",
    "        for wf in wordforms:\n",
    "            print(\">>>\", wf)\n",
    "            file = wf + \".json\"\n",
    "            parse_json(os.path.join(directory,file),word, local_word,examples,examples_local)\n",
    "        \n",
    "    data = pd.DataFrame(list(zip(word,local_word,examples, examples_local)),columns =['word', 'local_word', 'examples','local_examples'])\n",
    "    return  data\n",
    "enru_wv = parse_from_yandex_lookup_vs_wordforms(\"./y_lookup/en_ru/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru_wv.to_csv(\"yandex_lookup_en_ru_with_wordforms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru_wv.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fr_wv = parse_from_yandex_lookup_vs_wordforms(\"./y_lookup/en_fr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fr_wv.to_csv(\"yandex_lookup_en_fr_with_wordforms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word), len(local_word), len(examples), len(examples_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru_ = parse_from_yandex_lookup(\"./y_lookup/en_ru/\")\n",
    "enru.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfr__whole_list = parse_from_yandex_lookup(\"./y_lookup/en_fr_whole_list/\", print_output=True)\n",
    "enfr__whole_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enfr__whole_list['word']).index(\"nobody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru.to_csv(\"yandex_lookup_en_ru_lemmas_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfr__whole_list.to_csv(\"yandex_lookup_en_fr_lemmas_only_WHOLE_LIST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_y = \"http://192.168.122.13:31436/GetTranslate\"\n",
    "h_y = {\"apiVersion\": \"1.0.0\", \"text\": \"гайки и болты\", \"langPair\": {\"source\": \"ru\", \"target\": \"fr\"}}\n",
    "#h_y = {\"apiVersion\": \"1.0.0\", \"text\": \"Landing to the mars\", \"langPair\": \"en-ru\"}\n",
    "r = requests.post(url = url_y, json=h_y)\n",
    "data = r.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salut, connard.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru_small = parse_from_yandex_lookup(\"./y_lookup/en_ru/\")\n",
    "len(enru_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>before</td>\n",
       "      <td>до</td>\n",
       "      <td>[before the war]</td>\n",
       "      <td>[до войны]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>before</td>\n",
       "      <td>впереди</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>before</td>\n",
       "      <td>пред</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before</td>\n",
       "      <td>накануне</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>before</td>\n",
       "      <td>передо</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word local_word          examples local_examples\n",
       "0  before         до  [before the war]     [до войны]\n",
       "1  before    впереди                []             []\n",
       "2  before       пред                []             []\n",
       "3  before   накануне                []             []\n",
       "4  before     передо                []             []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enru_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru_big.to_csv(\"./lookup results/yandex_lookup_en_ru_lemmas_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def naive_translation(en_ru_dataframe, from_lang,to_lang):\n",
    "    word = []\n",
    "    local_word = []\n",
    "    example = []\n",
    "    local_example = []\n",
    "    for element_ind in tqdm(range(len(en_ru_dataframe))):\n",
    "        el_list = list(en_ru_dataframe.iloc[element_ind])\n",
    "        word.append(el_list[1])\n",
    "        print(el_list)\n",
    "        #print(el_list[2])\n",
    "        \n",
    "        try:\n",
    "            tr_local_word = y_translate(el_list[2],from_lang,to_lang)\n",
    "            print(el_list[2], \"ok\")\n",
    "        except:\n",
    "            tr_local_word = \"no_translation\"\n",
    "            print(\"failed\", el_list[1])\n",
    "        local_word.append(tr_local_word)\n",
    "        ex = ''\n",
    "        loc_ex = ''\n",
    "        try:\n",
    "            for example_i in el_list[3].split(\"|\"):\n",
    "                if example_i:\n",
    "                    ex += example_i + '|'\n",
    "                    try:\n",
    "                        ex_tr = y_translate(example_i,\"en\",to_lang)\n",
    "                        print(example_i, \"ok\")\n",
    "                    except:\n",
    "                        ex_tr = \"no_translation\"\n",
    "                        print(\"failed\", example_i)\n",
    "                    loc_ex+= ex_tr + '|'\n",
    "        except:\n",
    "            print(\"no examples\")\n",
    "        ex = ex[:-1]\n",
    "        loc_ex = loc_ex[:-1]\n",
    "        example.append(ex)\n",
    "        local_example.append(loc_ex)\n",
    "        if element_ind % 10 == 0: \n",
    "            data = pd.DataFrame(list(zip(word,local_word,example, local_example)),columns =['word', 'local_word', 'examples','local_examples'])\n",
    "            data.to_csv(\"/Users/nigula/LL/adjust_unigr_dict/y_translate/systran_enrufr_naive/\"+str(element_ind)+\".csv\")\n",
    "        \n",
    "        #if element_ind > 10: break\n",
    "    data = pd.DataFrame(list(zip(word,local_word,example, local_example)),columns =['word', 'local_word', 'examples','local_examples'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enru_whole = naive_translation(enru_big,\"ru\",\"fr\")\n",
    "df_enru_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enru_whole.to_csv(\"naive_transaltion_en_ru_fr_LEMMAS_WHOLE_LIST.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYSTRAN EN RU TO FR NAIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_systran_en_ru = pd.read_csv(\"systran_en_ru.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_systran_en_ru.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_systran_en_ru_fr = naive_translation(df_systran_en_ru,\"ru\",\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_systran_en_ru['local_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_systran_en_ru_fr['rus_word'] = list(df_systran_en_ru['local_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_systran_en_ru_fr = df_systran_en_ru_fr.reindex(columns = ['word','rus_word', 'local_word','examples','local_examples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_systran_en_ru_fr.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_systran_en_ru_fr.to_csv(\"enrufr_naive_translation_systran_lookup_whole_list.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
