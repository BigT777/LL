{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_tr(text):\n",
    "    translator = Translator()\n",
    "\n",
    "    try:\n",
    "        tr = translator.translate(text, src='tr').text\n",
    "        return tr\n",
    "    except:\n",
    "        return None\n",
    "translate_tr ('Merhaba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ba5e194f1d50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mother\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ru\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# this code will be updated when the format is changed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/googletrans/utils.py\u001b[0m in \u001b[0;36mformat_json\u001b[0;34m(original)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegacy_format_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/googletrans/utils.py\u001b[0m in \u001b[0;36mlegacy_format_json\u001b[0;34m(original)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnxt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "translator.translate(\"mother\", src=\"en\", dest = \"ru\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text,from_lang, to_lang):\n",
    "    tr = None\n",
    "    attempts = 0\n",
    "    while not tr:\n",
    "        try:\n",
    "            tr = translator.translate(text, src=from_lang, dest = to_lang).text\n",
    "            return tr\n",
    "        except:\n",
    "            tr = None\n",
    "            time.sleep(0.01)\n",
    "            attempts +=1\n",
    "            print(\"attempt\", attempts)\n",
    "            if attempts > 15:\n",
    "                tr = \"failes\"\n",
    "translate ('I like wine', 'en','fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "sence_id_list = []\n",
    "definition = []\n",
    "examples = []\n",
    "def_trans = []\n",
    "ex_trans = []\n",
    "def sence_translation( from_lang, to_lang, word,words, sence_ids, defs, ex, definitions_trans, examples_trans, debug = False, show_sentence = False,show_all = False):\n",
    "    sence_id = 0 \n",
    "    for i, synset in enumerate(wn.synsets(word)):\n",
    "        words.append(word)\n",
    "        sence_ids.append(sence_id)\n",
    "        if (debug): print(i, synset)\n",
    "        comparison_data = []    \n",
    "        current_definition = synset.definition()\n",
    "        defs.append(current_definition)   \n",
    "        def_tr = translate (current_definition, from_lang,to_lang)\n",
    "        definitions_trans.append(def_tr)\n",
    "        examples =  synset.examples()\n",
    "        comparison_data = [ex_snetence for ex_snetence in examples]\n",
    "\n",
    "        #comparison_data.append(current_definition)#теперь сюда входят и примеры и само значение\n",
    "        \n",
    "        examples = []\n",
    "        translated_examples = []\n",
    "        for comp_sentence in comparison_data:\n",
    "            examples.append(comp_sentence)\n",
    "            ex_tr = translate (comp_sentence, from_lang,to_lang)\n",
    "            translated_examples.append(ex_tr)\n",
    "            if (debug):print(comp_sentence)\n",
    "        ex.append(examples)\n",
    "        examples_trans.append(translated_examples)\n",
    "        if (debug):print()\n",
    "        \n",
    "        sence_id += 1\n",
    "            \n",
    "sence_translation(\"en\", \"ru\", \"home\",word_list,sence_id_list,definition,examples,def_trans, ex_trans, debug = False, show_sentence = True)#True False\n",
    "df = pd.DataFrame(list(zip(word_list,sence_id_list,definition,examples,def_trans,ex_trans)), \n",
    "                                              columns =['word','sence_id','definition','example','def_trans','ex_trans']) \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"break_wordnet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_for_eval = ['go','report','drive','look','feel','people','learn','table','bokk']\n",
    "def get_multisence_trans(words_list,export_name):\n",
    "    word_list = []\n",
    "    sence_id_list = []\n",
    "    definition = []\n",
    "    examples = []\n",
    "    def_trans = []\n",
    "    ex_trans = []\n",
    "    for word in words_list:\n",
    "        sence_translation(\"home\",word_list,sence_id_list,definition,examples,def_trans, ex_trans, debug = False, show_sentence = True)#True False\n",
    "    df = pd.DataFrame(list(zip(word_list,sence_id_list,definition,examples,def_trans,ex_trans)), \n",
    "                                              columns =['word','sence_id','definition','example','def_trans','ex_trans']) \n",
    "    df.to_csv(export_name + '.csv')\n",
    "\n",
    "get_multisence_trans(words_for_eval,'en_fr_wordnet')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk( word, sentence, debug = False, show_sentence = False,show_all = False):\n",
    "    \n",
    "    \n",
    "    \"\"\"Ваш код тут\"\"\"\n",
    "    sentence =  sentence.split(\" \")\n",
    "    sentence = [w for w in sentence if not w in stop_words] \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    sentence = [wordnet_lemmatizer.lemmatize(w) for w in sentence]\n",
    "    \n",
    "    bestsense = 0\n",
    "    #maxoverlap = 0\n",
    "    min_mean_overlap_dist = 100#начальная точка новой метрики\n",
    "    final_definition = ''\n",
    "    \n",
    "    word_index = sentence.index(word)#индекс исследуемого слова в предложении\n",
    "    \n",
    "    #получаем часть речи для дальнейшего отграничения ранжира поиска\n",
    "    #pos_sentence = nltk.pos_tag(sentence)\n",
    "    #word_pos = get_pos(pos_sentence, word)\n",
    "    #if (debug): print(\"word_pos\", word_pos)\n",
    "    \n",
    "    for i, synset in enumerate(wn.synsets(word)):\n",
    "        #if (debug): print(i, synset)\n",
    "        comparison_data = []    \n",
    "        current_definition = synset.definition()\n",
    "        \n",
    "        definition = tokenize(current_definition)\n",
    "        #print(definition)\n",
    "        #if (debug):print(\"DEFINITION FULL\",current_definition)\n",
    "        \n",
    "        #if (debug):print(\"DEFINITION PROCESSED\",definition)\n",
    "        \n",
    "        \n",
    "        examples =  synset.examples()\n",
    "        comparison_data = [tokenize(ex_snetence) for ex_snetence in examples]\n",
    "        sentence_set = set(sentence)\n",
    "        #if (show_sentence): print(\"SETENCE\",  sentence)\n",
    "        \n",
    "        #if (debug): print(definition & sentence_set)\n",
    "        mean_overlap_distance = 0\n",
    "        comparison_data.append(definition)#теперь сюда входят и примеры и само значение\n",
    "        #print(comparison_data) \n",
    "        comparison_data_set = [set(el) for el in comparison_data]\n",
    "        if (show_sentence): print(\"SETENCE\",  sentence)\n",
    "        if (debug): print(\"START ITERATING OVER AL DATA\")\n",
    "        \n",
    "        word_distance = []\n",
    "        for comp_sentence_set,comp_sentence in zip(comparison_data_set, comparison_data):\n",
    "            if (debug):print(\"comp_sentence:\",' '.join(comp_sentence))\n",
    "            overlap_words_set = sentence_set & comp_sentence_set\n",
    "            if(word in overlap_words_set):\n",
    "                overlap_words_set.remove(word)\n",
    "\n",
    "            if (overlap_words_set and debug):print(\"overlap_words_set\",overlap_words_set)\n",
    "            for overlapped_word in overlap_words_set:\n",
    "                if (debug): print(\"disambig_word_index = \", word_index)\n",
    "                ind = sentence.index(overlapped_word)\n",
    "                if (debug):print(\"overlapped_word = \", overlapped_word)\n",
    "                if (debug): print(\"overlapped_word_ind\", ind)\n",
    "                abs_distance = abs(ind - word_index)\n",
    "                if (debug): print(\"abs_distance\", abs_distance)\n",
    "                word_distance.append(abs_distance)  \n",
    "        \n",
    "        \n",
    "        #overlap_len = len(overlap)\n",
    "        if (debug): print(\"word_distance\" , word_distance)\n",
    "        #применяем новую метрику\n",
    "        mean_overlap_distance = np.mean(word_distance) / len(word_distance)\n",
    "        if (debug):\n",
    "            if ( mean_overlap_distance == 0 or math.isnan(mean_overlap_distance) ): \n",
    "                print(\"ITERATING FINISHED.NO OVERLAP FOUND\",'\\n')\n",
    "        if(mean_overlap_distance > 0):\n",
    "            if (debug):print(\"OVERLAP_FOUND\")\n",
    "            if (debug):print(\"EXAMPLES_ORIGINAL = \", examples)\n",
    "            if (debug):print(\"ALL_COMPAR_DATA = \", comparison_data)\n",
    "            if (debug): print(i, synset)\n",
    "            if (debug):print(\"DEFINITION FULL\",current_definition)\n",
    "            if (debug):print(\"DEFINITION PROCESSED\",definition)\n",
    "            if (show_sentence): print(\"SETENCE\",  sentence)\n",
    "            if (debug): print(\"mean_overlap_distance\", mean_overlap_distance)\n",
    "                \n",
    "            if (debug): print(\"\\n\")\n",
    "        \n",
    "        #обновляем посчитанное значение если оно меньше предыдущего\n",
    "        if (mean_overlap_distance < min_mean_overlap_dist):\n",
    "            min_mean_overlap_dist = mean_overlap_distance\n",
    "            bestsense = i\n",
    "            final_definition = current_definition\n",
    "    \n",
    "    return bestsense, final_definition\n",
    "lesk(\"break\", \"They break the rules in order to convince the rule-makers\",debug = True, show_sentence = True)#True False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
