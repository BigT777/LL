{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import copy\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='pgstage', user='linguist', password='eDQGK0GCStlYlHNV', host='192.168.122.183')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': {'lemma_branch': [{'definition': 'a set of pages fastened together in a cover for people to read',\n",
       "    'local_word': 'книга',\n",
       "    'examples': ['a book about animals']},\n",
       "   {'definition': 'a set of stamps, tickets, etc that are fastened together inside a cover',\n",
       "    'local_word': 'книжечка',\n",
       "    'examples': []},\n",
       "   {'definition': 'a set of pages fastened together in a cover and used for writing on',\n",
       "    'local_word': 'записная книжка',\n",
       "    'examples': ['an address book']},\n",
       "   {'definition': 'to arrange to use or do something at a particular time in the future',\n",
       "    'local_word': 'бронировать',\n",
       "    'examples': ['to book a ticket/hotel room',\n",
       "     \"We've booked a trip to Spain for next month.\",\n",
       "     'Sorry, the hotel is fully booked (= has no more rooms).']},\n",
       "   {'definition': 'to officially accuse someone of a crime',\n",
       "    'local_word': 'заводить дело',\n",
       "    'examples': ['Detectives booked him for resisting arrest.']},\n",
       "   {'definition': 'If a sports official books you, they write an official record of something you have done wrong.',\n",
       "    'local_word': 'штрафовать (в спорте)',\n",
       "    'examples': ['The referee booked two players for fighting during the game.']}],\n",
       "  'wordforms_branch': {}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_def_info(word, from_lang, to_lang, multisence_dict, print_ouput = False):\n",
    "    multisence_dict[word] = {'lemma_branch':[], 'wordforms_branch':{}}\n",
    "    definitions = []\n",
    "    same_page = False\n",
    "    for index in range(1,4):\n",
    "        url = \"https://dictionary.cambridge.org/dictionary/\" + from_lang + \"-\" + to_lang + \"/\" + word + \"_\" + str(index)\n",
    "        if print_ouput:print(url)\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.encoding = 'utf-8' \n",
    "        soup = bs(response.text, 'html.parser')\n",
    "        current_definition = {}\n",
    "        for link in soup.find_all([\"span\",\"b\"]):\n",
    "    \n",
    "            classes = link.get('class')\n",
    "            if classes and \"def\" in classes:\n",
    "                if link.text.strip() in definitions:\n",
    "                    same_page = True\n",
    "                    break\n",
    "                if print_ouput: print(\"DEFINITION\", link.text.strip())\n",
    "                current_definition['definition'] = link.text.strip()\n",
    "                definitions.append(link.text.strip())\n",
    "                \n",
    "            if classes and \"def-body\" in classes:\n",
    "                if print_ouput:print(\"RUS_DEFIN\", link.find(\"span\", attrs = {'class':\"trans\"}).text.strip())\n",
    "                current_definition['local_word'] = link.find(\"span\", attrs = {'class':\"trans\"}).text.strip()\n",
    "                current_definition['examples'] = []\n",
    "                for ex in link.find_all(\"span\", attrs = {'class':\"eg\"}):\n",
    "                    current_definition['examples'].append(ex.text.strip())\n",
    "                    if print_ouput:print(\"ENG_DEFIN_EX\", ex.text.strip())\n",
    "                if print_ouput:print(current_definition)\n",
    "                multisence_dict[word]['lemma_branch'].append(current_definition)\n",
    "                current_definition = {}\n",
    "                if print_ouput:print(\"===\")\n",
    "\n",
    "        if same_page == True:\n",
    "            break\n",
    "        time.sleep(random.uniform(0.5,0.9))\n",
    "sence_dict = {}      \n",
    "get_def_info(\"book\", \"english\",\"russian\",sence_dict)\n",
    "sence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baddest'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def nltk_lemmatize(word):\n",
    "    pos = pos_tag(word_tokenize(word))[0][1]\n",
    "    wordnet_pos = get_wordnet_pos(pos)\n",
    "    if wordnet_pos:\n",
    "        lemma = lemmatizer.lemmatize(word, pos = wordnet_pos)\n",
    "    else:\n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "    return lemma\n",
    "\n",
    "nltk_lemmatize(\"baddest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordform_info_from_reverso(eng_wordform, from_lang, to_lang, print_output = False):\n",
    "    wordform_localsencewords_examples_dict = {}\n",
    "    url = \"https://context.reverso.net/перевод/\" + from_lang + \"-\" + to_lang + \"/\" + eng_wordform \n",
    "    login = {'inUserName': 'n.babakov@lingualeo.com', 'inUserPass': '33vec33'}\n",
    "    header_main = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    response = requests.get(url, headers=header_main, data = login)\n",
    "    response.encoding = 'utf-8' \n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    first_string_passed = False\n",
    "    translations_variants = []\n",
    "    for link in soup.find_all(\"a\", attrs={\"class\" : \"translation\"}):\n",
    "        if first_string_passed == True:\n",
    "            sence_word = link.text.strip()\n",
    "            if print_output:print(sence_word)\n",
    "            wordform_localsencewords_examples_dict[sence_word] = []\n",
    "            translations_variants.append(sence_word)\n",
    "        first_string_passed = True\n",
    "    time.sleep(random.uniform(0.4,1.2))\n",
    "    for transl_word in translations_variants:\n",
    "        time.sleep(random.uniform(0.4,2.9))\n",
    "        url_example = \"https://context.reverso.net/перевод/\" + to_lang + \"-\" + from_lang + \"/\" + transl_word\n",
    "        response_ex = requests.get(url_example, headers=header_main)\n",
    "        soup_sub = bs(response_ex.text, 'html.parser')\n",
    "        if print_output:\n",
    "            print(\"========================================\")\n",
    "            print(\"\\nEXAMPLES FOR SENCE \",transl_word,\"\\n\" )\n",
    "        for l in soup_sub.find_all('span', attrs = {'class':'text', 'lang':'en'}):\n",
    "            example = l.text.strip()\n",
    "            #print(example, word in example, type(l.text.strip()), word)\n",
    "            regex = \"\\W\" + eng_wordform + \"\\w{0,1}\\W\"\n",
    "            find = re.findall(regex, example)\n",
    "            if len(find) > 0 :\n",
    "                wordform_localsencewords_examples_dict[transl_word].append(example)\n",
    "                if print_output: print(example)\n",
    "    return wordform_localsencewords_examples_dict\n",
    "#w_locsence_ex_dict = get_wordform_info_from_reverso('book',\"английский\",\"русский\", print_output = True )   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_context_vs_oxford_examples(eng_lemma, local_wordsence_examples_dict, general_dict, print_output = False):\n",
    "    oxford_sensewords_list = []\n",
    "    oxford_lemmas_examples_pointers_dict = {}\n",
    "    for definition_element in general_dict[eng_lemma]['lemma_branch']:\n",
    "        #if print_output: print(definition_element)\n",
    "        oxford_sensewords_list.append(definition_element['local_word'])\n",
    "        oxford_lemmas_examples_pointers_dict[definition_element['local_word']] = definition_element['examples']\n",
    "    if print_output: print(\"WILL LOOK THROUGH LOCAL WORDFORMS\", oxford_sensewords_list)\n",
    "    oxford_sensewords_list = set(oxford_sensewords_list)\n",
    "    for context_local_lemma in local_wordsence_examples_dict.keys():\n",
    "        if print_output: print(\"\\nNOWPROCESSING\", context_local_lemma)\n",
    "        orig_intersection_lemma = look_for_sublemma_word(context_local_lemma, oxford_sensewords_list)\n",
    "        if not orig_intersection_lemma:\n",
    "            if print_output: print(context_local_lemma, \"\\nno such lemma in orig dict\")\n",
    "            pass\n",
    "        elif len(local_wordsence_examples_dict[context_local_lemma]) == 0:\n",
    "            if print_output: print(context_local_lemma, \"\\ndoes not have examples with english wodform\")\n",
    "            pass\n",
    "        else:\n",
    "            #general_dict[eng_lemma]['lemma_branch'][context_local_lemma]['examples'].extend(local_wordsence_examples_dict[context_local_lemma][:3])\n",
    "            if print_output:print(oxford_lemmas_examples_pointers_dict[orig_intersection_lemma])\n",
    "            oxford_lemmas_examples_pointers_dict[orig_intersection_lemma].extend(local_wordsence_examples_dict[context_local_lemma][:3])\n",
    "            if print_output:print(\"add\",local_wordsence_examples_dict[context_local_lemma][:3] )\n",
    "dct = copy.deepcopy(sence_dict)\n",
    "#merge_context_vs_oxford_examples(\"book\",w_locsence_ex_dict, dct, print_output = True)        \n",
    "#dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_for_sublemma_word(wordform, lemmas_list):\n",
    "    if isinstance(lemmas_list, list) or isinstance(lemmas_list, set):\n",
    "        for lemma in lemmas_list:\n",
    "            if len(lemma.split()) == 1:\n",
    "                if wordform in lemma or lemma in wordform:\n",
    "                    #print(wordform)\n",
    "                    return lemma\n",
    "        return None\n",
    "    elif isinstance(lemmas_list, str):\n",
    "        if len(lemmas_list.split()) == 1:\n",
    "            if wordform in lemmas_list or lemmas_list in wordform:\n",
    "                return lemma\n",
    "            else:\n",
    "                return None\n",
    "    else:\n",
    "        return None #\"no type\" + str(type(lemmas_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
