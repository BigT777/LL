{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='pgstage', user='linguist', password='eDQGK0GCStlYlHNV', host='192.168.122.183')\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = []\n",
    "#definition = []\n",
    "local_word = []\n",
    "examples = []\n",
    "examples_local = []\n",
    "parent = \"./y_lookup/en_ru/\"\n",
    "for file in os.listdir(parent):\n",
    "    with open(os.path.join(parent,file), \"r\") as f: \n",
    "        data = json.load(f)\n",
    "        for definition in data['def']:\n",
    "            word_current =  definition['text']\n",
    "            for translation in definition['tr']: \n",
    "                word.append(word_current)\n",
    "                local_word.append(translation['text'])\n",
    "                ex_en = []\n",
    "                ex_rus = []\n",
    "                if 'ex' in translation:\n",
    "                    for exmpl in translation['ex']:\n",
    "                        #print(exmpl)\n",
    "                        ex_en.append(exmpl['text'])\n",
    "                        ex_rus.append(exmpl['tr'][0]['text'])\n",
    "                examples.append(ex_en)\n",
    "                examples_local.append(ex_rus)\n",
    "                #print(translation)\n",
    "                #print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_from_yandex_lookup(directory):\n",
    "    word = []\n",
    "    local_word = []\n",
    "    examples = []\n",
    "    examples_local = []\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        with open(os.path.join(directory,file), \"r\") as f: \n",
    "            data = json.load(f)\n",
    "            for definition in data['def']:\n",
    "                word_current =  definition['text']\n",
    "                for translation in definition['tr']: \n",
    "                    word.append(word_current)\n",
    "                    local_word.append(translation['text'])\n",
    "                    ex_en = []\n",
    "                    ex_rus = []\n",
    "                    if 'ex' in translation:\n",
    "                        for exmpl in translation['ex']:\n",
    "                            #print(exmpl)\n",
    "                            ex_en.append(exmpl['text'])\n",
    "                            ex_rus.append(exmpl['tr'][0]['text'])\n",
    "                    examples.append(ex_en)\n",
    "                    examples_local.append(ex_rus)\n",
    "    data = pd.DataFrame(list(zip(word,local_word,examples, examples_local)),columns =['word', 'local_word', 'examples','local_examples'])\n",
    "    return  data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['booker', 'booked', 'booking', 'books']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_forms(word):\n",
    "    req = \"\"\"SELECT DISTINCT\n",
    "    content_words.word_id,content_words.word_lemma, content_words.word_value\n",
    "    FROM content_words\n",
    "    WHERE content_words.word_value !~ ('\\W') AND\n",
    "    (array_length(regexp_split_to_array(content_words.word_value, '[ ''-]'), 1) = 1) \n",
    "    and word_lemma != 0 and word_hash = calc_hash(' \"\"\" + word + \"\"\"')\"\"\"\n",
    "    cursor.execute(req)\n",
    "    req_res = cursor.fetchone()\n",
    "    if not req_res:\n",
    "        print(word, \" is not in db\")\n",
    "        return []\n",
    "    else:\n",
    "        #print(a[0])\n",
    "        word_id = req_res[0]\n",
    "    word_forms_request = \"\"\"SELECT DISTINCT \n",
    "    content_words.word_value\n",
    "    FROM content_words\n",
    "    where word_lemma = \"\"\" + str(word_id) + \"\"\"  and word_lemma != word_id \"\"\"\n",
    "    cursor.execute(word_forms_request)\n",
    "    word_forms = []\n",
    "    for word in cursor:\n",
    "        #print(word[0])\n",
    "        word_forms.append(word[0])\n",
    "    return word_forms\n",
    "get_word_forms(\"book\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(path, word, local_word,examples,examples_local):\n",
    "    try:\n",
    "        with open(path, \"r\") as f: \n",
    "            data = json.load(f)\n",
    "            for definition in data['def']:\n",
    "                word_current =  definition['text']\n",
    "                for translation in definition['tr']: \n",
    "                    word.append(word_current)\n",
    "                    local_word.append(translation['text'])\n",
    "                    ex_en = []\n",
    "                    ex_rus = []\n",
    "                    if 'ex' in translation:\n",
    "                        for exmpl in translation['ex']:\n",
    "                            #print(exmpl)\n",
    "                            ex_en.append(exmpl['text'])\n",
    "                            ex_rus.append(exmpl['tr'][0]['text'])\n",
    "                    examples.append(ex_en)\n",
    "                    examples_local.append(ex_rus)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      ">>> wording\n",
      ">>> worded\n",
      ">>> words\n",
      "the\n",
      ">>> thebed\n",
      ">>> thest\n",
      ">>> the bed\n",
      ">>> thebest\n",
      ">>> thes\n",
      "and\n",
      ">>> anding\n",
      ">>> ands\n",
      ">>> ood\n",
      ">>> andren\n",
      ">>> anded\n",
      ">>> ander\n",
      "that\n",
      ">>> that led\n",
      ">>> thats\n",
      ">>> those\n",
      "for\n",
      ">>> forring\n",
      ">>> fored\n",
      ">>> fors\n",
      "with\n",
      ">>> withim\n",
      ">>> withing\n",
      ">>> withs\n",
      "but\n",
      ">>> buts\n",
      "you\n",
      ">>> youed\n",
      ">>> yous\n",
      ">>> youta\n",
      ">>> youx\n",
      ">>> youing\n",
      ">>> youger\n",
      "this\n",
      ">>> thises\n",
      ">>> this led\n",
      ">>> these\n",
      "not\n",
      ">>> not bed\n",
      ">>> notest\n",
      ">>> notting\n",
      ">>> nots\n",
      "have\n",
      ">>> have led\n",
      ">>> haveta\n",
      ">>> haveing\n",
      ">>> had\n",
      ">>> haved\n",
      ">>> haves\n",
      ">>> having\n",
      ">>> havest\n",
      "letter\n",
      ">>> lettered\n",
      ">>> letterd\n",
      ">>> lettering\n",
      ">>> letters\n",
      ">>> lettera\n",
      "plate\n",
      ">>> plating\n",
      ">>> plated\n",
      ">>> plates\n",
      "treat\n",
      ">>> treats\n",
      ">>> treated\n",
      ">>> treaten\n",
      ">>> treating\n",
      ">>> treatest\n",
      "dinner\n",
      ">>> dinners\n",
      "necessary\n",
      ">>> necessarie\n",
      "go\n",
      ">>> gota\n",
      ">>> gos\n",
      ">>> gone\n",
      ">>> went\n",
      ">>> goed\n",
      ">>> goes\n",
      ">>> goren\n",
      ">>> going\n",
      "secret\n",
      ">>> secrets\n",
      ">>> secret\n",
      ">>> secreter\n",
      "table\n",
      ">>> tables\n",
      ">>> tabled\n",
      ">>> tabling\n",
      ">>> tabler\n",
      "create\n",
      ">>> creating\n",
      ">>> creates\n",
      ">>> createing\n",
      ">>> created\n",
      "warm\n",
      ">>> warmest\n",
      ">>> warmed\n",
      ">>> warms\n",
      ">>> warmer\n",
      ">>> warming\n",
      "America\n",
      ">>> americae\n",
      ">>> americas\n",
      ">>> america\n",
      "nobody\n",
      ">>> nobodies\n",
      ">>> nobodys\n",
      "entire\n",
      ">>> entire\n",
      ">>> entired\n",
      "thousand\n",
      ">>> thousands\n",
      "Belgium\n",
      ">>> belgiums\n",
      "anything\n",
      ">>> anythings\n",
      "background\n",
      ">>> background\n",
      "child\n",
      ">>> children\n",
      ">>> childer\n",
      ">>> childs\n",
      ">>> chilt\n",
      "childhood\n",
      ">>> childhoods\n",
      ">>> childhood\n",
      "dependable\n",
      ">>> dependable\n",
      "everything\n",
      ">>> everythung\n",
      ">>> everything\n",
      "grandchild\n",
      ">>> grandchild\n",
      "ketchup\n",
      ">>> ketchups\n",
      ">>> ketchuped\n",
      "point\n",
      ">>> pointing\n",
      ">>> pointest\n",
      ">>> points\n",
      ">>> pointed\n",
      ">>> point\n",
      ">>> pointtest\n",
      "strength\n",
      ">>> strengths\n",
      "star\n",
      ">>> star\n",
      ">>> starred\n",
      ">>> starring\n",
      ">>> starrer\n",
      ">>> stars\n",
      ">>> starer\n",
      "thing\n",
      ">>> thung\n",
      ">>> things\n",
      "coincide\n",
      ">>> coincided\n",
      ">>> coinciding\n",
      ">>> coincides\n",
      "coincidental\n",
      "dance\n",
      ">>> danceing\n",
      ">>> dancing\n",
      ">>> dances\n",
      ">>> danced\n",
      "countryside\n",
      ">>> countrysid\n",
      "break\n",
      ">>> breaks\n",
      ">>> broke\n",
      ">>> breakest\n",
      ">>> breaking\n",
      ">>> broken\n",
      ">>> breaked\n",
      "mother\n",
      ">>> mothers\n",
      ">>> mothering\n",
      ">>> motherin\n",
      ">>> mothered\n",
      "start\n",
      ">>> starttest\n",
      ">>> startd\n",
      ">>> started\n",
      ">>> starts\n",
      ">>> startted\n",
      ">>> starting\n",
      "tip\n",
      ">>> tipping\n",
      ">>> tipped\n",
      ">>> tips\n",
      ">>> tiped\n",
      "apologise\n",
      ">>> apologised\n",
      ">>> apologisin\n",
      ">>> apologises\n",
      "come\n",
      ">>> came\n",
      ">>> comeing\n",
      ">>> comest\n",
      ">>> coming\n",
      ">>> comes\n",
      "curriculum\n",
      ">>> curricula\n",
      ">>> curriculum\n",
      "expertise\n",
      ">>> expertised\n",
      ">>> expertise\n",
      ">>> expertisin\n",
      ">>> expertises\n",
      "freeze\n",
      ">>> freezing\n",
      ">>> froze\n",
      ">>> frozen\n",
      ">>> freezes\n",
      ">>> freezed\n",
      "issue\n",
      ">>> issue\n",
      ">>> issueing\n",
      ">>> issued\n",
      ">>> issuing\n",
      ">>> issues\n",
      "peremptory\n",
      ">>> peremptori\n",
      "parent\n",
      ">>> parented\n",
      ">>> parenting\n",
      ">>> parent\n",
      ">>> parents\n",
      "member\n",
      ">>> members\n",
      "band\n",
      ">>> banding\n",
      ">>> bands\n",
      ">>> bood\n",
      ">>> banded\n",
      "order\n",
      ">>> orders\n",
      ">>> orderi\n",
      ">>> ordering\n",
      ">>> ordered\n",
      ">>> orderest\n",
      "hot\n",
      ">>> hots\n",
      ">>> hoting\n",
      ">>> hotted\n",
      ">>> hotest\n",
      ">>> hotter\n",
      ">>> hotting\n",
      ">>> hoted\n",
      ">>> hottest\n",
      "fly\n",
      ">>> flid\n",
      ">>> flyest\n",
      ">>> flew\n",
      ">>> flying\n",
      ">>> flyed\n",
      ">>> fliest\n",
      ">>> flies\n",
      ">>> flied\n",
      ">>> flys\n",
      "lie\n",
      ">>> lies\n",
      ">>> lying\n",
      ">>> lieing\n",
      ">>> lied\n",
      ">>> lain\n",
      ">>> liebing\n",
      "select\n",
      ">>> selects\n",
      ">>> selected\n",
      ">>> selectin\n",
      ">>> selectest\n",
      ">>> selectted\n",
      ">>> selecting\n",
      "school\n",
      ">>> schools\n",
      ">>> schooling\n",
      ">>> schooled\n",
      "cafe\n",
      ">>> cafes\n",
      "buy\n",
      ">>> buys\n",
      ">>> buying\n",
      ">>> buyest\n",
      ">>> buies\n",
      ">>> buyed\n",
      "tell\n",
      ">>> tellest\n",
      ">>> tollen\n",
      ">>> telling\n",
      ">>> tells\n",
      ">>> told\n",
      "international\n",
      ">>> internatio\n",
      "stand\n",
      ">>> standed\n",
      ">>> stands\n",
      ">>> standest\n",
      ">>> stander\n",
      ">>> stood\n",
      ">>> standing\n",
      "fish\n",
      ">>> fishd\n",
      ">>> fishing\n",
      ">>> fishes\n",
      ">>> fishs\n",
      ">>> fished\n",
      ">>> fishbed\n",
      "benefit\n",
      ">>> benefits\n",
      ">>> benefittin\n",
      ">>> benefitted\n",
      ">>> benefited\n",
      ">>> benefiting\n",
      "intelligent\n",
      ">>> intelligen\n",
      "follow\n",
      ">>> follows\n",
      ">>> followed\n",
      ">>> following\n",
      "journey\n",
      ">>> journeying\n",
      ">>> journeys\n",
      ">>> journeyd\n",
      ">>> journeyin\n",
      ">>> journeyed\n",
      "news\n",
      ">>> newses\n",
      "write\n",
      ">>> writes\n",
      ">>> wrote\n",
      ">>> writing\n",
      ">>> written\n",
      ">>> writeing\n",
      "approbation\n",
      ">>> approbatio\n",
      "read\n",
      ">>> readest\n",
      ">>> reads\n",
      ">>> reader\n",
      ">>> reading\n",
      ">>> readed\n",
      "hear\n",
      ">>> hearred\n",
      ">>> hearing\n",
      ">>> hearther\n",
      ">>> heared\n",
      ">>> horne\n",
      ">>> heard\n",
      ">>> hears\n",
      "feel\n",
      ">>> feeling\n",
      ">>> feelest\n",
      ">>> felt\n",
      ">>> feelling\n",
      ">>> feels\n",
      ">>> feeled\n",
      "be\n",
      ">>> beger\n",
      ">>> bes\n",
      ">>> is\n",
      ">>> am\n",
      ">>> will\n",
      ">>> being\n",
      ">>> were\n",
      ">>> been\n",
      ">>> beren\n",
      ">>> was\n",
      "right\n",
      ">>> rights\n",
      ">>> rightest\n",
      ">>> righter\n",
      ">>> righted\n",
      ">>> righting\n",
      "guru\n",
      ">>> guru\n",
      ">>> gurus\n",
      "beginner\n",
      ">>> beginners\n",
      "collide\n",
      ">>> collode\n",
      ">>> collided\n",
      ">>> collides\n",
      ">>> colliding\n",
      "genetically\n",
      "precedent\n",
      ">>> precedents\n",
      "refugee\n",
      ">>> refugees\n",
      ">>> refugeeing\n",
      "secular\n",
      ">>> seculars\n",
      "pasta\n",
      ">>> pastas\n",
      "beaver\n",
      ">>> beavered\n",
      ">>> beavers\n",
      ">>> beavering\n",
      "tiger\n",
      ">>> tigers\n",
      ">>> tigering\n",
      ">>> tigered\n",
      "lion\n",
      ">>> lions\n",
      "pen\n",
      ">>> penning\n",
      ">>> pened\n",
      ">>> pens\n",
      ">>> penned\n",
      "coconut\n",
      ">>> coconuts\n",
      "dynamite\n",
      ">>> dynamites\n",
      ">>> dynamited\n",
      ">>> dynamiting\n",
      "spoon\n",
      ">>> spoons\n",
      ">>> spoonin\n",
      ">>> spooned\n",
      ">>> spooning\n",
      "ocean\n",
      ">>> ocean\n",
      ">>> oceaner\n",
      ">>> oceans\n",
      "mug\n",
      ">>> mugging\n",
      ">>> mugged\n",
      ">>> mugs\n",
      "shampoo\n",
      ">>> shampoos\n",
      ">>> shampooing\n",
      ">>> shampooed\n",
      "buzzer\n",
      ">>> buzzers\n",
      "exhaustively\n",
      "exhaustively  is not in db\n",
      "apoplexy\n",
      "submissively\n",
      "typhus\n",
      "ravioli\n",
      "meeting\n",
      ">>> meetings\n",
      "actually\n",
      "earring\n",
      ">>> earrings\n",
      ">>> earringed\n",
      "add\n",
      ">>> added\n",
      ">>> adds\n",
      ">>> adding\n",
      "adjective\n",
      ">>> adjectives\n",
      ">>> adjective\n",
      "drawing\n",
      ">>> drawings\n",
      "dream\n",
      ">>> dreamled\n",
      ">>> dreamt\n",
      ">>> dreamest\n",
      ">>> dreaming\n",
      ">>> dreams\n",
      ">>> dreamed\n",
      "dressed\n",
      "driving\n",
      ">>> drivings\n",
      "drum\n",
      ">>> drumming\n",
      ">>> drummed\n",
      ">>> drums\n",
      "dry\n",
      ">>> dryest\n",
      ">>> dries\n",
      ">>> driest\n",
      ">>> drys\n",
      ">>> drying\n",
      ">>> dryed\n",
      "duck\n",
      ">>> ducking\n",
      ">>> ducked\n",
      ">>> ducks\n",
      "advanced\n",
      "during\n",
      "earn\n",
      ">>> earnt\n",
      ">>> earned\n",
      ">>> earn\n",
      ">>> earning\n",
      ">>> earns\n",
      ">>> earnd\n",
      "singular\n",
      ">>> singulars\n",
      "easily\n",
      ">>> easilier\n",
      "east\n",
      ">>> eastest\n",
      ">>> easting\n",
      ">>> easten\n",
      ">>> easts\n",
      ">>> eastren\n",
      ">>> east\n",
      "eighth\n",
      ">>> eighths\n",
      ">>> eighthed\n",
      "adventure\n",
      ">>> adventurin\n",
      ">>> adventures\n",
      ">>> adventure\n",
      ">>> adventured\n",
      "eighty\n",
      ">>> eighties\n",
      "adverb\n",
      ">>> adverbs\n",
      "electric\n",
      "advertisement\n",
      ">>> advertisem\n",
      "century\n",
      ">>> centuries\n",
      ">>> centuried\n",
      "size\n",
      ">>> sizing\n",
      ">>> sizes\n",
      ">>> sized\n",
      "electricity\n",
      ">>> electricit\n",
      "elephant\n",
      ">>> elephants\n",
      "else\n",
      ">>> elses\n",
      ">>> elsing\n",
      "empty\n",
      ">>> emptying\n",
      ">>> emptyed\n",
      ">>> emptied\n",
      ">>> emptiest\n",
      ">>> emptier\n",
      ">>> emptys\n",
      ">>> empties\n",
      "engine\n",
      ">>> engine bed\n",
      ">>> engine\n",
      ">>> engining\n",
      ">>> engines\n",
      ">>> engined\n",
      "engineer\n",
      ">>> engineered\n",
      ">>> engineerin\n",
      ">>> engineers\n",
      "enough\n",
      ">>> enoughs\n",
      "enter\n",
      ">>> entering\n",
      ">>> enters\n",
      ">>> entered\n",
      ">>> enterest\n",
      "entrance\n",
      ">>> entranced\n",
      ">>> entrance\n",
      ">>> entrances\n",
      ">>> entrancing\n",
      "advice\n",
      ">>> adviced\n",
      ">>> advices\n",
      ">>> advice\n",
      ">>> advicing\n",
      "aeroplane\n",
      ">>> aeroplaned\n",
      ">>> aeroplanes\n",
      "envelope\n",
      ">>> envelopes\n",
      ">>> envelope\n",
      "especially\n",
      "euro\n",
      ">>> euros\n",
      "even\n",
      ">>> evenning\n",
      ">>> evens\n",
      ">>> evened\n",
      "afraid\n",
      ">>> afraided\n",
      ">>> afraids\n",
      "afterwards\n",
      ">>> afterwards\n",
      "everyone\n",
      ">>> everyones\n",
      "against\n",
      ">>> againsts\n",
      "everything\n",
      ">>> everythung\n",
      ">>> everything\n",
      "everywhere\n",
      ">>> everywhere\n",
      "aged\n",
      "ago\n",
      ">>> ago\n",
      ">>> agota\n",
      "exactly\n",
      "exam\n",
      ">>> examing\n",
      ">>> exams\n",
      ">>> examed\n",
      ">>> exammed\n",
      "examination\n",
      ">>> examinatio\n",
      "excellent\n",
      ">>> excellente\n",
      "except\n",
      ">>> excepted\n",
      ">>> excepts\n",
      ">>> excepting\n",
      "exercise\n",
      ">>> exercising\n",
      ">>> exercised\n",
      ">>> exercises\n",
      "exit\n",
      ">>> exitting\n",
      ">>> exiting\n",
      ">>> exited\n",
      ">>> exits\n",
      "explain\n",
      ">>> explains\n",
      ">>> explainest\n",
      ">>> explainer\n",
      ">>> explaining\n",
      ">>> explained\n",
      "extra\n",
      ">>> extra bed\n",
      ">>> extras\n",
      "fact\n",
      ">>> facting\n",
      ">>> facted\n",
      ">>> facts\n",
      "fail\n",
      ">>> failling\n",
      ">>> failest\n",
      ">>> fails\n",
      ">>> failing\n",
      ">>> failed\n",
      "fair\n",
      ">>> fairest\n",
      ">>> fairer\n",
      ">>> fair\n",
      ">>> faired\n",
      ">>> fairing\n",
      ">>> fairs\n",
      ">>> fairi\n",
      "fall\n",
      ">>> fallest\n",
      ">>> fell\n",
      ">>> fallling\n",
      ">>> falls\n",
      ">>> falling\n",
      ">>> fallen\n",
      "agree\n",
      ">>> agreeing\n",
      ">>> agreed\n",
      ">>> agrees\n",
      "air\n",
      ">>> airi\n",
      ">>> aird\n",
      ">>> aired\n",
      ">>> airin\n",
      ">>> airs\n",
      ">>> airing\n",
      "airport\n",
      ">>> airports\n",
      "fan\n",
      ">>> fanning\n",
      ">>> fans\n",
      ">>> faner\n",
      ">>> fannest\n",
      ">>> faned\n",
      ">>> fanned\n",
      "fantastic\n",
      ">>> fantastics\n",
      "far\n",
      ">>> farer\n",
      ">>> farther\n",
      ">>> farring\n",
      ">>> farthest\n",
      ">>> furthest\n",
      ">>> further\n",
      ">>> fars\n",
      "farmer\n",
      ">>> farmers\n",
      "fashion\n",
      ">>> fashioned\n",
      ">>> fashions\n",
      ">>> fashioning\n",
      "quite\n",
      "alarm\n",
      ">>> alarming\n",
      ">>> alarmed\n",
      ">>> alarmling\n",
      ">>> alarms\n",
      "album\n",
      ">>> albums\n",
      "alcohol\n",
      ">>> alcohols\n",
      "almost\n",
      "alone\n",
      ">>> aloner\n",
      "field\n",
      ">>> fielding\n",
      ">>> fields\n",
      ">>> fielded\n",
      ">>> fielder\n",
      ">>> field\n",
      "fifth\n",
      ">>> fifths\n",
      "fifty\n",
      ">>> fiftys\n",
      "file\n",
      ">>> fild\n",
      ">>> files\n",
      ">>> file\n",
      ">>> filing\n",
      ">>> filed\n",
      "fill\n",
      ">>> fillling\n",
      ">>> filling\n",
      ">>> filled\n",
      ">>> fills\n",
      ">>> fillled\n",
      ">>> fillest\n",
      "final\n",
      ">>> finals\n",
      "finally\n",
      "finger\n",
      ">>> fingers\n",
      ">>> fingered\n",
      ">>> fingering\n",
      "fire\n",
      ">>> fireing\n",
      ">>> firest\n",
      ">>> fired\n",
      ">>> fires\n",
      ">>> firebed\n",
      ">>> firing\n",
      "fishing\n",
      ">>> fishings\n",
      "fit\n",
      ">>> fitter\n",
      ">>> fiting\n",
      ">>> fited\n",
      ">>> fits\n",
      ">>> fitting\n",
      ">>> fitted\n",
      ">>> fittest\n",
      "flight\n",
      ">>> flights\n",
      ">>> flighting\n",
      ">>> flighter\n",
      ">>> flighted\n",
      ">>> flightin\n",
      "along\n",
      ">>> alonger\n",
      ">>> alongs\n",
      ">>> alonged\n",
      "bedroom\n",
      ">>> bedroomed\n",
      ">>> bedrooms\n",
      "beer\n",
      ">>> beers\n",
      ">>> beeri\n",
      ">>> beered\n",
      "before\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> befores\n",
      "begin\n",
      ">>> begins\n",
      ">>> began\n",
      ">>> beginning\n",
      ">>> beginer\n",
      ">>> begining\n",
      ">>> beginnest\n",
      ">>> begun\n",
      ">>> begin\n",
      "behind\n",
      ">>> behinds\n",
      "below\n",
      ">>> below\n",
      ">>> belowed\n",
      ">>> belows\n",
      "best\n",
      ">>> bester\n",
      ">>> bests\n",
      ">>> best best\n",
      ">>> besting\n",
      ">>> bestest\n",
      ">>> bested\n",
      "synchrophasotron\n",
      "synchrophasotron  is not in db\n"
     ]
    }
   ],
   "source": [
    "def parse_from_yandex_lookup_vs_wordforms(directory):\n",
    "    word = []\n",
    "    local_word = []\n",
    "    examples = []\n",
    "    examples_local = []\n",
    "    words = pd.read_csv(\"test_words.csv\", header = None)\n",
    "    for word_i in words[0].items():\n",
    "        print (word_i[1])\n",
    "        file = word_i[1] + \".json\"\n",
    "        parse_json(os.path.join(directory,file),word, local_word,examples,examples_local)\n",
    "        wordforms = get_word_forms(word_i[1].lower())\n",
    "        for wf in wordforms:\n",
    "            print(\">>>\", wf)\n",
    "            file = wf + \".json\"\n",
    "            parse_json(os.path.join(directory,file),word, local_word,examples,examples_local)\n",
    "        \n",
    "    data = pd.DataFrame(list(zip(word,local_word,examples, examples_local)),columns =['word', 'local_word', 'examples','local_examples'])\n",
    "    return  data\n",
    "enru_wv = parse_from_yandex_lookup_vs_wordforms(\"./y_lookup/en_ru/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru_wv.to_csv(\"yandex_lookup_en_ru_with_wordforms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "      <td>слово</td>\n",
       "      <td>[last word, old english word, new word in art,...</td>\n",
       "      <td>[последнее слово, старое английское слово, нов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word</td>\n",
       "      <td>известие</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word</td>\n",
       "      <td>слова</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word</td>\n",
       "      <td>говорить</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word</td>\n",
       "      <td>сформулировать</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>word</td>\n",
       "      <td>текстовый</td>\n",
       "      <td>[word processing document]</td>\n",
       "      <td>[текстовый документ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word</td>\n",
       "      <td>словесный</td>\n",
       "      <td>[word game]</td>\n",
       "      <td>[словесная игра]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wording</td>\n",
       "      <td>формулировка</td>\n",
       "      <td>[exact wording]</td>\n",
       "      <td>[точная формулировка]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wording</td>\n",
       "      <td>редакция</td>\n",
       "      <td>[new wording]</td>\n",
       "      <td>[новая редакция]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wording</td>\n",
       "      <td>текст</td>\n",
       "      <td>[wording of the declaration]</td>\n",
       "      <td>[текст декларации]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>worded</td>\n",
       "      <td>сформулированный</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>words</td>\n",
       "      <td>речь</td>\n",
       "      <td>[sweet words, obscene words]</td>\n",
       "      <td>[сладкие речи, нецензурные фразы]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>words</td>\n",
       "      <td>текст</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>words</td>\n",
       "      <td>пословный</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>этот</td>\n",
       "      <td>[I didn't like the book]</td>\n",
       "      <td>[эта книга мне не понравилась]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the</td>\n",
       "      <td>тот</td>\n",
       "      <td>[the woman I told you about, this is the guy]</td>\n",
       "      <td>[та женщина, о которой я тебе рассказывал, это...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "      <td>такой</td>\n",
       "      <td>[not the man to shrink form responsibility]</td>\n",
       "      <td>[не такой человек, чтобы бежать от ответственн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the</td>\n",
       "      <td>тем</td>\n",
       "      <td>[the more the better, so much the worse]</td>\n",
       "      <td>[чем больше, тем лучше, тем хуже]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>thes</td>\n",
       "      <td>Фес</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>and</td>\n",
       "      <td>и</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>and</td>\n",
       "      <td>а также</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>and</td>\n",
       "      <td>причем</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>and</td>\n",
       "      <td>так и</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>and</td>\n",
       "      <td>с</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ands</td>\n",
       "      <td>НСРА</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ood</td>\n",
       "      <td>ООПР</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ander</td>\n",
       "      <td>Андер</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>that</td>\n",
       "      <td>что</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>that</td>\n",
       "      <td>будто</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>that</td>\n",
       "      <td>дабы</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word        local_word  \\\n",
       "0      word             слово   \n",
       "1      word          известие   \n",
       "2      word             слова   \n",
       "3      word          говорить   \n",
       "4      word    сформулировать   \n",
       "5      word         текстовый   \n",
       "6      word         словесный   \n",
       "7   wording      формулировка   \n",
       "8   wording          редакция   \n",
       "9   wording             текст   \n",
       "10   worded  сформулированный   \n",
       "11    words              речь   \n",
       "12    words             текст   \n",
       "13    words         пословный   \n",
       "14      the              этот   \n",
       "15      the               тот   \n",
       "16      the             такой   \n",
       "17      the               тем   \n",
       "18     thes               Фес   \n",
       "19      and                 и   \n",
       "20      and           а также   \n",
       "21      and            причем   \n",
       "22      and             так и   \n",
       "23      and                 с   \n",
       "24     ands              НСРА   \n",
       "25      ood              ООПР   \n",
       "26    Ander             Андер   \n",
       "27     that               что   \n",
       "28     that             будто   \n",
       "29     that              дабы   \n",
       "\n",
       "                                             examples  \\\n",
       "0   [last word, old english word, new word in art,...   \n",
       "1                                                  []   \n",
       "2                                                  []   \n",
       "3                                                  []   \n",
       "4                                                  []   \n",
       "5                          [word processing document]   \n",
       "6                                         [word game]   \n",
       "7                                     [exact wording]   \n",
       "8                                       [new wording]   \n",
       "9                        [wording of the declaration]   \n",
       "10                                                 []   \n",
       "11                       [sweet words, obscene words]   \n",
       "12                                                 []   \n",
       "13                                                 []   \n",
       "14                           [I didn't like the book]   \n",
       "15      [the woman I told you about, this is the guy]   \n",
       "16        [not the man to shrink form responsibility]   \n",
       "17           [the more the better, so much the worse]   \n",
       "18                                                 []   \n",
       "19                                                 []   \n",
       "20                                                 []   \n",
       "21                                                 []   \n",
       "22                                                 []   \n",
       "23                                                 []   \n",
       "24                                                 []   \n",
       "25                                                 []   \n",
       "26                                                 []   \n",
       "27                                                 []   \n",
       "28                                                 []   \n",
       "29                                                 []   \n",
       "\n",
       "                                       local_examples  \n",
       "0   [последнее слово, старое английское слово, нов...  \n",
       "1                                                  []  \n",
       "2                                                  []  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "5                                [текстовый документ]  \n",
       "6                                    [словесная игра]  \n",
       "7                               [точная формулировка]  \n",
       "8                                    [новая редакция]  \n",
       "9                                  [текст декларации]  \n",
       "10                                                 []  \n",
       "11                  [сладкие речи, нецензурные фразы]  \n",
       "12                                                 []  \n",
       "13                                                 []  \n",
       "14                     [эта книга мне не понравилась]  \n",
       "15  [та женщина, о которой я тебе рассказывал, это...  \n",
       "16  [не такой человек, чтобы бежать от ответственн...  \n",
       "17                  [чем больше, тем лучше, тем хуже]  \n",
       "18                                                 []  \n",
       "19                                                 []  \n",
       "20                                                 []  \n",
       "21                                                 []  \n",
       "22                                                 []  \n",
       "23                                                 []  \n",
       "24                                                 []  \n",
       "25                                                 []  \n",
       "26                                                 []  \n",
       "27                                                 []  \n",
       "28                                                 []  \n",
       "29                                                 []  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enru_wv.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      ">>> wording\n",
      ">>> worded\n",
      ">>> words\n",
      "the\n",
      ">>> thebed\n",
      ">>> thest\n",
      ">>> the bed\n",
      ">>> thebest\n",
      ">>> thes\n",
      "and\n",
      ">>> anding\n",
      ">>> ands\n",
      ">>> ood\n",
      ">>> andren\n",
      ">>> anded\n",
      ">>> ander\n",
      "that\n",
      ">>> that led\n",
      ">>> thats\n",
      ">>> those\n",
      "for\n",
      ">>> forring\n",
      ">>> fored\n",
      ">>> fors\n",
      "with\n",
      ">>> withim\n",
      ">>> withing\n",
      ">>> withs\n",
      "but\n",
      ">>> buts\n",
      "you\n",
      ">>> youed\n",
      ">>> yous\n",
      ">>> youta\n",
      ">>> youx\n",
      ">>> youing\n",
      ">>> youger\n",
      "this\n",
      ">>> thises\n",
      ">>> this led\n",
      ">>> these\n",
      "not\n",
      ">>> not bed\n",
      ">>> notest\n",
      ">>> notting\n",
      ">>> nots\n",
      "have\n",
      ">>> have led\n",
      ">>> haveta\n",
      ">>> haveing\n",
      ">>> had\n",
      ">>> haved\n",
      ">>> haves\n",
      ">>> having\n",
      ">>> havest\n",
      "letter\n",
      ">>> lettered\n",
      ">>> letterd\n",
      ">>> lettering\n",
      ">>> letters\n",
      ">>> lettera\n",
      "plate\n",
      ">>> plating\n",
      ">>> plated\n",
      ">>> plates\n",
      "treat\n",
      ">>> treats\n",
      ">>> treated\n",
      ">>> treaten\n",
      ">>> treating\n",
      ">>> treatest\n",
      "dinner\n",
      ">>> dinners\n",
      "necessary\n",
      ">>> necessarie\n",
      "go\n",
      ">>> gota\n",
      ">>> gos\n",
      ">>> gone\n",
      ">>> went\n",
      ">>> goed\n",
      ">>> goes\n",
      ">>> goren\n",
      ">>> going\n",
      "secret\n",
      ">>> secrets\n",
      ">>> secret\n",
      ">>> secreter\n",
      "table\n",
      ">>> tables\n",
      ">>> tabled\n",
      ">>> tabling\n",
      ">>> tabler\n",
      "create\n",
      ">>> creating\n",
      ">>> creates\n",
      ">>> createing\n",
      ">>> created\n",
      "warm\n",
      ">>> warmest\n",
      ">>> warmed\n",
      ">>> warms\n",
      ">>> warmer\n",
      ">>> warming\n",
      "America\n",
      ">>> americae\n",
      ">>> americas\n",
      ">>> america\n",
      "nobody\n",
      ">>> nobodies\n",
      ">>> nobodys\n",
      "entire\n",
      ">>> entire\n",
      ">>> entired\n",
      "thousand\n",
      ">>> thousands\n",
      "Belgium\n",
      ">>> belgiums\n",
      "anything\n",
      ">>> anythings\n",
      "background\n",
      ">>> background\n",
      "child\n",
      ">>> children\n",
      ">>> childer\n",
      ">>> childs\n",
      ">>> chilt\n",
      "childhood\n",
      ">>> childhoods\n",
      ">>> childhood\n",
      "dependable\n",
      ">>> dependable\n",
      "everything\n",
      ">>> everythung\n",
      ">>> everything\n",
      "grandchild\n",
      ">>> grandchild\n",
      "ketchup\n",
      ">>> ketchups\n",
      ">>> ketchuped\n",
      "point\n",
      ">>> pointing\n",
      ">>> pointest\n",
      ">>> points\n",
      ">>> pointed\n",
      ">>> point\n",
      ">>> pointtest\n",
      "strength\n",
      ">>> strengths\n",
      "star\n",
      ">>> star\n",
      ">>> starred\n",
      ">>> starring\n",
      ">>> starrer\n",
      ">>> stars\n",
      ">>> starer\n",
      "thing\n",
      ">>> thung\n",
      ">>> things\n",
      "coincide\n",
      ">>> coincided\n",
      ">>> coinciding\n",
      ">>> coincides\n",
      "coincidental\n",
      "dance\n",
      ">>> danceing\n",
      ">>> dancing\n",
      ">>> dances\n",
      ">>> danced\n",
      "countryside\n",
      ">>> countrysid\n",
      "break\n",
      ">>> breaks\n",
      ">>> broke\n",
      ">>> breakest\n",
      ">>> breaking\n",
      ">>> broken\n",
      ">>> breaked\n",
      "mother\n",
      ">>> mothers\n",
      ">>> mothering\n",
      ">>> motherin\n",
      ">>> mothered\n",
      "start\n",
      ">>> starttest\n",
      ">>> startd\n",
      ">>> started\n",
      ">>> starts\n",
      ">>> startted\n",
      ">>> starting\n",
      "tip\n",
      ">>> tipping\n",
      ">>> tipped\n",
      ">>> tips\n",
      ">>> tiped\n",
      "apologise\n",
      ">>> apologised\n",
      ">>> apologisin\n",
      ">>> apologises\n",
      "come\n",
      ">>> came\n",
      ">>> comeing\n",
      ">>> comest\n",
      ">>> coming\n",
      ">>> comes\n",
      "curriculum\n",
      ">>> curricula\n",
      ">>> curriculum\n",
      "expertise\n",
      ">>> expertised\n",
      ">>> expertise\n",
      ">>> expertisin\n",
      ">>> expertises\n",
      "freeze\n",
      ">>> freezing\n",
      ">>> froze\n",
      ">>> frozen\n",
      ">>> freezes\n",
      ">>> freezed\n",
      "issue\n",
      ">>> issue\n",
      ">>> issueing\n",
      ">>> issued\n",
      ">>> issuing\n",
      ">>> issues\n",
      "peremptory\n",
      ">>> peremptori\n",
      "parent\n",
      ">>> parented\n",
      ">>> parenting\n",
      ">>> parent\n",
      ">>> parents\n",
      "member\n",
      ">>> members\n",
      "band\n",
      ">>> banding\n",
      ">>> bands\n",
      ">>> bood\n",
      ">>> banded\n",
      "order\n",
      ">>> orders\n",
      ">>> orderi\n",
      ">>> ordering\n",
      ">>> ordered\n",
      ">>> orderest\n",
      "hot\n",
      ">>> hots\n",
      ">>> hoting\n",
      ">>> hotted\n",
      ">>> hotest\n",
      ">>> hotter\n",
      ">>> hotting\n",
      ">>> hoted\n",
      ">>> hottest\n",
      "fly\n",
      ">>> flid\n",
      ">>> flyest\n",
      ">>> flew\n",
      ">>> flying\n",
      ">>> flyed\n",
      ">>> fliest\n",
      ">>> flies\n",
      ">>> flied\n",
      ">>> flys\n",
      "lie\n",
      ">>> lies\n",
      ">>> lying\n",
      ">>> lieing\n",
      ">>> lied\n",
      ">>> lain\n",
      ">>> liebing\n",
      "select\n",
      ">>> selects\n",
      ">>> selected\n",
      ">>> selectin\n",
      ">>> selectest\n",
      ">>> selectted\n",
      ">>> selecting\n",
      "school\n",
      ">>> schools\n",
      ">>> schooling\n",
      ">>> schooled\n",
      "cafe\n",
      ">>> cafes\n",
      "buy\n",
      ">>> buys\n",
      ">>> buying\n",
      ">>> buyest\n",
      ">>> buies\n",
      ">>> buyed\n",
      "tell\n",
      ">>> tellest\n",
      ">>> tollen\n",
      ">>> telling\n",
      ">>> tells\n",
      ">>> told\n",
      "international\n",
      ">>> internatio\n",
      "stand\n",
      ">>> standed\n",
      ">>> stands\n",
      ">>> standest\n",
      ">>> stander\n",
      ">>> stood\n",
      ">>> standing\n",
      "fish\n",
      ">>> fishd\n",
      ">>> fishing\n",
      ">>> fishes\n",
      ">>> fishs\n",
      ">>> fished\n",
      ">>> fishbed\n",
      "benefit\n",
      ">>> benefits\n",
      ">>> benefittin\n",
      ">>> benefitted\n",
      ">>> benefited\n",
      ">>> benefiting\n",
      "intelligent\n",
      ">>> intelligen\n",
      "follow\n",
      ">>> follows\n",
      ">>> followed\n",
      ">>> following\n",
      "journey\n",
      ">>> journeying\n",
      ">>> journeys\n",
      ">>> journeyd\n",
      ">>> journeyin\n",
      ">>> journeyed\n",
      "news\n",
      ">>> newses\n",
      "write\n",
      ">>> writes\n",
      ">>> wrote\n",
      ">>> writing\n",
      ">>> written\n",
      ">>> writeing\n",
      "approbation\n",
      ">>> approbatio\n",
      "read\n",
      ">>> readest\n",
      ">>> reads\n",
      ">>> reader\n",
      ">>> reading\n",
      ">>> readed\n",
      "hear\n",
      ">>> hearred\n",
      ">>> hearing\n",
      ">>> hearther\n",
      ">>> heared\n",
      ">>> horne\n",
      ">>> heard\n",
      ">>> hears\n",
      "feel\n",
      ">>> feeling\n",
      ">>> feelest\n",
      ">>> felt\n",
      ">>> feelling\n",
      ">>> feels\n",
      ">>> feeled\n",
      "be\n",
      ">>> beger\n",
      ">>> bes\n",
      ">>> is\n",
      ">>> am\n",
      ">>> will\n",
      ">>> being\n",
      ">>> were\n",
      ">>> been\n",
      ">>> beren\n",
      ">>> was\n",
      "right\n",
      ">>> rights\n",
      ">>> rightest\n",
      ">>> righter\n",
      ">>> righted\n",
      ">>> righting\n",
      "guru\n",
      ">>> guru\n",
      ">>> gurus\n",
      "beginner\n",
      ">>> beginners\n",
      "collide\n",
      ">>> collode\n",
      ">>> collided\n",
      ">>> collides\n",
      ">>> colliding\n",
      "genetically\n",
      "precedent\n",
      ">>> precedents\n",
      "refugee\n",
      ">>> refugees\n",
      ">>> refugeeing\n",
      "secular\n",
      ">>> seculars\n",
      "pasta\n",
      ">>> pastas\n",
      "beaver\n",
      ">>> beavered\n",
      ">>> beavers\n",
      ">>> beavering\n",
      "tiger\n",
      ">>> tigers\n",
      ">>> tigering\n",
      ">>> tigered\n",
      "lion\n",
      ">>> lions\n",
      "pen\n",
      ">>> penning\n",
      ">>> pened\n",
      ">>> pens\n",
      ">>> penned\n",
      "coconut\n",
      ">>> coconuts\n",
      "dynamite\n",
      ">>> dynamites\n",
      ">>> dynamited\n",
      ">>> dynamiting\n",
      "spoon\n",
      ">>> spoons\n",
      ">>> spoonin\n",
      ">>> spooned\n",
      ">>> spooning\n",
      "ocean\n",
      ">>> ocean\n",
      ">>> oceaner\n",
      ">>> oceans\n",
      "mug\n",
      ">>> mugging\n",
      ">>> mugged\n",
      ">>> mugs\n",
      "shampoo\n",
      ">>> shampoos\n",
      ">>> shampooing\n",
      ">>> shampooed\n",
      "buzzer\n",
      ">>> buzzers\n",
      "exhaustively\n",
      "exhaustively  is not in db\n",
      "apoplexy\n",
      "submissively\n",
      "typhus\n",
      "ravioli\n",
      "meeting\n",
      ">>> meetings\n",
      "actually\n",
      "earring\n",
      ">>> earrings\n",
      ">>> earringed\n",
      "add\n",
      ">>> added\n",
      ">>> adds\n",
      ">>> adding\n",
      "adjective\n",
      ">>> adjectives\n",
      ">>> adjective\n",
      "drawing\n",
      ">>> drawings\n",
      "dream\n",
      ">>> dreamled\n",
      ">>> dreamt\n",
      ">>> dreamest\n",
      ">>> dreaming\n",
      ">>> dreams\n",
      ">>> dreamed\n",
      "dressed\n",
      "driving\n",
      ">>> drivings\n",
      "drum\n",
      ">>> drumming\n",
      ">>> drummed\n",
      ">>> drums\n",
      "dry\n",
      ">>> dryest\n",
      ">>> dries\n",
      ">>> driest\n",
      ">>> drys\n",
      ">>> drying\n",
      ">>> dryed\n",
      "duck\n",
      ">>> ducking\n",
      ">>> ducked\n",
      ">>> ducks\n",
      "advanced\n",
      "during\n",
      "earn\n",
      ">>> earnt\n",
      ">>> earned\n",
      ">>> earn\n",
      ">>> earning\n",
      ">>> earns\n",
      ">>> earnd\n",
      "singular\n",
      ">>> singulars\n",
      "easily\n",
      ">>> easilier\n",
      "east\n",
      ">>> eastest\n",
      ">>> easting\n",
      ">>> easten\n",
      ">>> easts\n",
      ">>> eastren\n",
      ">>> east\n",
      "eighth\n",
      ">>> eighths\n",
      ">>> eighthed\n",
      "adventure\n",
      ">>> adventurin\n",
      ">>> adventures\n",
      ">>> adventure\n",
      ">>> adventured\n",
      "eighty\n",
      ">>> eighties\n",
      "adverb\n",
      ">>> adverbs\n",
      "electric\n",
      "advertisement\n",
      ">>> advertisem\n",
      "century\n",
      ">>> centuries\n",
      ">>> centuried\n",
      "size\n",
      ">>> sizing\n",
      ">>> sizes\n",
      ">>> sized\n",
      "electricity\n",
      ">>> electricit\n",
      "elephant\n",
      ">>> elephants\n",
      "else\n",
      ">>> elses\n",
      ">>> elsing\n",
      "empty\n",
      ">>> emptying\n",
      ">>> emptyed\n",
      ">>> emptied\n",
      ">>> emptiest\n",
      ">>> emptier\n",
      ">>> emptys\n",
      ">>> empties\n",
      "engine\n",
      ">>> engine bed\n",
      ">>> engine\n",
      ">>> engining\n",
      ">>> engines\n",
      ">>> engined\n",
      "engineer\n",
      ">>> engineered\n",
      ">>> engineerin\n",
      ">>> engineers\n",
      "enough\n",
      ">>> enoughs\n",
      "enter\n",
      ">>> entering\n",
      ">>> enters\n",
      ">>> entered\n",
      ">>> enterest\n",
      "entrance\n",
      ">>> entranced\n",
      ">>> entrance\n",
      ">>> entrances\n",
      ">>> entrancing\n",
      "advice\n",
      ">>> adviced\n",
      ">>> advices\n",
      ">>> advice\n",
      ">>> advicing\n",
      "aeroplane\n",
      ">>> aeroplaned\n",
      ">>> aeroplanes\n",
      "envelope\n",
      ">>> envelopes\n",
      ">>> envelope\n",
      "especially\n",
      "euro\n",
      ">>> euros\n",
      "even\n",
      ">>> evenning\n",
      ">>> evens\n",
      ">>> evened\n",
      "afraid\n",
      ">>> afraided\n",
      ">>> afraids\n",
      "afterwards\n",
      ">>> afterwards\n",
      "everyone\n",
      ">>> everyones\n",
      "against\n",
      ">>> againsts\n",
      "everything\n",
      ">>> everythung\n",
      ">>> everything\n",
      "everywhere\n",
      ">>> everywhere\n",
      "aged\n",
      "ago\n",
      ">>> ago\n",
      ">>> agota\n",
      "exactly\n",
      "exam\n",
      ">>> examing\n",
      ">>> exams\n",
      ">>> examed\n",
      ">>> exammed\n",
      "examination\n",
      ">>> examinatio\n",
      "excellent\n",
      ">>> excellente\n",
      "except\n",
      ">>> excepted\n",
      ">>> excepts\n",
      ">>> excepting\n",
      "exercise\n",
      ">>> exercising\n",
      ">>> exercised\n",
      ">>> exercises\n",
      "exit\n",
      ">>> exitting\n",
      ">>> exiting\n",
      ">>> exited\n",
      ">>> exits\n",
      "explain\n",
      ">>> explains\n",
      ">>> explainest\n",
      ">>> explainer\n",
      ">>> explaining\n",
      ">>> explained\n",
      "extra\n",
      ">>> extra bed\n",
      ">>> extras\n",
      "fact\n",
      ">>> facting\n",
      ">>> facted\n",
      ">>> facts\n",
      "fail\n",
      ">>> failling\n",
      ">>> failest\n",
      ">>> fails\n",
      ">>> failing\n",
      ">>> failed\n",
      "fair\n",
      ">>> fairest\n",
      ">>> fairer\n",
      ">>> fair\n",
      ">>> faired\n",
      ">>> fairing\n",
      ">>> fairs\n",
      ">>> fairi\n",
      "fall\n",
      ">>> fallest\n",
      ">>> fell\n",
      ">>> fallling\n",
      ">>> falls\n",
      ">>> falling\n",
      ">>> fallen\n",
      "agree\n",
      ">>> agreeing\n",
      ">>> agreed\n",
      ">>> agrees\n",
      "air\n",
      ">>> airi\n",
      ">>> aird\n",
      ">>> aired\n",
      ">>> airin\n",
      ">>> airs\n",
      ">>> airing\n",
      "airport\n",
      ">>> airports\n",
      "fan\n",
      ">>> fanning\n",
      ">>> fans\n",
      ">>> faner\n",
      ">>> fannest\n",
      ">>> faned\n",
      ">>> fanned\n",
      "fantastic\n",
      ">>> fantastics\n",
      "far\n",
      ">>> farer\n",
      ">>> farther\n",
      ">>> farring\n",
      ">>> farthest\n",
      ">>> furthest\n",
      ">>> further\n",
      ">>> fars\n",
      "farmer\n",
      ">>> farmers\n",
      "fashion\n",
      ">>> fashioned\n",
      ">>> fashions\n",
      ">>> fashioning\n",
      "quite\n",
      "alarm\n",
      ">>> alarming\n",
      ">>> alarmed\n",
      ">>> alarmling\n",
      ">>> alarms\n",
      "album\n",
      ">>> albums\n",
      "alcohol\n",
      ">>> alcohols\n",
      "almost\n",
      "alone\n",
      ">>> aloner\n",
      "field\n",
      ">>> fielding\n",
      ">>> fields\n",
      ">>> fielded\n",
      ">>> fielder\n",
      ">>> field\n",
      "fifth\n",
      ">>> fifths\n",
      "fifty\n",
      ">>> fiftys\n",
      "file\n",
      ">>> fild\n",
      ">>> files\n",
      ">>> file\n",
      ">>> filing\n",
      ">>> filed\n",
      "fill\n",
      ">>> fillling\n",
      ">>> filling\n",
      ">>> filled\n",
      ">>> fills\n",
      ">>> fillled\n",
      ">>> fillest\n",
      "final\n",
      ">>> finals\n",
      "finally\n",
      "finger\n",
      ">>> fingers\n",
      ">>> fingered\n",
      ">>> fingering\n",
      "fire\n",
      ">>> fireing\n",
      ">>> firest\n",
      ">>> fired\n",
      ">>> fires\n",
      ">>> firebed\n",
      ">>> firing\n",
      "fishing\n",
      ">>> fishings\n",
      "fit\n",
      ">>> fitter\n",
      ">>> fiting\n",
      ">>> fited\n",
      ">>> fits\n",
      ">>> fitting\n",
      ">>> fitted\n",
      ">>> fittest\n",
      "flight\n",
      ">>> flights\n",
      ">>> flighting\n",
      ">>> flighter\n",
      ">>> flighted\n",
      ">>> flightin\n",
      "along\n",
      ">>> alonger\n",
      ">>> alongs\n",
      ">>> alonged\n",
      "bedroom\n",
      ">>> bedroomed\n",
      ">>> bedrooms\n",
      "beer\n",
      ">>> beers\n",
      ">>> beeri\n",
      ">>> beered\n",
      "before\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> befores\n",
      "begin\n",
      ">>> begins\n",
      ">>> began\n",
      ">>> beginning\n",
      ">>> beginer\n",
      ">>> begining\n",
      ">>> beginnest\n",
      ">>> begun\n",
      ">>> begin\n",
      "behind\n",
      ">>> behinds\n",
      "below\n",
      ">>> below\n",
      ">>> belowed\n",
      ">>> belows\n",
      "best\n",
      ">>> bester\n",
      ">>> bests\n",
      ">>> best best\n",
      ">>> besting\n",
      ">>> bestest\n",
      ">>> bested\n",
      "synchrophasotron\n",
      "synchrophasotron  is not in db\n"
     ]
    }
   ],
   "source": [
    "en_fr_wv = parse_from_yandex_lookup_vs_wordforms(\"./y_lookup/en_fr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fr_wv.to_csv(\"yandex_lookup_en_fr_with_wordforms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 676, 676, 676)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word), len(local_word), len(examples), len(examples_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for</td>\n",
       "      <td>для</td>\n",
       "      <td>[for the bank, for last month, for one year, f...</td>\n",
       "      <td>[для банка, за последний месяц, на один год, н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>ради</td>\n",
       "      <td>[for god]</td>\n",
       "      <td>[ради бога]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>в течение</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for</td>\n",
       "      <td>в отношении</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for</td>\n",
       "      <td>для целей</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word   local_word                                           examples  \\\n",
       "0  for          для  [for the bank, for last month, for one year, f...   \n",
       "1  for         ради                                          [for god]   \n",
       "2  for    в течение                                                 []   \n",
       "3  for  в отношении                                                 []   \n",
       "4  for    для целей                                                 []   \n",
       "\n",
       "                                      local_examples  \n",
       "0  [для банка, за последний месяц, на один год, н...  \n",
       "1                                        [ради бога]  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enru = parse_from_yandex_lookup(\"./y_lookup/en_ru/\")\n",
    "enru.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for</td>\n",
       "      <td>pour</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cafe</td>\n",
       "      <td>café</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>follow</td>\n",
       "      <td>suivre</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>follow</td>\n",
       "      <td>suivi</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>follow</td>\n",
       "      <td>ensuit</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word local_word examples local_examples\n",
       "0     for       pour       []             []\n",
       "1    cafe       café       []             []\n",
       "2  follow     suivre       []             []\n",
       "3  follow      suivi       []             []\n",
       "4  follow     ensuit       []             []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enfr = parse_from_yandex_lookup(\"./y_lookup/en_fr/\")\n",
    "enfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru.to_csv(\"yandex_lookup_en_ru_lemmas_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfr.to_csv(\"yandex_lookup_en_fr_lemmas_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translate': 'écrous et boulons'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_y = \"http://192.168.122.13:31436/GetTranslate\"\n",
    "h_y = {\"apiVersion\": \"1.0.0\", \"text\": \"гайки и болты\", \"langPair\": {\"source\": \"ru\", \"target\": \"fr\"}}\n",
    "#h_y = {\"apiVersion\": \"1.0.0\", \"text\": \"Landing to the mars\", \"langPair\": \"en-ru\"}\n",
    "r = requests.post(url = url_y, json=h_y)\n",
    "data = r.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salut, connard.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def y_translate(text, from_lang, to_lang):\n",
    "    url_y = \"http://192.168.122.13:31436/GetTranslate\"\n",
    "    h_y = {\"apiVersion\": \"1.0.0\", \"text\": text, \"langPair\": {\"source\": from_lang, \"target\": to_lang}}\n",
    "    r = requests.post(url = url_y, json=h_y)\n",
    "    data = r.json()\n",
    "    return data['translate']\n",
    "y_translate(\"привет уеба\", \"ru\", \"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "enru_small = parse_from_yandex_lookup(\"./y_lookup/small/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1318/1318 [18:23<00:00,  1.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "      <td>mot</td>\n",
       "      <td>[last word, old english word, new word in art,...</td>\n",
       "      <td>[dernier mot, le vieux mot anglais, nouveau mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word</td>\n",
       "      <td>nouvelle</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word</td>\n",
       "      <td>mot</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word</td>\n",
       "      <td>dire</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word</td>\n",
       "      <td>formuler</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word local_word                                           examples  \\\n",
       "0  word        mot  [last word, old english word, new word in art,...   \n",
       "1  word   nouvelle                                                 []   \n",
       "2  word        mot                                                 []   \n",
       "3  word       dire                                                 []   \n",
       "4  word   formuler                                                 []   \n",
       "\n",
       "                                      local_examples  \n",
       "0  [dernier mot, le vieux mot anglais, nouveau mo...  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def naive_translation(en_ru_dataframe, from_lang,to_lang):\n",
    "    word = []\n",
    "    local_word = []\n",
    "    example = []\n",
    "    local_example = []\n",
    "    for element_ind in tqdm(range(len(en_ru_dataframe))):\n",
    "        el_list = list(en_ru_dataframe.iloc[element_ind])\n",
    "        #print(el_list)\n",
    "        word.append(el_list[0])\n",
    "        tr_local_word = y_translate(el_list[1],from_lang,to_lang)\n",
    "        local_word.append(tr_local_word)\n",
    "        ex = []\n",
    "        loc_ex = []\n",
    "        for example_i in el_list[2]:\n",
    "            ex.append(example_i)\n",
    "            ex_tr = y_translate(example_i,\"en\",to_lang)\n",
    "            loc_ex.append(ex_tr)\n",
    "        example.append(ex)\n",
    "        local_example.append(loc_ex)\n",
    "    \n",
    "    data = pd.DataFrame(list(zip(word,local_word,example, local_example)),columns =['word', 'local_word', 'examples','local_examples'])\n",
    "    return data\n",
    "\n",
    "df = naive_translation(enru_wv,\"ru\",\"fr\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"naive_transaltion_en_ru_fr_with_wordfroms.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
