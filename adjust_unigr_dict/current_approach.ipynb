{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import psycopg2\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import copy\n",
    "\n",
    "url = \"https://dictionary.yandex.net/api/v1/dicservice.json/lookup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordforms_list = []\n",
    "for file in os.listdir(\"/Users/nigula/LL/adjust_unigr_dict/wordforms/wf_eng\"):\n",
    "    if \"json\" in file:\n",
    "        with open(os.path.join(\"/Users/nigula/LL/adjust_unigr_dict/wordforms/wf_eng\", file), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            for en_ref_word in data.keys():\n",
    "                #print(data[en_ref_word])\n",
    "                wordforms_list.extend(data[en_ref_word])\n",
    "                #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38188"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordforms_list.index(\"sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['youthful',\n",
       " 'youthfully',\n",
       " 'youthfulnesses',\n",
       " 'lesions',\n",
       " 'prototypic',\n",
       " 'prototypical',\n",
       " 'prototypes',\n",
       " 'prototypal',\n",
       " 'ruefully',\n",
       " 'ruefulness']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordforms_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordforms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file.split(\".\")[0] for file in os.listdir(\"/Users/nigula/LL/adjust_unigr_dict/lookup/reverso_en_ru\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set(wordforms_list) - set(files)\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)  получаем lookup от исходного языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_token_dict = {\n",
    " \"vertolet_token\" : \"dict.1.1.20191029T212638Z.e3a6524ff15de8ee.53dbf57d908343531709c5f0686045121f0fc6ae\",\n",
    "   \"bbk_token\" : \"dict.1.1.20190828T215834Z.0d8a3da5e08df3a0.85290ff28457230b81cb3b73720d2a0312ca14dc\", \n",
    "\"vasya_2019\" : \"dict.1.1.20191029T212638Z.e3a6524ff15de8ee.53dbf57d908343531709c5f0686045121f0fc6ae\",\n",
    "\"vasya_2011\" : \"dict.1.1.20191105T083743Z.8b9cdebb9755fa57.e42afa31c184e2ced2305b5452809e17bc19c920\",\n",
    "\"fanyi0\" : \"dict.1.1.20191105T095108Z.82f72da803eeedc2.ada6293a0591bed0222d3a8045bd722915f025bb\",\n",
    "\"fanyi00\" : \"dict.1.1.20191105T103102Z.3e0f76aef01d786a.92fea3781473b7c432aa49ee1f3879cb95181a63\",\n",
    "\"prvd0\" : \"dict.1.1.20191105T103348Z.960e0892b02b628b.5746d7d95af92a16d15941b24410707bbb7568c4\",\n",
    "\"prvd00\" : \"dict.1.1.20191105T105231Z.520f147163f275cd.f329913de7b0a719762e89ef84914cbe8c3f3d25\",\n",
    "\"prvdfin0\": \"dict.1.1.20191105T105704Z.a6f94da915862b61.76003fa911b16bbad05aa655d5be9ea1f78b3e1c\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_handled_words(directory_with_handled_files):\n",
    "    handled_words_from_folder = []\n",
    "    for word in os.listdir(directory_with_handled_files):\n",
    "        #print(word.split('.')[0])\n",
    "        handled_words_from_folder.append(word.split('.')[0])\n",
    "    handled_words_from_folder = set(handled_words_from_folder)\n",
    "    #print(check_word, \"word_in\", check_word in handled_words_from_folder)\n",
    "    #print(\"akready_handled_from_directory\", len(handled_words_from_folder))\n",
    "    return handled_words_from_folder\n",
    "\n",
    "a = get_handled_words(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request_func(from_lang,to_lang, word, header_main, login, en_from_lang, en_to_lang):\n",
    "    start = time.time()\n",
    "    url = \"https://context.reverso.net/перевод/\" + from_lang + \"-\" + to_lang + \"/\" + word \n",
    "#     print(\"going to find word in\", url)\n",
    "    response = requests.get(url, headers=header_main, data = login)\n",
    "    response.encoding = 'utf-8' \n",
    "    #\n",
    "    save_dir = os.path.join(\"/Users/nigula/LL/adjust_unigr_dict/lookup/reverso\" + \"_\" + en_from_lang + \"_\" + en_to_lang,word + \".xls\")\n",
    "    file = open(save_dir, \"wb\")\n",
    "    file.write(response.content)\n",
    "    file.close()\n",
    "#     print(\"saved to directory\", save_dir)\n",
    "    soup = bs(response.text, 'html.parser') \n",
    "    time.sleep(0.01)\n",
    "#     print(\"request_time\",time.time() - start) \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definitions_reverso(word, from_lang, to_lang, print_output = False):\n",
    "    pos_dict = {\"adv\":\"adverb\",\"adj\":\"adjective\",\"n\":\"noun\",'':'',\"nm\":\"noun\",\"nf\":\"noun\",\"v\":\"verb\",\"nn\":\"noun\",\n",
    "               \"adj/nm\":\"adjective\",\"nfpl\":\"noun\",\"conj\":\"conjunction\",\"pron\":\"pronoun\",'adj/adv':'adjective',\n",
    "               \"nmpl\":\"noun\"}\n",
    "    start = time.time()\n",
    "    login = {'inUserName': 'n.babakov@lingualeo.com', 'inUserPass': '33vec33'}\n",
    "    header_main = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    senseword_list = {\"def\":{\"tr\":[]}}\n",
    "    land_dict = {\"русский\":\"ru\",\"французский\":\"fr\", \"английский\":\"en\"}\n",
    "    found_saved = True\n",
    "    try:\n",
    "        word_dir = os.path.join(\"/Users/nigula/LL/adjust_unigr_dict/lookup/reverso\" + \"_\" + land_dict[from_lang] + \"_\" + land_dict[to_lang],word + \".xls\")\n",
    "        infile = open(word_dir,\"r\")\n",
    "#         print(\"found_word_in\", word_dir)\n",
    "        contents = infile.read()\n",
    "        soup = bs(contents,'html.parser')\n",
    "    except:\n",
    "        soup = send_request_func(from_lang,to_lang, word, header_main, login, land_dict[from_lang], land_dict[to_lang])\n",
    "        found_saved = False\n",
    "    #print(soup.prettify())\n",
    "    first_string_passed = False\n",
    "    pos = ''\n",
    "    for link in soup.find_all(\"a\", attrs={\"class\" : \"translation\"}):\n",
    "        #print(link.prettify())\n",
    "        try:\n",
    "            #print(\"||\",link['data-pos'])\n",
    "            pos = link['data-pos'][1:-1]\n",
    "        except:\n",
    "            pass\n",
    "        if first_string_passed == True:\n",
    "            sence_word = link.text.strip()\n",
    "            if len(sence_word) >0:\n",
    "                if pos not in pos_dict:\n",
    "                    senseword_list[\"def\"]['tr'].append({\"text\":sence_word.lower(), \"pos\":''})\n",
    "                else:\n",
    "                    senseword_list[\"def\"]['tr'].append({\"text\":sence_word.lower(), \"pos\":pos_dict[pos]})\n",
    "            #print(sence_word)\n",
    "        first_string_passed = True\n",
    "        \n",
    "    for link in soup.find_all(\"div\", attrs={\"class\" : \"translation\"}):\n",
    "        #print(link.prettify())\n",
    "        try:\n",
    "            #print(\"||\",link['data-pos'])\n",
    "            pos = link['data-pos'][1:-1]\n",
    "        except:\n",
    "            pass\n",
    "        if first_string_passed == True:\n",
    "            sence_word = link.text.strip()\n",
    "            if len(sence_word) >0:\n",
    "                if pos not in pos_dict:\n",
    "                    senseword_list[\"def\"]['tr'].append({\"text\":sence_word.lower(), \"pos\":''})\n",
    "                else:\n",
    "                    senseword_list[\"def\"]['tr'].append({\"text\":sence_word.lower(), \"pos\":pos_dict[pos]})\n",
    "            #print(sence_word)\n",
    "        first_string_passed = True\n",
    "    if len (senseword_list) == 0:\n",
    "        print(\"turn to alternative marks\")\n",
    "        for link in soup.find_all(\"div\", attrs={\"lang\" : \"fr\"}):\n",
    "            try:\n",
    "                #print(\"||\",link['data-pos'])\n",
    "                pos = link['data-pos'][1:-1]\n",
    "            except:\n",
    "                pass\n",
    "            sence_word = link.text.strip()\n",
    "            senseword_list[\"def\"]['tr'].append({\"text\":sence_word.lower(), \"pos\":pos})\n",
    "            #print(link.prettify())\n",
    "#     print(\"definiotns_time\", time.time() - start)\n",
    "    return senseword_list, found_saved\n",
    "\n",
    "\n",
    "get_definitions_reverso(\"Extra\", \"английский\", \"русский\", print_output = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_lookup_json(from_lang_words_list, from_lang, to_lang, token_dict, directory_with_handled_files):\n",
    "    tokens_names_list = []\n",
    "    tokens_list = []\n",
    "    for token_name, token in token_dict.items():\n",
    "        tokens_names_list.append(token_name)\n",
    "        tokens_list.append(token)\n",
    "    token_index = 0 \n",
    "    not_handled_words_list = []\n",
    "    \n",
    "    #save_folder = \"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_fr_en_2\"\n",
    "    save_folder = directory_with_handled_files\n",
    "   \n",
    "    handled_words_from_folder = get_handled_words(directory_with_handled_files)\n",
    "    handled_words_from_folder = set(handled_words_from_folder)\n",
    "    handled_words_from_folder_2 = get_handled_words(save_folder)\n",
    "    handled_words_from_folder_2 = set(handled_words_from_folder_2)\n",
    "    handled_words_from_folder = handled_words_from_folder.union(handled_words_from_folder_2)\n",
    "    print(\"handled_all_words\", len(handled_words_from_folder))\n",
    "\n",
    "    count = 0 \n",
    "    print(\"going_to_use token\", tokens_names_list[token_index])\n",
    "    skipped_words_count = 0\n",
    "    handled_words_count = 0\n",
    "    offline_handled_reverso = 0\n",
    "    must_request_reverso = 0\n",
    "    for fr_word in tqdm(from_lang_words_list):\n",
    "        #print(fr_word)\n",
    "        isnan = False\n",
    "        #print(count, start_from_count)\n",
    "        try:\n",
    "            isnan = math.isnan(fr_word)\n",
    "        except:\n",
    "            pass\n",
    "        #print(fr_word != \"no_equality\", isnan == False , fr_word not in handled_words_from_folder)\n",
    "        if fr_word != \"no_equality\" and isnan == False and fr_word not in handled_words_from_folder:\n",
    "            lang_pair = from_lang + \"-\" + to_lang\n",
    "            headers = {\"key\":tokens_list[token_index],\n",
    "                  \"lang\":lang_pair,\"text\":fr_word}\n",
    "            ddd = requests.get(url, headers).json()\n",
    "            if 'def' in ddd:\n",
    "                if len(ddd['def']) == 0 or len (ddd['def']['tr']==0):\n",
    "                    #print(\"go_to_reverso\")\n",
    "                    land_dict = {\"ru\":\"русский\",\"fr\":\"французский\", \"en\":\"английский\"}\n",
    "                    ddd, found_in_folder = get_definitions_reverso(fr_word,land_dict[from_lang],  land_dict[to_lang])\n",
    "            else:\n",
    "                land_dict = {\"ru\":\"русский\",\"fr\":\"французский\", \"en\":\"английский\"}\n",
    "                ddd, found_in_folder = get_definitions_reverso(fr_word,land_dict[from_lang],  land_dict[to_lang])\n",
    "            if 'message' in ddd and ddd['message'] == \"Limit of daily requests exceeded\":\n",
    "                token_index += 1\n",
    "                print(\"LIMIT REACHED, switch to token\",tokens_names_list[token_index] )\n",
    "                not_handled_words_list.append(fr_word)\n",
    "            try:\n",
    "                save_loc = os.path.join(save_folder, fr_word + \".json\")\n",
    "            except:\n",
    "                print(fr_word, \"is ambigious float or smth\")\n",
    "                continue\n",
    "            try:\n",
    "                with open(save_loc, 'w') as f:\n",
    "                    json.dump(ddd, f, indent = 4, ensure_ascii=False)\n",
    "                    #print(\"saved at \", save_loc)\n",
    "            except Exception as E:\n",
    "                print(fr_word, E)\n",
    "            #time.sleep(0.0001)\n",
    "            handled_words_count += 1\n",
    "            if found_in_folder == True:\n",
    "                offline_handled_reverso += 1\n",
    "            else:\n",
    "                must_request_reverso += 1\n",
    "        else:\n",
    "            skipped_words_count += 1\n",
    "            #print(fr_word, \"===>>>>skipped\")\n",
    "            pass\n",
    "            \n",
    "        count += 1\n",
    "        if count %5000 == 0:\n",
    "            handled_words_from_folder = get_handled_words(directory_with_handled_files)\n",
    "            handled_words_from_folder = set(handled_words_from_folder)\n",
    "            handled_words_from_folder_2 = get_handled_words(save_folder)\n",
    "            handled_words_from_folder_2 = set(handled_words_from_folder_2)\n",
    "            handled_words_from_folder = handled_words_from_folder.union(handled_words_from_folder_2)\n",
    "            print(\"offline_handled_reverso\", offline_handled_reverso,\"must_request_reverso\",must_request_reverso )\n",
    "            print(\"handled_words_from_folder\", len(handled_words_from_folder))\n",
    "            print(handled_words_count, \"words handled\", skipped_words_count, \"words skipped\\n\",)     \n",
    "    return not_handled_words_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordforms_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "handled = \"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru_wordforms/\"\n",
    "#from_ind = 500 + 689 + 229 + 3467 + 425 + 11717 + 72554\n",
    "from_ind = 0\n",
    "to_ind = len(wordforms_list)\n",
    "not_handled_words = get_y_lookup_json(wordforms_list[from_ind:to_ind], \"en\", \"ru\", big_token_dict,\n",
    "                  directory_with_handled_files = handled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " len(os.listdir(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru_wordforms/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handled = \"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_fr_en\"\n",
    "#from_ind = 1480+382+133+1858+15\n",
    "#to_ind = 25000\n",
    "from_ind = 0\n",
    "to_ind = len(words_to_be_handled)\n",
    "not_handled_words = get_y_lookup_json(words_to_be_handled[from_ind:to_ind], \"fr\", \"en\", small_token_dict,\n",
    "                  directory_with_handled_files = han dled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) объединяем сохраненные файлы в csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "next_iter\n",
      "1\n",
      "next_iter\n",
      "2\n",
      "next_iter\n",
      "3\n",
      "next_iter\n",
      "skip_this_iter\n",
      "5\n",
      "next_iter\n",
      "6\n",
      "next_iter\n",
      "7\n",
      "next_iter\n",
      "8\n",
      "next_iter\n",
      "9\n",
      "next_iter\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i == 4: \n",
    "        print(\"skip_this_iter\")\n",
    "        continue\n",
    "        \n",
    "    print(i)\n",
    "    print(\"next_iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_from_yandex_lookup(directory, print_output = False, necessary_words_list = None):\n",
    "    word = []\n",
    "    local_word = []\n",
    "    pos_list = []\n",
    "    examples = []\n",
    "    examples_local = []\n",
    "    words_from_not_handled_count = 0 \n",
    "    empty = 0\n",
    "    skipped_words = 0\n",
    "    for file in tqdm(os.listdir(directory)):\n",
    "        if print_output == True: print(file)\n",
    "        current_word = file.split(\".\")[0]\n",
    "        \n",
    "        if \"DS_Store\" not in file:\n",
    "            if necessary_words_list != None:\n",
    "                curr_handled_word = file.split(\".\")[0]\n",
    "                if curr_handled_word not in necessary_words_list:\n",
    "                    skipped_words += 1\n",
    "                    continue\n",
    "            try:\n",
    "                f = open(os.path.join(directory,file), \"r\", encoding='utf-8')\n",
    "            except:\n",
    "                f = open(os.path.join(directory,file), \"r\")\n",
    "            try:\n",
    "                data = json.load(f, encoding = 'utf-8')\n",
    "            except:\n",
    "                data = json.load(f)\n",
    "            if print_output == True:print(data)\n",
    "            if \"head\" in data:\n",
    "                if print_output == True:print(\"YANDEX\")\n",
    "                for definition in data['def']:\n",
    "#                     print(definition)\n",
    "                    word_current =  definition['text'] \n",
    "                    if 'pos' in definition:\n",
    "                        global_pos = definition['pos']\n",
    "                    else:\n",
    "                        global_pos = 'no_pos_available'\n",
    "                    for translation in definition['tr']: \n",
    "                        if 'pos' in translation:\n",
    "                            pos = translation['pos']\n",
    "                        else:\n",
    "                            pos = global_pos\n",
    "                        if print_output == True:print(pos, word_current, translation['text'])\n",
    "                        pos_list.append(pos)\n",
    "                        word.append(word_current)\n",
    "                        local_word.append(translation['text'])\n",
    "                        ex_en = []\n",
    "                        ex_rus = []\n",
    "#                         if 'ex' in translation:\n",
    "#                             for exmpl in translation['ex']:\n",
    "#                                 #print(exmpl)\n",
    "#                                 ex_en.append(exmpl['text'])\n",
    "#                                 ex_rus.append(exmpl['tr'][0]['text'])\n",
    "#                         examples.append(ex_en)\n",
    "#                         examples_local.append(ex_rus)\n",
    "                if len(data['def']) == 0:\n",
    "                    empty += 1\n",
    "            else:\n",
    "                if print_output == True:print(\"CONTEXT_REVERSO\")\n",
    "                word_current = file.split(\".\")[0]\n",
    "                for definition in data['def'].values():\n",
    "                    for translation in definition:\n",
    "                        if translation['pos'] == '':\n",
    "                            pos = 'no_pos_available'\n",
    "                        else:\n",
    "                            pos = translation['pos']\n",
    "                        if print_output == True:print(pos, word_current, translation['text'])\n",
    "                        pos_list.append(pos)\n",
    "                        word.append(word_current)\n",
    "                        local_word.append(translation['text'])\n",
    "                        \n",
    "            words_from_not_handled_count += 1\n",
    "    print(\"empty json\", empty)\n",
    "    print(\"non_handled_basic_language__words_added_to_dataframe\", words_from_not_handled_count)\n",
    "    print(skipped_words,\"skipped_words\")\n",
    "    data = pd.DataFrame(list(zip(word,local_word,pos_list)),columns =['word', 'local_word', 'pos'])\n",
    "    return  data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,3]\n",
    "typle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "handled_eng_wods = set(df['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42781, 63657)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['word'])), len(os.listdir(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru_wordforms/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92e170626de438daaa085d5c6b23f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63657), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty json 0\n",
      "non_handled_basic_language__words_added_to_dataframe 63654\n",
      "2 skipped_words\n"
     ]
    }
   ],
   "source": [
    "df = parse_from_yandex_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru_wordforms/\",\n",
    "                             print_output = False, necessary_words_list = wordforms_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>longs</td>\n",
       "      <td>жаждет</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>longs</td>\n",
       "      <td>тоскует</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>longs</td>\n",
       "      <td>мечтает</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longs</td>\n",
       "      <td>страстно желает</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instilments</td>\n",
       "      <td>частями</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word       local_word               pos\n",
       "0        longs           жаждет  no_pos_available\n",
       "1        longs          тоскует  no_pos_available\n",
       "2        longs          мечтает  no_pos_available\n",
       "3        longs  страстно желает  no_pos_available\n",
       "4  instilments          частями  no_pos_available"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thermodynamicss',\n",
       " 'fording',\n",
       " 'painfully',\n",
       " 'timorously',\n",
       " 'accordance',\n",
       " 'alternative',\n",
       " 'nastiness',\n",
       " 'condolent',\n",
       " 'emotions',\n",
       " 'melody',\n",
       " 'bestows',\n",
       " 'balconies',\n",
       " 'nests',\n",
       " 'gnashing',\n",
       " 'quarantines',\n",
       " 'sighted',\n",
       " 'mysticism',\n",
       " 'mittens',\n",
       " 'cranes',\n",
       " 'repetitiveness',\n",
       " 'lengthiness',\n",
       " 'pom-poms',\n",
       " 'grandness',\n",
       " 'namelessness',\n",
       " 'throw',\n",
       " 'chicnesses',\n",
       " 'Windowss',\n",
       " 'cuticula',\n",
       " 'overlay',\n",
       " 'surcharges',\n",
       " 'outfighting',\n",
       " 'explode',\n",
       " 'hyperbolic',\n",
       " 'artless',\n",
       " 'literally',\n",
       " 'tender',\n",
       " 'banker',\n",
       " 'dibss',\n",
       " 'hooter',\n",
       " 'antagonist',\n",
       " 'ellipticity',\n",
       " 'submerse',\n",
       " 'exonerate',\n",
       " 'progress',\n",
       " 'mineralized',\n",
       " 'ratified',\n",
       " 'dramatized',\n",
       " 'shone',\n",
       " 'cashed',\n",
       " 'splicer',\n",
       " 'auricles',\n",
       " 'vibrates',\n",
       " 'antiquity',\n",
       " 'circumferential',\n",
       " 'conscripted',\n",
       " 'hierarchies',\n",
       " 'criminally',\n",
       " 'espousal',\n",
       " 'dissected',\n",
       " 'harpist',\n",
       " 'regent',\n",
       " 'foaming',\n",
       " 'hatter',\n",
       " 'crunches',\n",
       " 'disposes',\n",
       " 'smartness',\n",
       " 'royalty',\n",
       " 'glycerines',\n",
       " 'parolee',\n",
       " 'venoms',\n",
       " 'domiciled',\n",
       " 'witnesses',\n",
       " 'fictions',\n",
       " 'fellowships',\n",
       " 'budgetary',\n",
       " 'encounters',\n",
       " 'orifices',\n",
       " 'remembrance',\n",
       " 'demigods',\n",
       " 'murines',\n",
       " 'nixing',\n",
       " 'immensity',\n",
       " 'polymer',\n",
       " 'honied',\n",
       " 'abstractly',\n",
       " 'grapy',\n",
       " 'jesters',\n",
       " 'appendectomies',\n",
       " 'metastasized',\n",
       " 'middles',\n",
       " 'backers',\n",
       " 'psychos',\n",
       " 'level',\n",
       " 'correctional',\n",
       " 'postponers',\n",
       " 'bossy',\n",
       " 'delays',\n",
       " 'telcoes',\n",
       " 'pasturing',\n",
       " 'nosy',\n",
       " 'regattas',\n",
       " 'soberly',\n",
       " 'dependably',\n",
       " 'ferromagnetic',\n",
       " 'spouses',\n",
       " 'watchwords',\n",
       " 'intubating',\n",
       " 'atonally',\n",
       " 'beautifying',\n",
       " 'aimless',\n",
       " 'revises',\n",
       " 'humbleness',\n",
       " 'frequency_band',\n",
       " 'acceptors',\n",
       " 'vindicating',\n",
       " 'shakes',\n",
       " 'sitting',\n",
       " 'medication',\n",
       " 'Kamas',\n",
       " 'timeliness',\n",
       " 'itch',\n",
       " 'Dalmatians',\n",
       " 'stink',\n",
       " 'snorters',\n",
       " 'microelectronics',\n",
       " 'murdering',\n",
       " 'newscasts',\n",
       " 'guarded',\n",
       " 'shooting',\n",
       " 'succulence',\n",
       " 'legatees',\n",
       " 'Haywoods',\n",
       " 'murdered',\n",
       " 'problematically',\n",
       " 'addresses',\n",
       " 'herb',\n",
       " 'merciless',\n",
       " 'squats',\n",
       " 'decorated',\n",
       " 'intensities',\n",
       " 'adverted',\n",
       " 'localize',\n",
       " 'rulers',\n",
       " 'pathogenic',\n",
       " 'medically',\n",
       " 'Polluxes',\n",
       " 'Isfahans',\n",
       " 'essentials',\n",
       " 'inclusive',\n",
       " 'steroidal',\n",
       " 'retrieving',\n",
       " 'bathes',\n",
       " 'Prometheuses',\n",
       " 'dishonorably',\n",
       " 'commandments',\n",
       " 'husks',\n",
       " 'Liechtensteiner',\n",
       " 'dusky',\n",
       " 'leviathans',\n",
       " 'insomniacs',\n",
       " 'rehabilitative',\n",
       " 'contrived',\n",
       " 'Angola',\n",
       " 'invariant',\n",
       " 'pediatricss',\n",
       " 'refinement',\n",
       " 'migrated',\n",
       " 'lunged',\n",
       " 'Valentines',\n",
       " 'miracle',\n",
       " 'prospectors',\n",
       " 'Dalmatia',\n",
       " 'mountainous',\n",
       " 'pediatrician',\n",
       " 'Lombardias',\n",
       " 'Mauritius',\n",
       " 'slandering',\n",
       " 'thistles',\n",
       " 'Salvadorean',\n",
       " 'conferee',\n",
       " 'Duns',\n",
       " 'precipitator',\n",
       " 'reproachers',\n",
       " 'vexed',\n",
       " 'inflamings',\n",
       " 'damns',\n",
       " 'Belarus',\n",
       " 'ova',\n",
       " 'acquaintanceship',\n",
       " 'congress',\n",
       " 'athlete',\n",
       " 'cold-bloodedly',\n",
       " 'lends',\n",
       " 'Svalbards',\n",
       " 'deify',\n",
       " 'cybercafes',\n",
       " 'positivism',\n",
       " 'appointments',\n",
       " 'techniques',\n",
       " 'differentiate',\n",
       " 'embank',\n",
       " 'prevent',\n",
       " 'blockheads',\n",
       " 'nutrients',\n",
       " 'Philistias',\n",
       " 'cross',\n",
       " 'usually',\n",
       " 'minimalist',\n",
       " 'perchlorates',\n",
       " 'cheerfulness',\n",
       " 'prophetical',\n",
       " 'Glaswegian',\n",
       " 'Rhenishes',\n",
       " 'opposition',\n",
       " 'frantic',\n",
       " 'directs',\n",
       " 'quarterbacks',\n",
       " 'advertence',\n",
       " 'allergenic',\n",
       " 'alarm',\n",
       " 'bookishness',\n",
       " 'betrayer',\n",
       " 'glaciers',\n",
       " 'sultriness',\n",
       " 'granite',\n",
       " 'transplantation',\n",
       " 'conversely',\n",
       " 'Californians',\n",
       " 'inquests',\n",
       " 'ideologic',\n",
       " 'eccentricity',\n",
       " 'converging',\n",
       " 'matters',\n",
       " 'saxophones',\n",
       " 'ostriches',\n",
       " 'newsrooms',\n",
       " 'heterology',\n",
       " 'bailee',\n",
       " 'despotical',\n",
       " 'endeavouring',\n",
       " 'borrows',\n",
       " 'editing',\n",
       " 'bannocks',\n",
       " 'stresses',\n",
       " 'salts',\n",
       " 'pontifex',\n",
       " 'accrual',\n",
       " 'dual',\n",
       " 'depilate',\n",
       " 'CRTS',\n",
       " 'merry',\n",
       " 'terse',\n",
       " 'grade',\n",
       " 'payee',\n",
       " 'lexis',\n",
       " 'preservation',\n",
       " 'supplementary',\n",
       " 'gravels',\n",
       " 'respectable',\n",
       " 'fables',\n",
       " 'slobberer',\n",
       " 'harems',\n",
       " 'drooping',\n",
       " 'flirted',\n",
       " 'headboards',\n",
       " 'functionalities',\n",
       " 'gratify',\n",
       " 'mechanical',\n",
       " 'snows',\n",
       " 'epiphanies',\n",
       " 'relays',\n",
       " 'swatches',\n",
       " 'quarrels',\n",
       " 'sailors',\n",
       " 'lurkers',\n",
       " 'implies',\n",
       " 'attics',\n",
       " 'prunes',\n",
       " 'repayments',\n",
       " 'destroyer',\n",
       " 'fears',\n",
       " 'dampeners',\n",
       " 'grubbily',\n",
       " 'expires',\n",
       " 'twiners',\n",
       " 'straggle',\n",
       " 'sodomites',\n",
       " 'proprietorships',\n",
       " 'concocting',\n",
       " 'tending',\n",
       " 'subtitles',\n",
       " 'pills',\n",
       " 'vomit',\n",
       " 'mimicked',\n",
       " 'ameliorative',\n",
       " 'pointless',\n",
       " 'Hermen',\n",
       " 'instrumentation',\n",
       " 'liquefies',\n",
       " 'gynaecology',\n",
       " 'purchase',\n",
       " 'provisions',\n",
       " 'archive',\n",
       " 'excrements',\n",
       " 'iamb',\n",
       " 'Moon',\n",
       " 'cooked',\n",
       " 'succeeds',\n",
       " 'disciples',\n",
       " 'tentacle',\n",
       " 'inquirings',\n",
       " 'reductive',\n",
       " 'passages',\n",
       " 'mistrusts',\n",
       " 'sponges',\n",
       " 'belligerence',\n",
       " 'swimmer',\n",
       " 'handovers',\n",
       " 'contaminate',\n",
       " 'Canidaes',\n",
       " 'fend',\n",
       " 'descendant',\n",
       " 'rag',\n",
       " 'principally',\n",
       " 'speared',\n",
       " 'solidly',\n",
       " 'upgrades',\n",
       " 'settings',\n",
       " 'Charlemagne',\n",
       " 'grazes',\n",
       " 'giggling',\n",
       " 'aspirers',\n",
       " 'ceases',\n",
       " 'ropy',\n",
       " 'Julius_Caesar',\n",
       " 'elderships',\n",
       " 'contending',\n",
       " 'profited',\n",
       " 'wrenches',\n",
       " 'anarchically',\n",
       " 'embalm',\n",
       " 'onlookers',\n",
       " 'outreaches',\n",
       " 'left_wing',\n",
       " 'haleness',\n",
       " 'swelling',\n",
       " 'tapeworms',\n",
       " 'folding',\n",
       " 'finisher',\n",
       " 'apparition',\n",
       " 'kudoss',\n",
       " 'transvestites',\n",
       " 'miscarry',\n",
       " 'sacred',\n",
       " 'arthropodous',\n",
       " 'enlarging',\n",
       " 'yearns',\n",
       " 'duchesses',\n",
       " 'liveness',\n",
       " 'theorisation',\n",
       " 'domiciliary',\n",
       " 'grading',\n",
       " 'coffins',\n",
       " 'arks',\n",
       " 'geriatrics',\n",
       " 'dogma',\n",
       " 'windstorms',\n",
       " 'harmonisation',\n",
       " 'spontaneous',\n",
       " 'bromate',\n",
       " 'Sudan',\n",
       " 'kitchens',\n",
       " 'Lausannes',\n",
       " 'accredit',\n",
       " 'pliers',\n",
       " 'exclude',\n",
       " 'disassembled',\n",
       " 'integrators',\n",
       " 'deputies',\n",
       " 'landed',\n",
       " 'conically',\n",
       " 'viziership',\n",
       " 'suspender',\n",
       " 'incarnate',\n",
       " 'splenic',\n",
       " 'accessed',\n",
       " 'semitrailers',\n",
       " 'excel',\n",
       " 'puttering',\n",
       " 'valence',\n",
       " 'trades',\n",
       " 'bolstered',\n",
       " 'ink',\n",
       " 'unleashes',\n",
       " 'impalpability',\n",
       " 'tariffing',\n",
       " 'misunderstood',\n",
       " 'coolly',\n",
       " 'issue',\n",
       " 'sap',\n",
       " 'regiment',\n",
       " 'alcoves',\n",
       " 'permissiveness',\n",
       " 'anaesthetize',\n",
       " 'longed',\n",
       " 'high',\n",
       " 'cropping',\n",
       " 'collation',\n",
       " 'liquidity',\n",
       " 'calling',\n",
       " 'forfeiture',\n",
       " 'complaisance',\n",
       " 'incorporation',\n",
       " 'sculpted',\n",
       " 'fix',\n",
       " 'pilfered',\n",
       " 'monstrosities',\n",
       " 'hermetic',\n",
       " 'unspeakably',\n",
       " 'motorcyclists',\n",
       " 'contentions',\n",
       " 'commercially',\n",
       " 'superstition',\n",
       " 'adversity',\n",
       " 'upholstered',\n",
       " 'womanize',\n",
       " 'accessories',\n",
       " 'hand_over',\n",
       " 'Nereuses',\n",
       " 'caloric',\n",
       " 'Kuwait',\n",
       " 'employs',\n",
       " 'denuded',\n",
       " 'appreciates',\n",
       " 'perfumed',\n",
       " 'algebraist',\n",
       " 'freezer',\n",
       " 'accommodations',\n",
       " 'curly',\n",
       " 'Woolves',\n",
       " 'Senegals',\n",
       " 'revalue',\n",
       " 'disorientation',\n",
       " 'transferred',\n",
       " 'Tyrolean',\n",
       " 'progresses',\n",
       " 'turn-ons',\n",
       " 'consumptions',\n",
       " 'adversities',\n",
       " 'sabotaging',\n",
       " 'conformation',\n",
       " 'emit',\n",
       " 'indented',\n",
       " 'cafeterias',\n",
       " 'shrubs',\n",
       " 'mud',\n",
       " 'concavity',\n",
       " 'teamsters',\n",
       " 'woodwind',\n",
       " 'restructured',\n",
       " 'digitization',\n",
       " 'dipped',\n",
       " 'ratiocinate',\n",
       " 'isolationistic',\n",
       " 'war',\n",
       " 'heated',\n",
       " 'impressiveness',\n",
       " 'enroll',\n",
       " 'perches',\n",
       " 'stereotypic',\n",
       " 'unthinking',\n",
       " 'railings',\n",
       " 'environmental',\n",
       " 'burnings',\n",
       " 'flashbacks',\n",
       " 'vehement',\n",
       " 'mates',\n",
       " 'fencings',\n",
       " 'myelinic',\n",
       " 'followers',\n",
       " 'Peters',\n",
       " 'dikes',\n",
       " 'campaigning',\n",
       " 'medina',\n",
       " 'subtractive',\n",
       " 'dingily',\n",
       " 'brutalization',\n",
       " 'prospecting',\n",
       " 'Ardenneses',\n",
       " 'steerage',\n",
       " 'approbative',\n",
       " 'senior',\n",
       " 'appeared',\n",
       " 'Gibsons',\n",
       " 'abridger',\n",
       " 'grouch',\n",
       " 'chetahs',\n",
       " 'occupation',\n",
       " 'nauseated',\n",
       " 'false',\n",
       " 'fugitives',\n",
       " 'overvaluing',\n",
       " 'edits',\n",
       " 'inflaming',\n",
       " 'resuscitator',\n",
       " 'recuperate',\n",
       " 'symphonize',\n",
       " 'curses',\n",
       " 'skier',\n",
       " 'roasted',\n",
       " 'forty-fives',\n",
       " 'wiggle',\n",
       " 'nonviolence',\n",
       " 'governorships',\n",
       " 'Roseaus',\n",
       " 'islanders',\n",
       " 'funds',\n",
       " 'regulating',\n",
       " 'Gestapoes',\n",
       " 'distributively',\n",
       " 'tragic',\n",
       " 'Medicaids',\n",
       " 'necessitating',\n",
       " 'enigma',\n",
       " 'forints',\n",
       " 'variants',\n",
       " 'connecting',\n",
       " 'dried',\n",
       " 'metastatic',\n",
       " 'incarnates',\n",
       " 'prefaced',\n",
       " 'thirsty',\n",
       " 'analogously',\n",
       " 'defamatory',\n",
       " 'reciprocity',\n",
       " 'EC',\n",
       " 'longitude',\n",
       " 'attending',\n",
       " 'appalling',\n",
       " 'conducing',\n",
       " 'interests',\n",
       " 'autocrat',\n",
       " 'Bangladesh',\n",
       " 'allocated',\n",
       " 'threshing',\n",
       " 'Hellenes',\n",
       " 'morose',\n",
       " 'triplets',\n",
       " 'morphological',\n",
       " 'athletic',\n",
       " 'befuddling',\n",
       " 'holiday',\n",
       " 'loiterer',\n",
       " 'obsessing',\n",
       " 'implicative',\n",
       " 'leaflet',\n",
       " 'lagers',\n",
       " 'methodological',\n",
       " 'feathering',\n",
       " 'Benedict',\n",
       " 'musicals',\n",
       " 'stranding',\n",
       " 'necropoliss',\n",
       " 'singularly',\n",
       " 'stone',\n",
       " 'coherent',\n",
       " 'brewed',\n",
       " 'reaffirming',\n",
       " 'woman',\n",
       " 'Sikhism',\n",
       " 'impendence',\n",
       " 'pampers',\n",
       " 'decorations',\n",
       " 'beats',\n",
       " 'incubators',\n",
       " 'farted',\n",
       " 'hurriedly',\n",
       " 'condemned',\n",
       " 'vivacious',\n",
       " 'negotiator',\n",
       " 'attains',\n",
       " 'reformism',\n",
       " 'oddity',\n",
       " 'cacophony',\n",
       " 'secrets',\n",
       " 'galloped',\n",
       " 'temple',\n",
       " 'meddle',\n",
       " 'sociably',\n",
       " 'cartwheels',\n",
       " 'typic',\n",
       " 'depends',\n",
       " 'forgery',\n",
       " 'squirming',\n",
       " 'Highlanders',\n",
       " 'dogs',\n",
       " 'parenthetic',\n",
       " 'decrees',\n",
       " 'impulsive',\n",
       " 'dynamical',\n",
       " 'petter',\n",
       " 'robustness',\n",
       " 'idolatrous',\n",
       " 'Dublins',\n",
       " 'holies',\n",
       " 'luring',\n",
       " 'polos',\n",
       " 'harmonizing',\n",
       " 'toxicology',\n",
       " 'critical',\n",
       " 'loaned',\n",
       " 'conformism',\n",
       " 'monumental',\n",
       " 'crucial',\n",
       " 'ruination',\n",
       " 'coincided',\n",
       " 'individualized',\n",
       " 'implication',\n",
       " 'ligands',\n",
       " 'intervene',\n",
       " 'plundered',\n",
       " 'felt',\n",
       " 'mature',\n",
       " 'revoked',\n",
       " 'alarmingly',\n",
       " 'premising',\n",
       " 'genomicss',\n",
       " 'Moores',\n",
       " 'rigger',\n",
       " 'careening',\n",
       " 'thermostats',\n",
       " 'touted',\n",
       " 'biassed',\n",
       " 'informaticss',\n",
       " 'compendiums',\n",
       " 'Albees',\n",
       " 'prodigies',\n",
       " 'wilds',\n",
       " 'faking',\n",
       " 'happily',\n",
       " 'Catalonia',\n",
       " 'directorship',\n",
       " 'withstander',\n",
       " 'pitchforks',\n",
       " 'teasers',\n",
       " 'recoveries',\n",
       " 'reallocate',\n",
       " 'synced',\n",
       " 'demonstrative',\n",
       " 'HPS',\n",
       " 'gnomes',\n",
       " 'juice',\n",
       " 'adamances',\n",
       " 'melodramatically',\n",
       " 'impressionists',\n",
       " 'southers',\n",
       " 'disarmed',\n",
       " 'brawn',\n",
       " 'sounding',\n",
       " 'fought',\n",
       " 'bustling',\n",
       " 'grudging',\n",
       " 'purring',\n",
       " 'leashed',\n",
       " 'careerism',\n",
       " 'neighbours',\n",
       " 'conceptions',\n",
       " 'Arabia',\n",
       " 'itching',\n",
       " 'technology',\n",
       " 'sedgy',\n",
       " 'refrigerant',\n",
       " 'oppressed',\n",
       " 'housemates',\n",
       " 'tapered',\n",
       " 'stroked',\n",
       " 'eulogize',\n",
       " 'vales',\n",
       " 'environmentally',\n",
       " 'harry',\n",
       " 'miscarrying',\n",
       " 'maths',\n",
       " 'amulets',\n",
       " 'defloration',\n",
       " 'disassociating',\n",
       " 'shabbiness',\n",
       " 'hedges',\n",
       " 'gassing',\n",
       " 'otolaryngologies',\n",
       " 'Malmoes',\n",
       " 'UKS',\n",
       " 'schizophrenic',\n",
       " 'leed',\n",
       " 'speaking',\n",
       " 'riddles',\n",
       " 'muddling',\n",
       " 'Satanic',\n",
       " 'dampens',\n",
       " 'dandies',\n",
       " 'stereotype',\n",
       " 'etymologist',\n",
       " 'luminesce',\n",
       " 'recruited',\n",
       " 'enthralling',\n",
       " 'complement',\n",
       " 'mannequins',\n",
       " 'arched',\n",
       " 'diatribes',\n",
       " 'gummy',\n",
       " 'crates',\n",
       " 'grey',\n",
       " 'anemic',\n",
       " 'burnishing',\n",
       " 'reposit',\n",
       " 'megalomanic',\n",
       " 'jails',\n",
       " 'artlessly',\n",
       " 'tramps',\n",
       " 'epicure',\n",
       " 'freewheeling',\n",
       " 'favourites',\n",
       " 'thoroughnesses',\n",
       " 'untangled',\n",
       " 'believability',\n",
       " 'reifying',\n",
       " 'deciphered',\n",
       " 'fermentation',\n",
       " 'capsules',\n",
       " 'Spartan',\n",
       " 'nobles',\n",
       " 'reasonably',\n",
       " 'notary',\n",
       " 'energize',\n",
       " 'substantiation',\n",
       " 'comparably',\n",
       " 'inheritors',\n",
       " 'steadfast',\n",
       " 'malpractices',\n",
       " 'constitutional',\n",
       " 'faddists',\n",
       " 'glows',\n",
       " 'convoys',\n",
       " 'subscriptions',\n",
       " 'vaccines',\n",
       " 'disparagers',\n",
       " 'abhorrence',\n",
       " 'freshmen',\n",
       " 'sleet',\n",
       " 'substantiate',\n",
       " 'cherishing',\n",
       " 'hemorrhagic',\n",
       " 'invulnerability',\n",
       " 'cryonic',\n",
       " 'other',\n",
       " 'tufts',\n",
       " 'inactive',\n",
       " 'abase',\n",
       " 'infliction',\n",
       " 'emasculated',\n",
       " 'Manamas',\n",
       " 'ossification',\n",
       " 'circumvent',\n",
       " 'accreditations',\n",
       " 'barrelled',\n",
       " 'casualties',\n",
       " 'invoices',\n",
       " 'operators',\n",
       " 'radiographer',\n",
       " 'alarmism',\n",
       " 'intonations',\n",
       " 'cumulation',\n",
       " 'waveforms',\n",
       " 'cereals',\n",
       " 'preachers',\n",
       " 'substitution',\n",
       " 'swampy',\n",
       " 'torpedoing',\n",
       " 'appropriated',\n",
       " 'detriment',\n",
       " 'annulments',\n",
       " 'circumvented',\n",
       " 'incessantly',\n",
       " 'maintenance',\n",
       " 'sprinkled',\n",
       " 'cleansing',\n",
       " 'received',\n",
       " 'paediatricss',\n",
       " 'shames',\n",
       " 'Ilmens',\n",
       " 'checkers',\n",
       " 'prepossession',\n",
       " 'arcades',\n",
       " 'vibrionic',\n",
       " 'came',\n",
       " 'career',\n",
       " 'hurried',\n",
       " 'excerpted',\n",
       " 'depiction',\n",
       " 'scream',\n",
       " 'answering',\n",
       " 'tvs',\n",
       " 'advisor',\n",
       " 'messianic',\n",
       " 'volatiles',\n",
       " 'angle',\n",
       " 'share',\n",
       " 'reiteration',\n",
       " 'globalization',\n",
       " 'magnanimously',\n",
       " 'obturates',\n",
       " 'postponement',\n",
       " 'Vladivostoks',\n",
       " 'hybridization',\n",
       " 'coalesced',\n",
       " 'Indonesia',\n",
       " 'impress',\n",
       " 'keenly',\n",
       " 'manifestos',\n",
       " 'respectively',\n",
       " 'Pis',\n",
       " 'accord',\n",
       " 'indemnification',\n",
       " 'goofing',\n",
       " 'massaging',\n",
       " 'Wembleys',\n",
       " 'exhalation',\n",
       " 'frequenter',\n",
       " 'cervical',\n",
       " 'conformists',\n",
       " 'magnetize',\n",
       " 'uglifying',\n",
       " 'Latiums',\n",
       " 'microscopy',\n",
       " 'surpasses',\n",
       " 'afghans',\n",
       " 'exasperated',\n",
       " 'abhorrer',\n",
       " 'hypothesized',\n",
       " 'searching',\n",
       " 'Slavs',\n",
       " 'dietitians',\n",
       " 'suspend',\n",
       " 'priestly',\n",
       " 'headstones',\n",
       " 'humbling',\n",
       " 'investigatings',\n",
       " 'belongings',\n",
       " 'implanting',\n",
       " 'traumas',\n",
       " 'Theodosiuses',\n",
       " 'hazard',\n",
       " 'buttocks',\n",
       " 'seats',\n",
       " '1950ss',\n",
       " 'refinements',\n",
       " 'languages',\n",
       " 'couplings',\n",
       " 'prostheticss',\n",
       " 'dreg',\n",
       " 'object',\n",
       " 'subsisters',\n",
       " 'Samarias',\n",
       " 'Mars',\n",
       " 'mutinous',\n",
       " 'redesigning',\n",
       " 'measurement',\n",
       " 'recital',\n",
       " 'impregnate',\n",
       " 'greening',\n",
       " 'inculcate',\n",
       " 'tequilas',\n",
       " 'synergetic',\n",
       " 'disappoints',\n",
       " 'roofs',\n",
       " 'sealing',\n",
       " 'deposers',\n",
       " 'sphere',\n",
       " 'cleanings',\n",
       " 'Amoss',\n",
       " 'packing',\n",
       " 'rubberized',\n",
       " 'paperers',\n",
       " 'underestimate',\n",
       " 'stringing',\n",
       " 'astrophysicists',\n",
       " 'defender',\n",
       " 'myopia',\n",
       " 'incontrovertible',\n",
       " 'views',\n",
       " 'anecdotal',\n",
       " 'liberalize',\n",
       " 'luxates',\n",
       " 'dairies',\n",
       " 'unanimous',\n",
       " 'aspirator',\n",
       " 'Mauritian',\n",
       " 'imagery',\n",
       " 'doubly',\n",
       " 'geneticist',\n",
       " 'verbified',\n",
       " 'scribblers',\n",
       " 'landholders',\n",
       " 'plows',\n",
       " 'algorithms',\n",
       " 'hordes',\n",
       " 'Wales',\n",
       " 'molal',\n",
       " 'moderates',\n",
       " 'acclaims',\n",
       " 'stated',\n",
       " 'necessity',\n",
       " 'Isabellas',\n",
       " 'intermingling',\n",
       " 'lectureship',\n",
       " 'electronically',\n",
       " 'embody',\n",
       " 'idolizes',\n",
       " 'autonomous',\n",
       " 'convalescence',\n",
       " 'reelecting',\n",
       " 'straying',\n",
       " 'motor',\n",
       " 'shrugs',\n",
       " 'sinned',\n",
       " 'Germany',\n",
       " 'self-conscious',\n",
       " 'redes',\n",
       " 'anteceding',\n",
       " 'Germanic',\n",
       " 'blacksmiths',\n",
       " 'murals',\n",
       " 'ramp',\n",
       " 'lacerate',\n",
       " 'contain',\n",
       " 'gasolines',\n",
       " 'laminator',\n",
       " 'stigmatized',\n",
       " 'hammy',\n",
       " 'journalists',\n",
       " 'bold',\n",
       " 'bedrolls',\n",
       " 'expansivity',\n",
       " 'retinal',\n",
       " 'carving',\n",
       " 'dryads',\n",
       " 'slept',\n",
       " 'pints',\n",
       " 'festered',\n",
       " 'celebration',\n",
       " 'sidewalls',\n",
       " 'nervous system',\n",
       " 'mythologies',\n",
       " 'sculptors',\n",
       " 'anorectics',\n",
       " 'Cracows',\n",
       " 'haters',\n",
       " 'fronds',\n",
       " 'contributive',\n",
       " 'identify',\n",
       " 'lusting',\n",
       " 'anachronism',\n",
       " 'inflect',\n",
       " 'boys',\n",
       " 'massive',\n",
       " 'ameliorate',\n",
       " 'squeaker',\n",
       " 'revamped',\n",
       " 'establishing',\n",
       " 'deceptions',\n",
       " 'stalemating',\n",
       " 'fabricate',\n",
       " 'primes',\n",
       " 'immunity',\n",
       " 'exercising',\n",
       " 'brewery',\n",
       " 'neutrality',\n",
       " 'countrywomen',\n",
       " 'chanterelles',\n",
       " 'tiresomely',\n",
       " 'pomposity',\n",
       " 'nurturing',\n",
       " 'apprehensively',\n",
       " 'refineries',\n",
       " 'acquires',\n",
       " 'infect',\n",
       " 'titanic',\n",
       " 'smoother',\n",
       " 'debriefings',\n",
       " 'backspacer',\n",
       " 'alienable',\n",
       " 'clammy',\n",
       " 'babying',\n",
       " 'induct',\n",
       " 'apprehensible',\n",
       " 'offerors',\n",
       " 'snorkelings',\n",
       " 'attract',\n",
       " 'unsuitable',\n",
       " 'tranquillity',\n",
       " 'reversals',\n",
       " ...}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/nigula/LL/adjust_unigr_dict/lookup results/yandex_lookup_en_ru_wordforms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty_lookup(directory,handled_words, print_output = False):\n",
    "    total_words_count = 0 \n",
    "    empty = 0\n",
    "    not_handled_from_original_list = 0\n",
    "    for file in tqdm(os.listdir(directory)):\n",
    "        if print_output == True: print(file)\n",
    "        current_word = file.split(\".\")[0]\n",
    "        if \"DS_Store\" not in file:\n",
    "            try:\n",
    "                f = open(os.path.join(directory,file), \"r\", encoding='utf-8')\n",
    "            except:\n",
    "                f = open(os.path.join(directory,file), \"r\")\n",
    "            try:\n",
    "                data = json.load(f, encoding = 'utf-8')\n",
    "            except:\n",
    "                data = json.load(f)\n",
    "            if print_output == True:print(data)\n",
    "            word_current = file.split(\".\")[0]\n",
    "            if word_current not in handled_words:\n",
    "                not_handled_from_original_list += 1\n",
    "            if \"head\" in data:\n",
    "                if print_output == True:print(\"YANDEX\")\n",
    "#                 for definition in data['def']:\n",
    "#                     word_current =  definition['text'] \n",
    "#                     if 'pos' in definition:\n",
    "#                         global_pos = definition['pos']\n",
    "#                     else:\n",
    "#                         global_pos = 'no_pos_available'\n",
    "#                     if len(definition['tr']): \n",
    "                        \n",
    "#                     for translation in definition['tr']: \n",
    "#                         if 'pos' in translation:\n",
    "#                             pos = translation['pos']\n",
    "#                         else:\n",
    "#                             pos = global_pos\n",
    "#                         if print_output == True:print(pos, word_current, translation['text'])\n",
    "#                         pos_list.append(pos)\n",
    "#                         word.append(word_current)\n",
    "#                         local_word.append(translation['text'])\n",
    "#                         ex_en = []\n",
    "#                         ex_rus = []\n",
    "                if len(data['def']) == 0:\n",
    "                    empty += 1\n",
    "            else:\n",
    "                if print_output == True:print(\"CONTEXT_REVERSO\")\n",
    "                \n",
    "                if len(data['def']['tr']) == 0:\n",
    "                    empty += 1\n",
    "#                 for definition in data['def'].values():\n",
    "#                     for translation in definition:\n",
    "#                         if translation['pos'] == '':\n",
    "#                             pos = 'no_pos_available'\n",
    "#                         else:\n",
    "#                             pos = translation['pos']\n",
    "#                         if print_output == True:print(pos, word_current, translation['text'])\n",
    "#                         pos_list.append(pos)\n",
    "#                         word.append(word_current)\n",
    "#                         local_word.append(translation['text'])       \n",
    "            total_words_count += 1\n",
    "    print(empty, \"empty words\",total_words_count,\"total_words_count\", not_handled_from_original_list,\"not_handled_from_original_list\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130000, 64005)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordforms_list),len(set(wordforms_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83c7305c56843a08c5618d281243116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63657), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20880 empty words 63656 total_words_count 21008 not_handled_from_original_list\n"
     ]
    }
   ],
   "source": [
    "check_empty_lookup(\"/Users/nigula/LL/adjust_unigr_dict/lookup/yandex_lookup_en_ru_wordforms/\", handled_eng_wods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * делаем список ссылок на запрос, сохраняем асинхронными парсингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>longs</td>\n",
       "      <td>жаждет</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>longs</td>\n",
       "      <td>тоскует</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>longs</td>\n",
       "      <td>мечтает</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longs</td>\n",
       "      <td>страстно желает</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instilments</td>\n",
       "      <td>частями</td>\n",
       "      <td>no_pos_available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word       local_word               pos\n",
       "0        longs           жаждет  no_pos_available\n",
       "1        longs          тоскует  no_pos_available\n",
       "2        longs          мечтает  no_pos_available\n",
       "3        longs  страстно желает  no_pos_available\n",
       "4  instilments          частями  no_pos_available"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(from_lang,to_lang, word):\n",
    "    url = \"https://context.reverso.net/перевод/\" + from_lang + \"-\" + to_lang + \"/\" + word \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wordforms_list = []\n",
    "for file in os.listdir(\"/Users/nigula/LL/adjust_unigr_dict/wordforms/wf_eng\"):\n",
    "    if \"json\" in file:\n",
    "        with open(os.path.join(\"/Users/nigula/LL/adjust_unigr_dict/wordforms/wf_eng\", file), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            for en_ref_word in data.keys():\n",
    "                #print(data[en_ref_word])\n",
    "                wordforms_list.extend(data[en_ref_word])\n",
    "                #break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_wordforms = list(set(df['local_word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37354486f2ce40e4a0be616062a35aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=149077), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_non_handled_words_link(handled_directory, words_list, from_lang, to_lang):\n",
    "    handled_word_list = []\n",
    "    for handled_word in os.listdir(handled_directory):\n",
    "        word = handled_word.split(\".\")[0]\n",
    "        handled_word_list.append(word)\n",
    "\n",
    "    links_list = []\n",
    "    for word in tqdm(list(set(words_list))):\n",
    "        if word not in handled_word_list:\n",
    "            url = get_link(from_lang, to_lang, word)\n",
    "            links_list.append(url)\n",
    "    return links_list\n",
    "\n",
    "links_list = get_non_handled_words_link(\"/Users/nigula/LL/adjust_unigr_dict/lookup/reverso_ru_fr\", rus_wordforms,\"русский\", \"французский\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://context.reverso.net/перевод/русский-французский/заболачивание',\n",
       " 'https://context.reverso.net/перевод/русский-французский/составил почти',\n",
       " 'https://context.reverso.net/перевод/русский-французский/отрубленной',\n",
       " 'https://context.reverso.net/перевод/русский-французский/затоптали',\n",
       " 'https://context.reverso.net/перевод/русский-французский/рубежи',\n",
       " 'https://context.reverso.net/перевод/русский-французский/предупреждающее',\n",
       " 'https://context.reverso.net/перевод/русский-французский/лет двадцати',\n",
       " 'https://context.reverso.net/перевод/русский-французский/кэмпбеллов',\n",
       " 'https://context.reverso.net/перевод/русский-французский/latsch',\n",
       " 'https://context.reverso.net/перевод/русский-французский/охватывать']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reverso_ru_fr_links_list.json\", \"w\") as f:\n",
    "    data = json.dump(links_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64005"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"reverso_en_fr_links_list.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * Запускаем скрипт cross_approach_script к полученному csv. Меняем параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * объединяем с прошлым 1)concat_medium_results_and_detect_missing_stuff 2) merge_cross_approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "лемматизируем всю херню и добавляем в отдельный столбец для каждого языка\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
