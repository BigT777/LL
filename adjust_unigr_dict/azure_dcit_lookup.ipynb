{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subscription ID\n",
    "6ad923bc-5698-47da-be90-a497f515bc95\n",
    "\n",
    "\n",
    "endpoint \n",
    "https://ll-dict-lookup.cognitiveservices.azure.com/sts/v1.0/issuetoken\n",
    "\n",
    "\n",
    "k1 7f44a7c95fd34041a2eef780f3f79817 \n",
    "\n",
    "k2 470a910b5c4f4df8936ce62f2c26f4f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': '6ad923bc-5698-47da-be90-a497f515bc95',\n",
    "}\n",
    "\n",
    "response = requests.post('https://api.cognitive.microsoft.com/sts/v1.0/issueToken', headers=headers)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Alternatively, you can exchange your secret key for an access token. This token is included with each request as the Authorization header. To obtain an authorization token, make a POST request to the following URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': '7f44a7c95fd34041a2eef780f3f79817',\n",
    "}\n",
    "\n",
    "response = requests.post('https://ll-dict-lookup.cognitiveservices.azure.com/sts/v1.0/issuetoken', headers=headers)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Authorization token"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eyJhbGciOiJodHRwOi8vd3d3LnczLm9yZy8yMDAxLzA0L3htbGRzaWctbW9yZSNobWFjLXNoYTI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ1cm46bXMuY29nbml0aXZlc2VydmljZXMiLCJleHAiOiIxNTY4ODA3OTA3IiwicmVnaW9uIjoiZ2xvYmFsIiwic3Vic2NyaXB0aW9uLWlkIjoiNDFkOGYxN2IwODYwNGIyMWIzNTQ0OGJjN2E1YmQzNzciLCJwcm9kdWN0LWlkIjoiVGV4dFRyYW5zbGF0b3IuUzEiLCJjb2duaXRpdmUtc2VydmljZXMtZW5kcG9pbnQiOiJodHRwczovL2FwaS5jb2duaXRpdmUubWljcm9zb2Z0LmNvbS9pbnRlcm5hbC92MS4wLyIsImF6dXJlLXJlc291cmNlLWlkIjoiL3N1YnNjcmlwdGlvbnMvNmFkOTIzYmMtNTY5OC00N2RhLWJlOTAtYTQ5N2Y1MTViYzk1L3Jlc291cmNlR3JvdXBzL2Nsb3VkLXNoZWxsLXN0b3JhZ2Utd2VzdGV1cm9wZS9wcm92aWRlcnMvTWljcm9zb2Z0LkNvZ25pdGl2ZVNlcnZpY2VzL2FjY291bnRzL0xMLWRpY3QtbG9va3VwIiwic2NvcGUiOiJodHRwczovL2FwaS5taWNyb3NvZnR0cmFuc2xhdG9yLmNvbS8iLCJhdWQiOiJ1cm46bXMubWljcm9zb2Z0dHJhbnNsYXRvciJ9.DZhy9qyHnVD7b4vjWBMVTgTbYL7IFPD5fd3t3lXq9kA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "An authentication token is valid for 10 minutes. The token should be re-used when making multiple calls to the Translator APIs. However, if your program makes requests to the Translator API over an extended period of time, then your program must request a new access token at regular intervals (e.g. every 8 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stringfied_json(word):\n",
    "    dt = {'Text': word}\n",
    "    stringIO = StringIO()\n",
    "    json.dump(dt, stringIO)\n",
    "    return stringIO.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': '7f44a7c95fd34041a2eef780f3f79817',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('api-version', '3.0'),\n",
    "    ('from', 'en'),\n",
    "    ('to', 'fr'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#data = {'Text':'fly'}\n",
    "#data = '[{\\'Text\\':\\'fly\\'}]'\n",
    "data = get_stringfied_json(\"fly\")\n",
    "\n",
    "response = requests.post('https://api.cognitive.microsofttranslator.com/dictionary/lookup', headers=headers, params=params, data=data)\n",
    "response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.loads(response.text)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  word\n",
       "1   the\n",
       "2   and\n",
       "3  that\n",
       "4   for"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.read_csv(\"test_words.csv\", header = None)\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Text\": \"break\"}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stringfied_json(\"break\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "the\n",
      "and\n",
      "that\n",
      "for\n",
      "with\n",
      "but\n",
      "you\n",
      "this\n",
      "not\n",
      "have\n",
      "letter\n",
      "plate\n",
      "treat\n",
      "dinner\n",
      "necessary\n",
      "go\n",
      "secret\n",
      "table\n",
      "create\n",
      "warm\n",
      "America\n",
      "nobody\n",
      "entire\n",
      "thousand\n",
      "Belgium\n",
      "anything\n",
      "background\n",
      "child\n",
      "childhood\n",
      "dependable\n",
      "everything\n",
      "grandchild\n",
      "ketchup\n",
      "point\n",
      "strength\n",
      "star\n",
      "thing\n",
      "coincide\n",
      "coincidental\n",
      "dance\n",
      "countryside\n",
      "break\n",
      "mother\n",
      "start\n",
      "tip\n",
      "apologise\n",
      "come\n",
      "curriculum\n",
      "expertise\n",
      "freeze\n",
      "issue\n",
      "peremptory\n",
      "parent\n",
      "member\n",
      "band\n",
      "order\n",
      "hot\n",
      "fly\n",
      "lie\n",
      "select\n",
      "school\n",
      "cafe\n",
      "buy\n",
      "tell\n",
      "international\n",
      "stand\n",
      "fish\n",
      "benefit\n",
      "intelligent\n",
      "follow\n",
      "journey\n",
      "news\n",
      "write\n",
      "approbation\n",
      "read\n",
      "hear\n",
      "feel\n",
      "be\n",
      "right\n",
      "guru\n",
      "beginner\n",
      "collide\n",
      "genetically\n",
      "precedent\n",
      "refugee\n",
      "secular\n",
      "pasta\n",
      "beaver\n",
      "tiger\n",
      "lion\n",
      "pen\n",
      "coconut\n",
      "dynamite\n",
      "spoon\n",
      "ocean\n",
      "mug\n",
      "shampoo\n",
      "buzzer\n",
      "exhaustively\n",
      "apoplexy\n",
      "submissively\n",
      "typhus\n",
      "ravioli\n",
      "meeting\n",
      "actually\n",
      "earring\n",
      "add\n",
      "adjective\n",
      "drawing\n",
      "dream\n",
      "dressed\n",
      "driving\n",
      "drum\n",
      "dry\n",
      "duck\n",
      "advanced\n",
      "during\n",
      "earn\n",
      "singular\n",
      "easily\n",
      "east\n",
      "eighth\n",
      "adventure\n",
      "eighty\n",
      "adverb\n",
      "electric\n",
      "advertisement\n",
      "century\n",
      "size\n",
      "electricity\n",
      "elephant\n",
      "else\n",
      "empty\n",
      "engine\n",
      "engineer\n",
      "enough\n",
      "enter\n",
      "entrance\n",
      "advice\n",
      "aeroplane\n",
      "envelope\n",
      "especially\n",
      "euro\n",
      "even\n",
      "afraid\n",
      "afterwards\n",
      "everyone\n",
      "against\n",
      "everything\n",
      "everywhere\n",
      "aged\n",
      "ago\n",
      "exactly\n",
      "exam\n",
      "examination\n",
      "excellent\n",
      "except\n",
      "exercise\n",
      "exit\n",
      "explain\n",
      "extra\n",
      "fact\n",
      "fail\n",
      "fair\n",
      "fall\n",
      "agree\n",
      "air\n",
      "airport\n",
      "fan\n",
      "fantastic\n",
      "far\n",
      "farmer\n",
      "fashion\n",
      "quite\n",
      "alarm\n",
      "album\n",
      "alcohol\n",
      "almost\n",
      "alone\n",
      "field\n",
      "fifth\n",
      "fifty\n",
      "file\n",
      "fill\n",
      "final\n",
      "finally\n",
      "finger\n",
      "fire\n",
      "fishing\n",
      "fit\n",
      "flight\n",
      "along\n",
      "bedroom\n",
      "beer\n",
      "before\n",
      "begin\n",
      "behind\n",
      "below\n",
      "best\n",
      "synchrophasotron\n"
     ]
    }
   ],
   "source": [
    "for word in words[0].items():\n",
    "    print (word[1])\n",
    "    data = get_stringfied_json(word[1])\n",
    "    response = requests.post('https://api.cognitive.microsofttranslator.com/dictionary/lookup', headers=headers, params=params, data=data)\n",
    "    result = json.loads(response.text)\n",
    "    save_loc = \"./lookup/azure_en_fr/\" + word[1] + \".json\"\n",
    "    with open(save_loc, \"w\") as f:\n",
    "        json.dump(result,f,indent = 4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stringfied_json_vs_tarns(word, trans):\n",
    "    dt = {'Text': word, 'Translation':trans}\n",
    "    stringIO = StringIO()\n",
    "    json.dump(dt, stringIO, ensure_ascii = False)\n",
    "    return stringIO.getvalue().encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalizedSource': 'word',\n",
       " 'normalizedTarget': 'поговорить',\n",
       " 'examples': [{'sourcePrefix': 'I need to have a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with him anyway.',\n",
       "   'targetPrefix': 'Мне нужно ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' с ним в любом случае.'},\n",
       "  {'sourcePrefix': 'We just want a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': '.',\n",
       "   'targetPrefix': 'Мы просто хотим ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': '.'},\n",
       "  {'sourcePrefix': 'My lawyer wants a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with you.',\n",
       "   'targetPrefix': 'Мой адвокат хочет ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' с Вами.'},\n",
       "  {'sourcePrefix': 'If we may break ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' in private?',\n",
       "   'targetPrefix': 'Можем ли мы ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' наедине?'},\n",
       "  {'sourcePrefix': 'Someone wants a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with you.',\n",
       "   'targetPrefix': 'Кое-кто хочет ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' с тобой.'},\n",
       "  {'sourcePrefix': 'We need a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with you.',\n",
       "   'targetPrefix': 'Нам нужно ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' с вами.'},\n",
       "  {'sourcePrefix': 'This man wants a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with you.',\n",
       "   'targetPrefix': 'Этот синьор хотел бы с вами ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': '.'},\n",
       "  {'sourcePrefix': 'What do you want to have a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' about?',\n",
       "   'targetPrefix': 'О чем ты хочешь с ней ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': '?'},\n",
       "  {'sourcePrefix': 'Someone wants a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with you.',\n",
       "   'targetPrefix': 'Кто-то хочет ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' с Вами.'},\n",
       "  {'sourcePrefix': 'He wants a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with you.',\n",
       "   'targetPrefix': 'Он хочет ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' с тобой.'},\n",
       "  {'sourcePrefix': 'A ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with my son, please.',\n",
       "   'targetPrefix': 'Могу я ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' с моим сыном.'},\n",
       "  {'sourcePrefix': 'We need to have a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with you.',\n",
       "   'targetPrefix': 'Нам нужно с тобой ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': '.'},\n",
       "  {'sourcePrefix': 'My mother wants a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': ' with you.',\n",
       "   'targetPrefix': 'Моя мать хочет ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': ' с Вами.'},\n",
       "  {'sourcePrefix': 'I would have you with me to break ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': '.',\n",
       "   'targetPrefix': 'Мы с тобой должны с ним ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': '.'},\n",
       "  {'sourcePrefix': 'That he wants to have a ',\n",
       "   'sourceTerm': 'word',\n",
       "   'sourceSuffix': '?',\n",
       "   'targetPrefix': 'Что он хочет с ней ',\n",
       "   'targetTerm': 'поговорить',\n",
       "   'targetSuffix': '?'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_examples(from_lang, to_lang, from_word, to_word):\n",
    "    headers_func = {\n",
    "    'Ocp-Apim-Subscription-Key': '7f44a7c95fd34041a2eef780f3f79817',\n",
    "    'Content-Type': 'application/json',\n",
    "    }\n",
    "    params_f = (\n",
    "    ('api-version', '3.0'),\n",
    "    ('from', from_lang),\n",
    "    ('to', to_lang),\n",
    "    )\n",
    "    data_f = get_stringfied_json_vs_tarns(from_word, to_word)\n",
    "    response_f = requests.post('https://api.cognitive.microsofttranslator.com/dictionary/examples', headers=headers_func, params=params_f, data=data_f)\n",
    "    results = json.loads(response_f.text)\n",
    "    return results\n",
    "\n",
    "get_examples(\"en\", \"ru\", \"word\", \"поговорить\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"normalizedSource\":\"actually\",\"normalizedTarget\":\"фактически\",\"examples\":[{\"sourcePrefix\":\"Just a few blocks, \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\".\",\"targetPrefix\":\"\",\"targetTerm\":\"Фактически\",\"targetSuffix\":\", всего в нескольких кварталах.\"},{\"sourcePrefix\":\"The methods are called only when the value \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" changes.\",\"targetPrefix\":\"Методы вызываются только в случае, если \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" изменяет значение.\"},{\"sourcePrefix\":\"So it \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" completes it twice as fast.\",\"targetPrefix\":\"Поэтому \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" он завершает его в 2 раза быстрее.\"},{\"sourcePrefix\":\"The floor plan is \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" a section drawing.\",\"targetPrefix\":\"\",\"targetTerm\":\"Фактически\",\"targetSuffix\":\" план этажа представляет собой чертеж сечения.\"},{\"sourcePrefix\":\"This fluid is \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" alive.\",\"targetPrefix\":\"\",\"targetTerm\":\"Фактически\",\"targetSuffix\":\" эта жидкость жива.\"},{\"sourcePrefix\":\"People are \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" voting.\",\"targetPrefix\":\"Люди \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" принимают решение.\"},{\"sourcePrefix\":\"The system is \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" not out of memory.\",\"targetPrefix\":\"Система не \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" является нехватка памяти.\"},{\"sourcePrefix\":\"It returns the number of elements \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" inserted.\",\"targetPrefix\":\"Она возвращает число \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" новых элементов.\"},{\"sourcePrefix\":\"Which \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" makes these quite rare.\",\"targetPrefix\":\"Что \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" делает их весьма редкими.\"},{\"sourcePrefix\":\"So you \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" live up here?\",\"targetPrefix\":\"Так значит, ты \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" живешь тут?\"},{\"sourcePrefix\":\"The trouble is this isn\\'t what is \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" happening.\",\"targetPrefix\":\"Проблема, это не то, что \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" случается.\"},{\"sourcePrefix\":\"So there\\'s \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" two different processes.\",\"targetPrefix\":\"Так что есть \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" два различных процесса.\"},{\"sourcePrefix\":\"We were not \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" present at the trials.\",\"targetPrefix\":\"\",\"targetTerm\":\"Фактически\",\"targetSuffix\":\" мы не присутствовали при испытаниях.\"},{\"sourcePrefix\":\"That is, they are \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" the same task.\",\"targetPrefix\":\"То есть они \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" ту же задачу.\"},{\"sourcePrefix\":\"It \",\"sourceTerm\":\"actually\",\"sourceSuffix\":\" does today.\",\"targetPrefix\":\"Он \",\"targetTerm\":\"фактически\",\"targetSuffix\":\" делает сегодня.\"}]}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': '7f44a7c95fd34041a2eef780f3f79817',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('api-version', '3.0'),\n",
    "    ('from', 'en'),\n",
    "    ('to', 'ru'),\n",
    ")\n",
    "\n",
    "#data = '[{\\'Text\\':\\'actually\\', \\'Translation\\':\\'фактически\\'}]'\n",
    "data = get_stringfied_json_vs_tarns('actually', 'фактически')\n",
    "\n",
    "response = requests.post('https://api.cognitive.microsofttranslator.com/dictionary/examples', headers=headers, params=params, data=data)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalizedSource': 'actually',\n",
       " 'normalizedTarget': 'фактически',\n",
       " 'examples': [{'sourcePrefix': 'Just a few blocks, ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': '.',\n",
       "   'targetPrefix': '',\n",
       "   'targetTerm': 'Фактически',\n",
       "   'targetSuffix': ', всего в нескольких кварталах.'},\n",
       "  {'sourcePrefix': 'The methods are called only when the value ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' changes.',\n",
       "   'targetPrefix': 'Методы вызываются только в случае, если ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' изменяет значение.'},\n",
       "  {'sourcePrefix': 'So it ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' completes it twice as fast.',\n",
       "   'targetPrefix': 'Поэтому ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' он завершает его в 2 раза быстрее.'},\n",
       "  {'sourcePrefix': 'The floor plan is ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' a section drawing.',\n",
       "   'targetPrefix': '',\n",
       "   'targetTerm': 'Фактически',\n",
       "   'targetSuffix': ' план этажа представляет собой чертеж сечения.'},\n",
       "  {'sourcePrefix': 'This fluid is ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' alive.',\n",
       "   'targetPrefix': '',\n",
       "   'targetTerm': 'Фактически',\n",
       "   'targetSuffix': ' эта жидкость жива.'},\n",
       "  {'sourcePrefix': 'People are ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' voting.',\n",
       "   'targetPrefix': 'Люди ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' принимают решение.'},\n",
       "  {'sourcePrefix': 'The system is ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' not out of memory.',\n",
       "   'targetPrefix': 'Система не ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' является нехватка памяти.'},\n",
       "  {'sourcePrefix': 'It returns the number of elements ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' inserted.',\n",
       "   'targetPrefix': 'Она возвращает число ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' новых элементов.'},\n",
       "  {'sourcePrefix': 'Which ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' makes these quite rare.',\n",
       "   'targetPrefix': 'Что ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' делает их весьма редкими.'},\n",
       "  {'sourcePrefix': 'So you ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' live up here?',\n",
       "   'targetPrefix': 'Так значит, ты ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' живешь тут?'},\n",
       "  {'sourcePrefix': \"The trouble is this isn't what is \",\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' happening.',\n",
       "   'targetPrefix': 'Проблема, это не то, что ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' случается.'},\n",
       "  {'sourcePrefix': \"So there's \",\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' two different processes.',\n",
       "   'targetPrefix': 'Так что есть ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' два различных процесса.'},\n",
       "  {'sourcePrefix': 'We were not ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' present at the trials.',\n",
       "   'targetPrefix': '',\n",
       "   'targetTerm': 'Фактически',\n",
       "   'targetSuffix': ' мы не присутствовали при испытаниях.'},\n",
       "  {'sourcePrefix': 'That is, they are ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' the same task.',\n",
       "   'targetPrefix': 'То есть они ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' ту же задачу.'},\n",
       "  {'sourcePrefix': 'It ',\n",
       "   'sourceTerm': 'actually',\n",
       "   'sourceSuffix': ' does today.',\n",
       "   'targetPrefix': 'Он ',\n",
       "   'targetTerm': 'фактически',\n",
       "   'targetSuffix': ' делает сегодня.'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = json.loads(response.text)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['фактически',\n",
       " 'действительно',\n",
       " 'собственно',\n",
       " 'реально',\n",
       " 'самом деле',\n",
       " 'вообще',\n",
       " 'правда',\n",
       " 'честно говоря']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sensewords_list(path):\n",
    "    sensewords_list = []\n",
    "    with open(path, \"r\") as f: \n",
    "        data = json.load(f)\n",
    "        for translation in data['translations']:\n",
    "            sensewords_list.append(translation['normalizedTarget'])\n",
    "            #print(translation['normalizedTarget'])\n",
    "    return sensewords_list\n",
    "            \n",
    "get_sensewords_list(\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_ru/actually.json\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples_from_azure_dir(directory, from_lang, to_lang, save_directory):\n",
    "    start = True\n",
    "    words = pd.read_csv(\"test_words.csv\", header = None)\n",
    "    for word_i in words[0].items():\n",
    "        print (word_i[1], \"========\")\n",
    "        #if word_i[1] == \"envelope\": start = True\n",
    "        if start == True:\n",
    "            file = word_i[1] + \".json\"\n",
    "            file_path = os.path.join(directory, file)\n",
    "            sensewords = get_sensewords_list(file_path)\n",
    "            for senseword in sensewords:\n",
    "                ex_file = get_examples(from_lang, to_lang, word_i[1], senseword)\n",
    "                file_name = word_i[1] +'_' + senseword + \".json\"\n",
    "                save_dir_file = os.path.join(save_directory, file_name)\n",
    "                with open(save_dir_file, \"w\") as f:\n",
    "                    json.dump(ex_file,f , indent = 4, ensure_ascii=False)\n",
    "        \n",
    "#get_examples_from_azure_dir(\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_ru\", \"en\", \"ru\",\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_ru_ex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word ========\n",
      "the ========\n",
      "and ========\n",
      "that ========\n",
      "for ========\n",
      "with ========\n",
      "but ========\n",
      "you ========\n",
      "this ========\n",
      "not ========\n",
      "have ========\n",
      "letter ========\n",
      "plate ========\n",
      "treat ========\n",
      "dinner ========\n",
      "necessary ========\n",
      "go ========\n",
      "secret ========\n",
      "table ========\n",
      "create ========\n",
      "warm ========\n",
      "America ========\n",
      "nobody ========\n",
      "entire ========\n",
      "thousand ========\n",
      "Belgium ========\n",
      "anything ========\n",
      "background ========\n",
      "child ========\n",
      "childhood ========\n",
      "dependable ========\n",
      "everything ========\n",
      "grandchild ========\n",
      "ketchup ========\n",
      "point ========\n",
      "strength ========\n",
      "star ========\n",
      "thing ========\n",
      "coincide ========\n",
      "coincidental ========\n",
      "dance ========\n",
      "countryside ========\n",
      "break ========\n",
      "mother ========\n",
      "start ========\n",
      "tip ========\n",
      "apologise ========\n",
      "come ========\n",
      "curriculum ========\n",
      "expertise ========\n",
      "freeze ========\n",
      "issue ========\n",
      "peremptory ========\n",
      "parent ========\n",
      "member ========\n",
      "band ========\n",
      "order ========\n",
      "hot ========\n",
      "fly ========\n",
      "lie ========\n",
      "select ========\n",
      "school ========\n",
      "cafe ========\n",
      "buy ========\n",
      "tell ========\n",
      "international ========\n",
      "stand ========\n",
      "fish ========\n",
      "benefit ========\n",
      "intelligent ========\n",
      "follow ========\n",
      "journey ========\n",
      "news ========\n",
      "write ========\n",
      "approbation ========\n",
      "read ========\n",
      "hear ========\n",
      "feel ========\n",
      "be ========\n",
      "right ========\n",
      "guru ========\n",
      "beginner ========\n",
      "collide ========\n",
      "genetically ========\n",
      "precedent ========\n",
      "refugee ========\n",
      "secular ========\n",
      "pasta ========\n",
      "beaver ========\n",
      "tiger ========\n",
      "lion ========\n",
      "pen ========\n",
      "coconut ========\n",
      "dynamite ========\n",
      "spoon ========\n",
      "ocean ========\n",
      "mug ========\n",
      "shampoo ========\n",
      "buzzer ========\n",
      "exhaustively ========\n",
      "apoplexy ========\n",
      "submissively ========\n",
      "typhus ========\n",
      "ravioli ========\n",
      "meeting ========\n",
      "actually ========\n",
      "earring ========\n",
      "add ========\n",
      "adjective ========\n",
      "drawing ========\n",
      "dream ========\n",
      "dressed ========\n",
      "driving ========\n",
      "drum ========\n",
      "dry ========\n",
      "duck ========\n",
      "advanced ========\n",
      "during ========\n",
      "earn ========\n",
      "singular ========\n",
      "easily ========\n",
      "east ========\n",
      "eighth ========\n",
      "adventure ========\n",
      "eighty ========\n",
      "adverb ========\n",
      "electric ========\n",
      "advertisement ========\n",
      "century ========\n",
      "size ========\n",
      "electricity ========\n",
      "elephant ========\n",
      "else ========\n",
      "empty ========\n",
      "engine ========\n",
      "engineer ========\n",
      "enough ========\n",
      "enter ========\n",
      "entrance ========\n",
      "advice ========\n",
      "aeroplane ========\n",
      "envelope ========\n",
      "especially ========\n",
      "euro ========\n",
      "even ========\n",
      "afraid ========\n",
      "afterwards ========\n",
      "everyone ========\n",
      "against ========\n",
      "everything ========\n",
      "everywhere ========\n",
      "aged ========\n",
      "ago ========\n",
      "exactly ========\n",
      "exam ========\n",
      "examination ========\n",
      "excellent ========\n",
      "except ========\n",
      "exercise ========\n",
      "exit ========\n",
      "explain ========\n",
      "extra ========\n",
      "fact ========\n",
      "fail ========\n",
      "fair ========\n",
      "fall ========\n",
      "agree ========\n",
      "air ========\n",
      "airport ========\n",
      "fan ========\n",
      "fantastic ========\n",
      "far ========\n",
      "farmer ========\n",
      "fashion ========\n",
      "quite ========\n",
      "alarm ========\n",
      "album ========\n",
      "alcohol ========\n",
      "almost ========\n",
      "alone ========\n",
      "field ========\n",
      "fifth ========\n",
      "fifty ========\n",
      "file ========\n",
      "fill ========\n",
      "final ========\n",
      "finally ========\n",
      "finger ========\n",
      "fire ========\n",
      "fishing ========\n",
      "fit ========\n",
      "flight ========\n",
      "along ========\n",
      "bedroom ========\n",
      "beer ========\n",
      "before ========\n",
      "begin ========\n",
      "behind ========\n",
      "below ========\n",
      "best ========\n",
      "synchrophasotron ========\n"
     ]
    }
   ],
   "source": [
    "get_examples_from_azure_dir(\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_fr\", \"en\", \"fr\",\n",
    "                            \"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_fr_ex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (\n",
    "    ('Subscription-Key', '<your-key>'),\n",
    ")\n",
    "\n",
    "response = requests.post('https://api.cognitive.microsoft.com/sts/v1.0/issueToken', params=params)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': '<client-secret>',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('api-version', '3.0'),\n",
    "    ('from', 'en'),\n",
    "    ('to', 'es'),\n",
    ")\n",
    "\n",
    "data = [{'Text':'fly'}]\n",
    "\n",
    "response = requests.post('https://api.cognitive.microsofttranslator.com/dictionary/lookup', headers=headers, params=params, data=data)\n",
    "\n",
    "#NB. Original query string below. It seems impossible to parse and\n",
    "#reproduce query strings 100% accurately so the one below is given\n",
    "#in case the reproduced version is not \"correct\".\n",
    "# response = requests.post('https://api.cognitive.microsofttranslator.com/dictionary/lookup?api-version=3.0&from=en&to=es', headers=headers, data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word ========\n",
      "the ========\n",
      "and ========\n",
      "that ========\n",
      "for ========\n",
      "with ========\n",
      "but ========\n",
      "you ========\n",
      "this ========\n",
      "not ========\n",
      "have ========\n",
      "letter ========\n",
      "plate ========\n",
      "treat ========\n",
      "dinner ========\n",
      "necessary ========\n",
      "go ========\n",
      "secret ========\n",
      "table ========\n",
      "create ========\n",
      "warm ========\n",
      "America ========\n",
      "nobody ========\n",
      "entire ========\n",
      "thousand ========\n",
      "Belgium ========\n",
      "anything ========\n",
      "background ========\n",
      "child ========\n",
      "childhood ========\n",
      "dependable ========\n",
      "everything ========\n",
      "grandchild ========\n",
      "ketchup ========\n",
      "point ========\n",
      "strength ========\n",
      "star ========\n",
      "thing ========\n",
      "coincide ========\n",
      "coincidental ========\n",
      "dance ========\n",
      "countryside ========\n",
      "break ========\n",
      "mother ========\n",
      "start ========\n",
      "tip ========\n",
      "apologise ========\n",
      "come ========\n",
      "curriculum ========\n",
      "expertise ========\n",
      "freeze ========\n",
      "issue ========\n",
      "peremptory ========\n",
      "parent ========\n",
      "member ========\n",
      "band ========\n",
      "order ========\n",
      "hot ========\n",
      "fly ========\n",
      "lie ========\n",
      "select ========\n",
      "school ========\n",
      "cafe ========\n",
      "buy ========\n",
      "tell ========\n",
      "international ========\n",
      "stand ========\n",
      "fish ========\n",
      "benefit ========\n",
      "intelligent ========\n",
      "follow ========\n",
      "journey ========\n",
      "news ========\n",
      "write ========\n",
      "approbation ========\n",
      "read ========\n",
      "hear ========\n",
      "feel ========\n",
      "be ========\n",
      "right ========\n",
      "guru ========\n",
      "beginner ========\n",
      "collide ========\n",
      "genetically ========\n",
      "precedent ========\n",
      "refugee ========\n",
      "secular ========\n",
      "pasta ========\n",
      "beaver ========\n",
      "tiger ========\n",
      "lion ========\n",
      "pen ========\n",
      "coconut ========\n",
      "dynamite ========\n",
      "spoon ========\n",
      "ocean ========\n",
      "mug ========\n",
      "shampoo ========\n",
      "buzzer ========\n",
      "exhaustively ========\n",
      "apoplexy ========\n",
      "submissively ========\n",
      "typhus ========\n",
      "ravioli ========\n",
      "meeting ========\n",
      "actually ========\n",
      "earring ========\n",
      "add ========\n",
      "adjective ========\n",
      "drawing ========\n",
      "dream ========\n",
      "dressed ========\n",
      "driving ========\n",
      "drum ========\n",
      "dry ========\n",
      "duck ========\n",
      "advanced ========\n",
      "during ========\n",
      "earn ========\n",
      "singular ========\n",
      "easily ========\n",
      "east ========\n",
      "eighth ========\n",
      "adventure ========\n",
      "eighty ========\n",
      "adverb ========\n",
      "electric ========\n",
      "advertisement ========\n",
      "century ========\n",
      "size ========\n",
      "electricity ========\n",
      "elephant ========\n",
      "else ========\n",
      "empty ========\n",
      "engine ========\n",
      "engineer ========\n",
      "enough ========\n",
      "enter ========\n",
      "entrance ========\n",
      "advice ========\n",
      "aeroplane ========\n",
      "envelope ========\n",
      "especially ========\n",
      "euro ========\n",
      "even ========\n",
      "afraid ========\n",
      "afterwards ========\n",
      "everyone ========\n",
      "against ========\n",
      "everything ========\n",
      "everywhere ========\n",
      "aged ========\n",
      "ago ========\n",
      "exactly ========\n",
      "exam ========\n",
      "examination ========\n",
      "excellent ========\n",
      "except ========\n",
      "exercise ========\n",
      "exit ========\n",
      "explain ========\n",
      "extra ========\n",
      "fact ========\n",
      "fail ========\n",
      "fair ========\n",
      "fall ========\n",
      "agree ========\n",
      "air ========\n",
      "airport ========\n",
      "fan ========\n",
      "fantastic ========\n",
      "far ========\n",
      "farmer ========\n",
      "fashion ========\n",
      "quite ========\n",
      "alarm ========\n",
      "album ========\n",
      "alcohol ========\n",
      "almost ========\n",
      "alone ========\n",
      "field ========\n",
      "fifth ========\n",
      "fifty ========\n",
      "file ========\n",
      "fill ========\n",
      "final ========\n",
      "finally ========\n",
      "finger ========\n",
      "fire ========\n",
      "fishing ========\n",
      "fit ========\n",
      "flight ========\n",
      "along ========\n",
      "bedroom ========\n",
      "beer ========\n",
      "before ========\n",
      "begin ========\n",
      "behind ========\n",
      "below ========\n",
      "best ========\n",
      "synchrophasotron ========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "      <th>examples_and_definitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "      <td>слово</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>word | floor | words | But i need your word. |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word</td>\n",
       "      <td>microsoft word</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>word | Per snapshot image size and placement c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word</td>\n",
       "      <td>текстовый</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>text | word | Word processing applications all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word</td>\n",
       "      <td>поговорить</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>talk | speak | word | chat | I need to have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>в</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>in | the | The restaurant serves dinner as an ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word      local_word   pos examples local_examples  \\\n",
       "0  word           слово  NOUN     NOUN           NOUN   \n",
       "1  word  microsoft word  NOUN     NOUN           NOUN   \n",
       "2  word       текстовый  NOUN     NOUN           NOUN   \n",
       "3  word      поговорить  NOUN     NOUN           NOUN   \n",
       "4   the               в   DET      DET            DET   \n",
       "\n",
       "                            examples_and_definitions  \n",
       "0  word | floor | words | But i need your word. |...  \n",
       "1  word | Per snapshot image size and placement c...  \n",
       "2  text | word | Word processing applications all...  \n",
       "3  talk | speak | word | chat | I need to have a ...  \n",
       "4  in | the | The restaurant serves dinner as an ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def azure_to_csv(directory, from_lang, to_lang, examples_directory):\n",
    "    eng_word_list = []\n",
    "    local_senseword_list = []\n",
    "    pos_list = []\n",
    "    overall_context = []\n",
    "    words = pd.read_csv(\"test_words.csv\", header = None)\n",
    "    for word_i in words[0].items():\n",
    "        print (word_i[1], \"========\")\n",
    "        file = word_i[1] + \".json\"\n",
    "        file_path = os.path.join(directory, file)\n",
    "        with open(file_path, \"r\") as f: \n",
    "            data = json.load(f)\n",
    "            for translation in data['translations']:\n",
    "                eng_word = word_i[1]\n",
    "                local_word = translation['normalizedTarget']\n",
    "                pos = translation['posTag']\n",
    "                word_context = ''\n",
    "                for backtrans in translation['backTranslations']:\n",
    "                    word_context += backtrans['normalizedText'] + ' | '\n",
    "                #print(translation['posTag'])\n",
    "                example_file_path = os.path.join(examples_directory, word_i[1] + \"_\" + local_word + \".json\")\n",
    "                with open(example_file_path, \"r\") as ex_file: \n",
    "                    example_data = json.load(ex_file)\n",
    "                    for example_json in example_data['examples']:\n",
    "                        eng_ex = example_json[\"sourcePrefix\"] + example_json[\"sourceTerm\"] + example_json[\"sourceSuffix\"]\n",
    "                        local_ex = example_json[\"targetPrefix\"] + example_json[\"targetTerm\"] + example_json[\"targetSuffix\"]\n",
    "                        word_context += eng_ex + ' | '\n",
    "                    eng_word_list.append(word_i[1])\n",
    "                    local_senseword_list.append(local_word)\n",
    "                    pos_list.append(pos)\n",
    "                    overall_context.append(word_context)\n",
    "                \n",
    "                \n",
    "                \n",
    "        #break\n",
    "    df_f = pd.DataFrame(list(zip(eng_word_list, local_senseword_list,pos_list,pos_list,pos_list,overall_context )),\n",
    "                        columns =['word','local_word','pos','examples','local_examples','examples_and_definitions'])\n",
    "    return df_f\n",
    "\n",
    "#get_examples_from_azure_dir(\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_ru\", \"en\", \"ru\",\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_ru_ex\")\n",
    "df_final = azure_to_csv(\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_ru\", \"en\", \"ru\",\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_ru_ex\")\n",
    "\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"lookup_azure_en_ru.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word ========\n",
      "the ========\n",
      "and ========\n",
      "that ========\n",
      "for ========\n",
      "with ========\n",
      "but ========\n",
      "you ========\n",
      "this ========\n",
      "not ========\n",
      "have ========\n",
      "letter ========\n",
      "plate ========\n",
      "treat ========\n",
      "dinner ========\n",
      "necessary ========\n",
      "go ========\n",
      "secret ========\n",
      "table ========\n",
      "create ========\n",
      "warm ========\n",
      "America ========\n",
      "nobody ========\n",
      "entire ========\n",
      "thousand ========\n",
      "Belgium ========\n",
      "anything ========\n",
      "background ========\n",
      "child ========\n",
      "childhood ========\n",
      "dependable ========\n",
      "everything ========\n",
      "grandchild ========\n",
      "ketchup ========\n",
      "point ========\n",
      "strength ========\n",
      "star ========\n",
      "thing ========\n",
      "coincide ========\n",
      "coincidental ========\n",
      "dance ========\n",
      "countryside ========\n",
      "break ========\n",
      "mother ========\n",
      "start ========\n",
      "tip ========\n",
      "apologise ========\n",
      "come ========\n",
      "curriculum ========\n",
      "expertise ========\n",
      "freeze ========\n",
      "issue ========\n",
      "peremptory ========\n",
      "parent ========\n",
      "member ========\n",
      "band ========\n",
      "order ========\n",
      "hot ========\n",
      "fly ========\n",
      "lie ========\n",
      "select ========\n",
      "school ========\n",
      "cafe ========\n",
      "buy ========\n",
      "tell ========\n",
      "international ========\n",
      "stand ========\n",
      "fish ========\n",
      "benefit ========\n",
      "intelligent ========\n",
      "follow ========\n",
      "journey ========\n",
      "news ========\n",
      "write ========\n",
      "approbation ========\n",
      "read ========\n",
      "hear ========\n",
      "feel ========\n",
      "be ========\n",
      "right ========\n",
      "guru ========\n",
      "beginner ========\n",
      "collide ========\n",
      "genetically ========\n",
      "precedent ========\n",
      "refugee ========\n",
      "secular ========\n",
      "pasta ========\n",
      "beaver ========\n",
      "tiger ========\n",
      "lion ========\n",
      "pen ========\n",
      "coconut ========\n",
      "dynamite ========\n",
      "spoon ========\n",
      "ocean ========\n",
      "mug ========\n",
      "shampoo ========\n",
      "buzzer ========\n",
      "exhaustively ========\n",
      "apoplexy ========\n",
      "submissively ========\n",
      "typhus ========\n",
      "ravioli ========\n",
      "meeting ========\n",
      "actually ========\n",
      "earring ========\n",
      "add ========\n",
      "adjective ========\n",
      "drawing ========\n",
      "dream ========\n",
      "dressed ========\n",
      "driving ========\n",
      "drum ========\n",
      "dry ========\n",
      "duck ========\n",
      "advanced ========\n",
      "during ========\n",
      "earn ========\n",
      "singular ========\n",
      "easily ========\n",
      "east ========\n",
      "eighth ========\n",
      "adventure ========\n",
      "eighty ========\n",
      "adverb ========\n",
      "electric ========\n",
      "advertisement ========\n",
      "century ========\n",
      "size ========\n",
      "electricity ========\n",
      "elephant ========\n",
      "else ========\n",
      "empty ========\n",
      "engine ========\n",
      "engineer ========\n",
      "enough ========\n",
      "enter ========\n",
      "entrance ========\n",
      "advice ========\n",
      "aeroplane ========\n",
      "envelope ========\n",
      "especially ========\n",
      "euro ========\n",
      "even ========\n",
      "afraid ========\n",
      "afterwards ========\n",
      "everyone ========\n",
      "against ========\n",
      "everything ========\n",
      "everywhere ========\n",
      "aged ========\n",
      "ago ========\n",
      "exactly ========\n",
      "exam ========\n",
      "examination ========\n",
      "excellent ========\n",
      "except ========\n",
      "exercise ========\n",
      "exit ========\n",
      "explain ========\n",
      "extra ========\n",
      "fact ========\n",
      "fail ========\n",
      "fair ========\n",
      "fall ========\n",
      "agree ========\n",
      "air ========\n",
      "airport ========\n",
      "fan ========\n",
      "fantastic ========\n",
      "far ========\n",
      "farmer ========\n",
      "fashion ========\n",
      "quite ========\n",
      "alarm ========\n",
      "album ========\n",
      "alcohol ========\n",
      "almost ========\n",
      "alone ========\n",
      "field ========\n",
      "fifth ========\n",
      "fifty ========\n",
      "file ========\n",
      "fill ========\n",
      "final ========\n",
      "finally ========\n",
      "finger ========\n",
      "fire ========\n",
      "fishing ========\n",
      "fit ========\n",
      "flight ========\n",
      "along ========\n",
      "bedroom ========\n",
      "beer ========\n",
      "before ========\n",
      "begin ========\n",
      "behind ========\n",
      "below ========\n",
      "best ========\n",
      "synchrophasotron ========\n"
     ]
    }
   ],
   "source": [
    "df_final_en_fr = azure_to_csv(\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_fr\", \"en\", \"fr\",\"/Users/nigula/LL/adjust_unigr_dict/lookup/azure_en_fr_ex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>local_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>examples</th>\n",
       "      <th>local_examples</th>\n",
       "      <th>examples_and_definitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "      <td>conseil</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>national security council | council | board | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word</td>\n",
       "      <td>nouvelles</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>news | word | stop press | breaking news | I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word</td>\n",
       "      <td>mot</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>line | note | code word | word | password | ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word</td>\n",
       "      <td>paroles</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>word | talk | lyrics | lyric | pep talk | utte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word</td>\n",
       "      <td>parole</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>word | faith | speech | gospel truth | spoken ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word local_word    pos examples local_examples  \\\n",
       "0  word    conseil   NOUN     NOUN           NOUN   \n",
       "1  word  nouvelles  OTHER    OTHER          OTHER   \n",
       "2  word        mot   NOUN     NOUN           NOUN   \n",
       "3  word    paroles  OTHER    OTHER          OTHER   \n",
       "4  word     parole  OTHER    OTHER          OTHER   \n",
       "\n",
       "                            examples_and_definitions  \n",
       "0  national security council | council | board | ...  \n",
       "1  news | word | stop press | breaking news | I w...  \n",
       "2  line | note | code word | word | password | ro...  \n",
       "3  word | talk | lyrics | lyric | pep talk | utte...  \n",
       "4  word | faith | speech | gospel truth | spoken ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_en_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_en_fr.to_csv(\"lookup_azure_en_fr.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
